{
  "categories": [
    {
      "slug": "system-integrations",
      "name": "System Integrations",
      "icon": "ðŸ”Œ",
      "subcategories": [
        {
          "slug": "assets-media",
          "name": "Assets Media",
          "skills": [
            {
              "slug": "unsplash-search",
              "name": "unsplash-search",
              "id": "OC-0064",
              "version": "1.0.0",
              "description": "Unsplash Photo Search - Find and license high-res stock photos",
              "commands": [
                "search",
                "get-photo",
                "download",
                "random",
                "list-collections"
              ],
              "env": [
                "UNSPLASH_ACCESS_KEY"
              ],
              "path": "system-integrations/assets-media/unsplash-search",
              "markdownBody": "# Unsplash Photo Search\n\nFind and license high-resolution stock photos from Unsplash.\n\n## Prerequisites\n\n- `UNSPLASH_ACCESS_KEY` â€“ Unsplash API access key.\n\n## Commands\n\n| Command            | Description                              |\n|--------------------|------------------------------------------|\n| `search`           | Search photos by keyword                 |\n| `get-photo`        | Get details for a specific photo         |\n| `download`         | Trigger a download for a photo           |\n| `random`           | Fetch random photos                      |\n| `list-collections` | List featured collections                |\n\n## Usage\n\n```bash\nexport UNSPLASH_ACCESS_KEY=\"your-key\"\npython3 scripts/unsplash_search.py search --query \"mountains\" --per-page 10\npython3 scripts/unsplash_search.py get-photo --photo-id \"abc123\"\npython3 scripts/unsplash_search.py download --photo-id \"abc123\"\npython3 scripts/unsplash_search.py random --count 3\npython3 scripts/unsplash_search.py list-collections --per-page 5\n```"
            },
            {
              "slug": "stock-photo-search",
              "name": "stock-photo-search",
              "id": "OC-0068",
              "version": "1.0.0",
              "description": "Pexels/Pixabay Search - Source free stock photos and videos",
              "commands": [
                "search-pexels",
                "search-pixabay",
                "download",
                "curated",
                "popular"
              ],
              "env": [
                "PEXELS_API_KEY",
                "PIXABAY_API_KEY"
              ],
              "path": "system-integrations/assets-media/stock-photo-search",
              "markdownBody": "# Pexels / Pixabay Search\n\nSource free stock photos and videos from Pexels and Pixabay.\n\n## Prerequisites\n\n- `PEXELS_API_KEY` â€“ Pexels API key.\n- `PIXABAY_API_KEY` â€“ Pixabay API key.\n\n## Commands\n\n| Command          | Description                              |\n|------------------|------------------------------------------|\n| `search-pexels`  | Search photos on Pexels                  |\n| `search-pixabay` | Search photos on Pixabay                 |\n| `download`       | Download a photo by URL                  |\n| `curated`        | Fetch curated photos from Pexels         |\n| `popular`        | Fetch popular images from Pixabay        |\n\n## Usage\n\n```bash\nexport PEXELS_API_KEY=\"your-pexels-key\"\nexport PIXABAY_API_KEY=\"your-pixabay-key\"\npython3 scripts/stock_photo_search.py search-pexels --query \"sunset\" --per-page 10\npython3 scripts/stock_photo_search.py search-pixabay --query \"ocean\" --per-page 10\npython3 scripts/stock_photo_search.py download --url \"https://images.pexels.com/photos/123/example.jpeg\" --output photo.jpg\npython3 scripts/stock_photo_search.py curated --per-page 5\npython3 scripts/stock_photo_search.py popular --per-page 5\n```"
            },
            {
              "slug": "mux-uploader",
              "name": "mux-uploader",
              "id": "OC-0066",
              "version": "1.0.0",
              "description": "Mux Video Uploader - Create video assets and retrieve playback IDs",
              "commands": [
                "create-asset",
                "list-assets",
                "get-asset",
                "delete-asset",
                "create-upload",
                "get-playback"
              ],
              "env": [
                "MUX_TOKEN_ID",
                "MUX_TOKEN_SECRET"
              ],
              "path": "system-integrations/assets-media/mux-uploader",
              "markdownBody": "# Mux Video Uploader\n\nCreate video assets, manage uploads, and retrieve playback IDs from Mux.\n\n## Prerequisites\n\n- `MUX_TOKEN_ID` â€“ Mux API token ID.\n- `MUX_TOKEN_SECRET` â€“ Mux API token secret.\n\n## Commands\n\n| Command         | Description                              |\n|-----------------|------------------------------------------|\n| `create-asset`  | Create a new asset from a video URL      |\n| `list-assets`   | List video assets                        |\n| `get-asset`     | Get details for a specific asset         |\n| `delete-asset`  | Delete a video asset                     |\n| `create-upload` | Create a direct upload URL               |\n| `get-playback`  | Get playback info for an asset           |\n\n## Usage\n\n```bash\nexport MUX_TOKEN_ID=\"your-token-id\"\nexport MUX_TOKEN_SECRET=\"your-token-secret\"\npython3 scripts/mux_uploader.py create-asset --url \"https://example.com/video.mp4\"\npython3 scripts/mux_uploader.py list-assets --limit 10\npython3 scripts/mux_uploader.py get-asset --asset-id \"abc123\"\npython3 scripts/mux_uploader.py delete-asset --asset-id \"abc123\"\npython3 scripts/mux_uploader.py create-upload --cors-origin \"https://example.com\"\npython3 scripts/mux_uploader.py get-playback --asset-id \"abc123\"\n```"
            },
            {
              "slug": "imgix-builder",
              "name": "imgix-builder",
              "id": "OC-0067",
              "version": "1.0.0",
              "description": "Imgix URL Builder - Generate on-demand image transformation URLs",
              "commands": [
                "build-url",
                "list-sources",
                "purge",
                "get-source"
              ],
              "env": [
                "IMGIX_API_KEY",
                "IMGIX_DOMAIN"
              ],
              "path": "system-integrations/assets-media/imgix-builder",
              "markdownBody": "# Imgix URL Builder\n\nGenerate on-demand image transformation URLs and manage Imgix sources.\n\n## Prerequisites\n\n- `IMGIX_API_KEY` â€“ Imgix management API key.\n- `IMGIX_DOMAIN` â€“ Default Imgix source domain (e.g. `my-site.imgix.net`).\n\n## Commands\n\n| Command        | Description                                |\n|----------------|--------------------------------------------|\n| `build-url`    | Build a transformation URL for an image    |\n| `list-sources` | List configured Imgix sources              |\n| `purge`        | Purge a cached image from the CDN          |\n| `get-source`   | Get details for a specific source          |\n\n## Usage\n\n```bash\nexport IMGIX_API_KEY=\"your-key\"\nexport IMGIX_DOMAIN=\"my-site.imgix.net\"\npython3 scripts/imgix_builder.py build-url --path \"/photos/hero.jpg\" --width 800 --height 600 --auto compress,format\npython3 scripts/imgix_builder.py list-sources\npython3 scripts/imgix_builder.py purge --url \"https://my-site.imgix.net/photos/hero.jpg\"\npython3 scripts/imgix_builder.py get-source --source-id \"abc123\"\n```"
            },
            {
              "slug": "cloudinary-manager",
              "name": "cloudinary-manager",
              "id": "OC-0065",
              "version": "1.0.0",
              "description": "Cloudinary Asset Manager - Upload, transform, and optimize images",
              "commands": [
                "upload",
                "list",
                "get",
                "transform",
                "delete",
                "search"
              ],
              "env": [
                "CLOUDINARY_URL",
                "CLOUDINARY_CLOUD_NAME",
                "CLOUDINARY_API_KEY",
                "CLOUDINARY_API_SECRET"
              ],
              "path": "system-integrations/assets-media/cloudinary-manager",
              "markdownBody": "# Cloudinary Asset Manager\n\nUpload, transform, and optimize images with Cloudinary.\n\n## Prerequisites\n\n- `CLOUDINARY_URL` â€“ Full Cloudinary URL (e.g. `cloudinary://key:secret@cloud`), **or** set all three:\n  - `CLOUDINARY_CLOUD_NAME` â€“ Cloud name.\n  - `CLOUDINARY_API_KEY` â€“ API key.\n  - `CLOUDINARY_API_SECRET` â€“ API secret.\n\n## Commands\n\n| Command     | Description                                |\n|-------------|--------------------------------------------|\n| `upload`    | Upload an image from a URL or local path   |\n| `list`      | List resources in your account             |\n| `get`       | Get details for a specific asset           |\n| `transform` | Generate a transformation URL              |\n| `delete`    | Delete a resource by public ID             |\n| `search`    | Search assets with an expression           |\n\n## Usage\n\n```bash\nexport CLOUDINARY_URL=\"cloudinary://key:secret@cloud\"\npython3 scripts/cloudinary_manager.py upload --url \"https://example.com/photo.jpg\" --public-id \"my-photo\"\npython3 scripts/cloudinary_manager.py list --max-results 10\npython3 scripts/cloudinary_manager.py get --public-id \"my-photo\"\npython3 scripts/cloudinary_manager.py transform --public-id \"my-photo\" --width 400 --height 300 --crop fill\npython3 scripts/cloudinary_manager.py delete --public-id \"my-photo\"\npython3 scripts/cloudinary_manager.py search --expression \"cat AND format:jpg\" --max-results 5\n```"
            }
          ]
        },
        {
          "slug": "auth-users",
          "name": "Auth Users",
          "skills": [
            {
              "slug": "workos-directory",
              "name": "workos-directory",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0062: WorkOS Directory Sync - Manage enterprise SSO and SCIM directories via the WorkOS API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/auth-users/workos-directory",
              "markdownBody": "# WorkOS Directory Sync\n\nManage enterprise directory sync, SSO connections, and organizations via WorkOS.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `WORKOS_API_KEY` environment variable set to your WorkOS API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-directories` | List all configured directories |\n| `list-users` | List users in a directory |\n| `list-groups` | List groups in a directory |\n| `get-directory` | Get details of a specific directory |\n| `list-connections` | List SSO connections |\n| `list-orgs` | List organizations |\n\n## Usage\n\n```bash\nexport WORKOS_API_KEY=\"sk_live_...\"\n\npython scripts/workos_directory.py list-directories --limit 10\npython scripts/workos_directory.py list-users --directory-id dir_abc123\npython scripts/workos_directory.py list-groups --directory-id dir_abc123\npython scripts/workos_directory.py get-directory --directory-id dir_abc123\npython scripts/workos_directory.py list-connections --limit 10\npython scripts/workos_directory.py list-orgs --limit 10\n```"
            },
            {
              "slug": "supabase-auth",
              "name": "supabase-auth",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0061: Supabase Auth Helper - Send password reset emails, manage providers and users via the Supabase Admin API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/auth-users/supabase-auth",
              "markdownBody": "# Supabase Auth Helper\n\nManage Supabase Auth users, send password resets, and inspect MFA factors.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `SUPABASE_URL` environment variable (e.g. `https://xyzproject.supabase.co`)\n- `SUPABASE_SERVICE_KEY` environment variable set to your service role key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-users` | List all users with pagination |\n| `get-user` | Get details for a specific user |\n| `create-user` | Create a new user with email and password |\n| `delete-user` | Delete a user by ID |\n| `send-reset` | Send a password reset email to a user |\n| `list-factors` | List MFA factors for a user |\n\n## Usage\n\n```bash\nexport SUPABASE_URL=\"https://xyzproject.supabase.co\"\nexport SUPABASE_SERVICE_KEY=\"eyJ...\"\n\npython scripts/supabase_auth.py list-users --limit 20\npython scripts/supabase_auth.py get-user --user-id \"uuid-here\"\npython scripts/supabase_auth.py create-user --email user@example.com --password \"s3cret!\"\npython scripts/supabase_auth.py delete-user --user-id \"uuid-here\"\npython scripts/supabase_auth.py send-reset --email user@example.com\npython scripts/supabase_auth.py list-factors --user-id \"uuid-here\"\n```"
            },
            {
              "slug": "firebase-auth",
              "name": "firebase-auth",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0063: Firebase Auth Manager - Disable accounts, revoke tokens, and manage custom claims via the Firebase Auth REST API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/auth-users/firebase-auth",
              "markdownBody": "# Firebase Auth Manager\n\nManage Firebase Auth users, disable accounts, and set custom claims from the CLI.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `FIREBASE_PROJECT_ID` environment variable set to your Firebase project ID\n- `GOOGLE_APPLICATION_CREDENTIALS` environment variable pointing to a service account JSON file\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-users` | List all users with pagination |\n| `get-user` | Get details for a specific user by UID |\n| `create-user` | Create a new user with email and password |\n| `disable-user` | Disable a user account |\n| `delete-user` | Permanently delete a user |\n| `set-claims` | Set custom claims on a user |\n\n## Usage\n\n```bash\nexport FIREBASE_PROJECT_ID=\"my-project\"\nexport GOOGLE_APPLICATION_CREDENTIALS=\"/path/to/service-account.json\"\n\npython scripts/firebase_auth.py list-users --limit 20\npython scripts/firebase_auth.py get-user --uid \"abc123\"\npython scripts/firebase_auth.py create-user --email user@example.com --password \"s3cret!\"\npython scripts/firebase_auth.py disable-user --uid \"abc123\"\npython scripts/firebase_auth.py delete-user --uid \"abc123\"\npython scripts/firebase_auth.py set-claims --uid \"abc123\" --claims '{\"admin\": true}'\n```"
            },
            {
              "slug": "clerk-admin",
              "name": "clerk-admin",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0059: Clerk User Admin - Ban/unban users, manage sessions and roles via the Clerk Backend API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/auth-users/clerk-admin",
              "markdownBody": "# Clerk User Admin\n\nManage Clerk users, sessions, and roles from the command line.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `CLERK_SECRET_KEY` environment variable set to your Clerk secret key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-users` | List all users with optional limit |\n| `get-user` | Get details for a specific user by ID |\n| `ban` | Ban a user by ID |\n| `unban` | Unban a previously banned user |\n| `delete-user` | Permanently delete a user |\n| `list-sessions` | List active sessions for a user |\n| `update-role` | Update the role for a user in an organization |\n\n## Usage\n\n```bash\nexport CLERK_SECRET_KEY=\"sk_live_...\"\n\npython scripts/clerk_admin.py list-users --limit 10\npython scripts/clerk_admin.py get-user --user-id user_abc123\npython scripts/clerk_admin.py ban --user-id user_abc123\npython scripts/clerk_admin.py unban --user-id user_abc123\npython scripts/clerk_admin.py delete-user --user-id user_abc123\npython scripts/clerk_admin.py list-sessions --user-id user_abc123\npython scripts/clerk_admin.py update-role --user-id user_abc123 --org-id org_xyz --role admin\n```"
            },
            {
              "slug": "auth0-inspector",
              "name": "auth0-inspector",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0060: Auth0 Log Inspector - Check failed login attempts and anomalies via the Auth0 Management API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/auth-users/auth0-inspector",
              "markdownBody": "# Auth0 Log Inspector\n\nInspect Auth0 logs for failed logins, anomalies, and manage users and connections.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `AUTH0_DOMAIN` environment variable (e.g. `your-tenant.us.auth0.com`)\n- `AUTH0_MGMT_TOKEN` environment variable set to a Management API token\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-logs` | List recent log events |\n| `search-logs` | Search logs with a Lucene query |\n| `list-users` | List all users |\n| `get-user` | Get details for a specific user |\n| `block-user` | Block a user by ID |\n| `list-connections` | List configured identity connections |\n\n## Usage\n\n```bash\nexport AUTH0_DOMAIN=\"your-tenant.us.auth0.com\"\nexport AUTH0_MGMT_TOKEN=\"eyJ...\"\n\npython scripts/auth0_inspector.py list-logs --limit 25\npython scripts/auth0_inspector.py search-logs --query \"type:f\"\npython scripts/auth0_inspector.py list-users --limit 10\npython scripts/auth0_inspector.py get-user --user-id \"auth0|abc123\"\npython scripts/auth0_inspector.py block-user --user-id \"auth0|abc123\"\npython scripts/auth0_inspector.py list-connections\n```"
            }
          ]
        },
        {
          "slug": "cms-content",
          "name": "Cms Content",
          "skills": [
            {
              "slug": "wordpress-publisher",
              "name": "WordPress Post Publisher",
              "id": "OC-0046",
              "version": "1.0.0",
              "description": "Draft and publish blog posts via the WordPress REST API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/wordpress-publisher",
              "markdownBody": "# WordPress Post Publisher\n\nCreate, update, and manage WordPress posts and categories through the REST API.\n\n## Capabilities\n\n- List, create, update, and delete posts\n- Manage post status (draft, publish, pending)\n- Browse categories for content organization\n\n## Quick Start\n\n```bash\nexport WORDPRESS_URL=\"https://your-site.com\"\nexport WORDPRESS_USERNAME=\"admin\"\nexport WORDPRESS_APP_PASSWORD=\"xxxx xxxx xxxx xxxx\"\npython3 scripts/wordpress_publisher.py list-posts\npython3 scripts/wordpress_publisher.py create-post --title \"Hello World\" --content \"<p>My first post</p>\"\n```\n\n## Commands & Parameters\n\n| Command           | Parameters                                             | Description                     |\n| ----------------- | ------------------------------------------------------ | ------------------------------- |\n| `list-posts`      | `--status` (optional), `--per-page` (optional)         | List posts                      |\n| `get-post`        | `--id`                                                 | Get a single post               |\n| `create-post`     | `--title`, `--content`, `--status` (default: draft)    | Create a new post               |\n| `update-post`     | `--id`, `--title`/`--content`/`--status` (optional)    | Update an existing post         |\n| `delete-post`     | `--id`                                                 | Move a post to trash            |\n| `list-categories` | â€”                                                      | List all categories             |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `WORDPRESS_URL`, `WORDPRESS_USERNAME`, `WORDPRESS_APP_PASSWORD`"
            },
            {
              "slug": "webflow-updater",
              "name": "Webflow CMS Updater",
              "id": "OC-0048",
              "version": "1.0.0",
              "description": "Push collection item changes to Webflow CMS.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/webflow-updater",
              "markdownBody": "# Webflow CMS Updater\n\nManage Webflow sites, collections, and items through the Webflow Data API.\n\n## Capabilities\n\n- List sites and their collections\n- CRUD operations on collection items\n- Publish staged changes to production\n\n## Quick Start\n\n```bash\nexport WEBFLOW_API_TOKEN=\"your-api-token\"\npython3 scripts/webflow_updater.py list-sites\npython3 scripts/webflow_updater.py list-items --collection-id abc123\npython3 scripts/webflow_updater.py create-item --collection-id abc123 --fields '{\"name\":\"New Item\",\"slug\":\"new-item\"}'\n```\n\n## Commands & Parameters\n\n| Command            | Parameters                                        | Description                        |\n| ------------------ | ------------------------------------------------- | ---------------------------------- |\n| `list-sites`       | â€”                                                 | List all authorized sites          |\n| `list-collections` | `--site-id`                                       | List collections for a site        |\n| `list-items`       | `--collection-id`                                 | List items in a collection         |\n| `create-item`      | `--collection-id`, `--fields` (JSON)              | Create a new collection item       |\n| `update-item`      | `--collection-id`, `--item-id`, `--fields` (JSON) | Update an existing item            |\n| `publish`          | `--site-id`, `--domains` (optional, JSON array)   | Publish staged changes             |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `WEBFLOW_API_TOKEN`"
            },
            {
              "slug": "strapi-client",
              "name": "Strapi API Client",
              "id": "OC-0045",
              "version": "1.0.0",
              "description": "Manage dynamic content types via the Strapi REST API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/strapi-client",
              "markdownBody": "# Strapi API Client\n\nInteract with your Strapi instance to list content types, create, update, and delete entries.\n\n## Capabilities\n\n- List available content types\n- CRUD operations on collection entries\n- Filter and paginate entry lists\n\n## Quick Start\n\n```bash\nexport STRAPI_URL=\"https://your-strapi.example.com\"\nexport STRAPI_API_TOKEN=\"your-api-token\"\npython3 scripts/strapi_client.py list-content-types\npython3 scripts/strapi_client.py create --type articles --data '{\"title\":\"Hello\",\"body\":\"World\"}'\n```\n\n## Commands & Parameters\n\n| Command              | Parameters                                    | Description                     |\n| -------------------- | --------------------------------------------- | ------------------------------- |\n| `list-content-types` | â€”                                             | List registered content types   |\n| `list-entries`       | `--type`                                      | List entries for a content type |\n| `get-entry`          | `--type`, `--id`                              | Get a single entry by ID        |\n| `create`             | `--type`, `--data` (JSON)                     | Create a new entry              |\n| `update`             | `--type`, `--id`, `--data` (JSON)             | Update an existing entry        |\n| `delete`             | `--type`, `--id`                              | Delete an entry                 |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `STRAPI_URL`, `STRAPI_API_TOKEN`"
            },
            {
              "slug": "sanity-helper",
              "name": "Sanity Studio Helper",
              "id": "OC-0044",
              "version": "1.0.0",
              "description": "Trigger webhooks or clear datasets in Sanity CMS.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/sanity-helper",
              "markdownBody": "# Sanity Studio Helper\n\nQuery, create, patch, and delete documents in your Sanity dataset, plus trigger webhooks.\n\n## Capabilities\n\n- List and retrieve documents from a dataset\n- Create, patch, and delete documents via mutations\n- Trigger deploy webhooks for rebuilds\n\n## Quick Start\n\n```bash\nexport SANITY_PROJECT_ID=\"your-project-id\"\nexport SANITY_TOKEN=\"your-api-token\"\nexport SANITY_DATASET=\"production\"\npython3 scripts/sanity_helper.py list-documents --type post\npython3 scripts/sanity_helper.py create --doc '{\"_type\":\"post\",\"title\":\"Hello\"}'\n```\n\n## Commands & Parameters\n\n| Command            | Parameters                                    | Description                     |\n| ------------------ | --------------------------------------------- | ------------------------------- |\n| `list-documents`   | `--type` (optional)                           | List documents, filter by type  |\n| `get-document`     | `--id`                                        | Get a document by ID            |\n| `create`           | `--doc` (JSON)                                | Create a new document           |\n| `patch`            | `--id`, `--set` (JSON)                        | Patch fields on a document      |\n| `delete`           | `--id`                                        | Delete a document               |\n| `trigger-webhook`  | `--url`                                       | POST to a deploy webhook URL    |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `SANITY_PROJECT_ID`, `SANITY_TOKEN`, `SANITY_DATASET`"
            },
            {
              "slug": "notion-publisher",
              "name": "Notion Page Publisher",
              "id": "OC-0049",
              "version": "1.0.0",
              "description": "Create and update Notion pages and databases.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/notion-publisher",
              "markdownBody": "# Notion Page Publisher\n\nSearch, create, and update Notion pages and databases via the Notion API.\n\n## Capabilities\n\n- Search across pages and databases\n- Create and update pages with rich properties\n- Append block children to existing pages\n- Query database contents\n\n## Quick Start\n\n```bash\nexport NOTION_API_KEY=\"your-integration-token\"\npython3 scripts/notion_publisher.py search --query \"Meeting Notes\"\npython3 scripts/notion_publisher.py create-page --parent-id abc123 --properties '{\"title\":[{\"text\":{\"content\":\"New Page\"}}]}'\n```\n\n## Commands & Parameters\n\n| Command          | Parameters                                            | Description                        |\n| ---------------- | ----------------------------------------------------- | ---------------------------------- |\n| `search`         | `--query`                                             | Search pages and databases         |\n| `get-page`       | `--page-id`                                           | Get a page by ID                   |\n| `create-page`    | `--parent-id`, `--properties` (JSON)                  | Create a new page                  |\n| `update-page`    | `--page-id`, `--properties` (JSON)                    | Update page properties             |\n| `append-blocks`  | `--page-id`, `--blocks` (JSON)                        | Append block children to a page    |\n| `get-database`   | `--database-id`                                       | Query a database                   |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `NOTION_API_KEY`"
            },
            {
              "slug": "ghost-admin",
              "name": "Ghost Admin",
              "id": "OC-0047",
              "version": "1.0.0",
              "description": "Manage membership tiers and posts via the Ghost Admin API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/ghost-admin",
              "markdownBody": "# Ghost Admin\n\nCreate, update, and delete posts, and inspect membership tiers and members through the Ghost Admin API.\n\n## Capabilities\n\n- Full CRUD for Ghost posts (draft and published)\n- List membership tiers and active members\n- JWT-based Admin API authentication\n\n## Quick Start\n\n```bash\nexport GHOST_URL=\"https://your-ghost.example.com\"\nexport GHOST_ADMIN_KEY=\"admin-api-key-id:secret\"\npython3 scripts/ghost_admin.py list-posts\npython3 scripts/ghost_admin.py create-post --title \"New Post\" --html \"<p>Content here</p>\"\n```\n\n## Commands & Parameters\n\n| Command        | Parameters                                          | Description                     |\n| -------------- | --------------------------------------------------- | ------------------------------- |\n| `list-posts`   | â€”                                                   | List recent posts               |\n| `create-post`  | `--title`, `--html`, `--status` (default: draft)    | Create a new post               |\n| `update-post`  | `--id`, `--title`/`--html`/`--status` (optional)    | Update an existing post         |\n| `delete-post`  | `--id`                                              | Delete a post                   |\n| `list-tiers`   | â€”                                                   | List membership tiers           |\n| `list-members` | â€”                                                   | List members                    |\n\n## Dependencies\n\n- Python 3.8+\n- `requests`, `PyJWT` libraries\n- Environment variables: `GHOST_URL`, `GHOST_ADMIN_KEY`"
            },
            {
              "slug": "contentful-manager",
              "name": "Contentful Entry Manager",
              "id": "OC-0043",
              "version": "1.0.0",
              "description": "Publish or archive content entries in Contentful CMS.",
              "commands": [],
              "env": [],
              "path": "system-integrations/cms-content/contentful-manager",
              "markdownBody": "# Contentful Entry Manager\n\nManage content entries in your Contentful space â€” list, create, publish, unpublish, and archive.\n\n## Capabilities\n\n- List and inspect content entries in a space\n- Create new entries with custom field data\n- Publish and unpublish entries\n- Archive entries to remove them from delivery\n\n## Quick Start\n\n```bash\nexport CONTENTFUL_SPACE_ID=\"your-space-id\"\nexport CONTENTFUL_MANAGEMENT_TOKEN=\"your-cma-token\"\npython3 scripts/contentful_manager.py list-entries --content-type blogPost\npython3 scripts/contentful_manager.py publish --entry-id abc123\n```\n\n## Commands & Parameters\n\n| Command         | Parameters                                       | Description                     |\n| --------------- | ------------------------------------------------ | ------------------------------- |\n| `list-entries`  | `--content-type` (optional)                      | List entries, optionally by type|\n| `get-entry`     | `--entry-id`                                     | Get a single entry by ID        |\n| `publish`       | `--entry-id`                                     | Publish an entry                |\n| `unpublish`     | `--entry-id`                                     | Unpublish an entry              |\n| `archive`       | `--entry-id`                                     | Archive an entry                |\n| `create-entry`  | `--content-type`, `--fields` (JSON)              | Create a new entry              |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `CONTENTFUL_SPACE_ID`, `CONTENTFUL_MANAGEMENT_TOKEN`"
            }
          ]
        },
        {
          "slug": "commerce-payments",
          "name": "Commerce Payments",
          "skills": [
            {
              "slug": "stripe-webhooks",
              "name": "stripe-webhooks",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0070: Stripe Webhook Debugger â€” Inspect webhook events, manage endpoints, and replay failed deliveries.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/stripe-webhooks",
              "markdownBody": "# Stripe Webhook Debugger\n\nInspect webhook events, manage endpoints, and replay failed deliveries through the Stripe API.\n\n## Capabilities\n\n1. **Event Inspection**: List and view individual webhook events.\n2. **Endpoint Management**: List existing endpoints or create new ones.\n3. **Replay**: Retry delivery of a specific event to an endpoint.\n\n## Quick Start\n\n```bash\n# List recent events\npython3 skills/system-integrations/commerce-payments/stripe-webhooks/scripts/manage.py list-events\n\n# Get details of a specific event\npython3 skills/system-integrations/commerce-payments/stripe-webhooks/scripts/manage.py get-event evt_1234\n\n# List webhook endpoints\npython3 skills/system-integrations/commerce-payments/stripe-webhooks/scripts/manage.py list-endpoints\n\n# Create a new endpoint\npython3 skills/system-integrations/commerce-payments/stripe-webhooks/scripts/manage.py create-endpoint https://example.com/webhook --events invoice.paid customer.created\n\n# Replay an event\npython3 skills/system-integrations/commerce-payments/stripe-webhooks/scripts/manage.py replay evt_1234\n```\n\n## Commands & Parameters\n\n### `list-events`\nLists recent webhook events.\n- `--type`: Filter by event type (e.g. `invoice.paid`)\n- `--limit`: Number of results (default: 10)\n\n### `get-event`\nRetrieves details of a specific event.\n- `event_id`: Stripe event ID (required)\n\n### `list-endpoints`\nLists configured webhook endpoints.\n- `--limit`: Number of results (default: 10)\n\n### `create-endpoint`\nCreates a new webhook endpoint.\n- `url`: Endpoint URL (required)\n- `--events`: Space-separated list of event types to subscribe to\n\n### `replay`\nRetries delivery of an event by re-posting its payload to all enabled endpoints.\n- `event_id`: Stripe event ID (required)\n\n## Environment Variables\n\n| Variable            | Required | Description          |\n|---------------------|----------|----------------------|\n| `STRIPE_SECRET_KEY` | Yes      | Stripe secret API key |"
            },
            {
              "slug": "stripe-subscriptions",
              "name": "stripe-subscriptions",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0069: Stripe Subscription Manager â€” Cancel/refund subscriptions, manage products and prices via the Stripe API.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/stripe-subscriptions",
              "markdownBody": "# Stripe Subscription Manager\n\nCancel or refund subscriptions, list products and prices through the Stripe API.\n\n## Capabilities\n\n1. **Subscription Management**: List, cancel, and refund subscriptions.\n2. **Product Catalog**: List products and create new ones.\n3. **Price Inspection**: List prices associated with products.\n\n## Quick Start\n\n```bash\n# List active subscriptions\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py list-subscriptions\n\n# Cancel a subscription immediately\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py cancel sub_1234 --immediate\n\n# Refund the latest invoice on a subscription\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py refund sub_1234\n\n# List all products\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py list-products\n\n# Create a product\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py create-product \"Pro Plan\"\n\n# List prices\npython3 skills/system-integrations/commerce-payments/stripe-subscriptions/scripts/manage.py list-prices\n```\n\n## Commands & Parameters\n\n### `list-subscriptions`\nLists subscriptions from your Stripe account.\n- `--status`: Filter by status (`active`, `canceled`, `past_due`, etc.)\n- `--limit`: Number of results (default: 10)\n\n### `cancel`\nCancels a subscription.\n- `subscription_id`: Stripe subscription ID (required)\n- `--immediate`: Cancel immediately instead of at period end (flag)\n\n### `refund`\nRefunds the latest invoice on a subscription.\n- `subscription_id`: Stripe subscription ID (required)\n- `--amount`: Partial refund amount in cents (optional, full refund by default)\n\n### `list-products`\nLists products in your Stripe account.\n- `--limit`: Number of results (default: 10)\n\n### `create-product`\nCreates a new product.\n- `name`: Product name (required)\n- `--description`: Product description\n\n### `list-prices`\nLists prices.\n- `--product`: Filter by product ID\n- `--limit`: Number of results (default: 10)\n\n## Environment Variables\n\n| Variable            | Required | Description          |\n|---------------------|----------|----------------------|\n| `STRIPE_SECRET_KEY` | Yes      | Stripe secret API key |"
            },
            {
              "slug": "shopify-orders",
              "name": "shopify-orders",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0073: Shopify Order Manager â€” Fetch, refund, or fulfill orders, and browse products and customers.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/shopify-orders",
              "markdownBody": "# Shopify Order Manager\n\nFetch, refund, or fulfill orders, list products, and browse customers through the Shopify Admin API.\n\n## Capabilities\n\n1. **Order Management**: List, inspect, refund, and fulfill orders.\n2. **Product Catalog**: List products in the store.\n3. **Customer Directory**: Browse customer records.\n\n## Quick Start\n\n```bash\n# List recent orders\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py list-orders\n\n# Get order details\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py get-order 1234567890\n\n# Refund an order\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py refund 1234567890\n\n# Fulfill an order\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py fulfill 1234567890 --tracking-number \"1Z999AA10123456784\"\n\n# List products\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py list-products\n\n# List customers\npython3 skills/system-integrations/commerce-payments/shopify-orders/scripts/manage.py list-customers\n```\n\n## Commands & Parameters\n\n### `list-orders`\nLists recent orders.\n- `--status`: Filter by status (`open`, `closed`, `cancelled`, `any`; default: `any`)\n- `--limit`: Number of results (default: 10)\n\n### `get-order`\nRetrieves details for a specific order.\n- `order_id`: Shopify order ID (required)\n\n### `refund`\nCreates a full refund for an order.\n- `order_id`: Shopify order ID (required)\n- `--note`: Refund reason note\n\n### `fulfill`\nCreates a fulfillment for an order.\n- `order_id`: Shopify order ID (required)\n- `--tracking-number`: Shipment tracking number\n- `--tracking-company`: Shipping carrier name\n\n### `list-products`\nLists products in the store.\n- `--limit`: Number of results (default: 10)\n\n### `list-customers`\nLists customers.\n- `--limit`: Number of results (default: 10)\n\n## Environment Variables\n\n| Variable               | Required | Description                         |\n|------------------------|----------|-------------------------------------|\n| `SHOPIFY_STORE`        | Yes      | Shopify store domain (e.g. `mystore.myshopify.com`) |\n| `SHOPIFY_ACCESS_TOKEN` | Yes      | Shopify Admin API access token      |"
            },
            {
              "slug": "revenuecat-lookup",
              "name": "revenuecat-lookup",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0072: RevenueCat Customer Lookup â€” Check in-app purchase status, offerings, entitlements, and subscriptions.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/revenuecat-lookup",
              "markdownBody": "# RevenueCat Customer Lookup\n\nCheck in-app purchase status, list offerings and entitlements, and inspect subscriptions through the RevenueCat API.\n\n## Capabilities\n\n1. **Customer Lookup**: Retrieve a customer profile by app user ID.\n2. **Offerings & Entitlements**: List available offerings and entitlements.\n3. **Subscription Inspection**: View subscription details and product catalog.\n\n## Quick Start\n\n```bash\n# Get customer info\npython3 skills/system-integrations/commerce-payments/revenuecat-lookup/scripts/manage.py get-customer app_user_123\n\n# List offerings\npython3 skills/system-integrations/commerce-payments/revenuecat-lookup/scripts/manage.py list-offerings\n\n# List entitlements for a customer\npython3 skills/system-integrations/commerce-payments/revenuecat-lookup/scripts/manage.py list-entitlements app_user_123\n\n# Get subscription details\npython3 skills/system-integrations/commerce-payments/revenuecat-lookup/scripts/manage.py get-subscription app_user_123 --product-id prod_monthly\n\n# List products\npython3 skills/system-integrations/commerce-payments/revenuecat-lookup/scripts/manage.py list-products\n```\n\n## Commands & Parameters\n\n### `get-customer`\nRetrieves a customer profile.\n- `app_user_id`: RevenueCat app user ID (required)\n\n### `list-offerings`\nLists all offerings configured in your RevenueCat project.\n\n### `list-entitlements`\nLists active entitlements for a customer.\n- `app_user_id`: RevenueCat app user ID (required)\n\n### `get-subscription`\nGets subscription details for a customer.\n- `app_user_id`: RevenueCat app user ID (required)\n- `--product-id`: Filter by product identifier\n\n### `list-products`\nLists products configured in your RevenueCat project.\n- `--limit`: Number of results (default: 10)\n\n## Environment Variables\n\n| Variable            | Required | Description                      |\n|---------------------|----------|----------------------------------|\n| `REVENUECAT_API_KEY`| Yes      | RevenueCat secret API key (V1)   |"
            },
            {
              "slug": "paddle-inspector",
              "name": "paddle-inspector",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0074: Paddle Subscription Inspector â€” Audit billing history, manage subscriptions, and list transactions.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/paddle-inspector",
              "markdownBody": "# Paddle Subscription Inspector\n\nAudit billing history, manage subscriptions (cancel, pause, resume), and list transactions through the Paddle API.\n\n## Capabilities\n\n1. **Subscription Management**: List, inspect, cancel, pause, and resume subscriptions.\n2. **Transaction History**: List transactions for billing audits.\n\n## Quick Start\n\n```bash\n# List subscriptions\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py list-subscriptions\n\n# Get subscription details\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py get-subscription sub_01h1234\n\n# Cancel a subscription\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py cancel sub_01h1234\n\n# Pause a subscription\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py pause sub_01h1234\n\n# Resume a paused subscription\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py resume sub_01h1234\n\n# List transactions\npython3 skills/system-integrations/commerce-payments/paddle-inspector/scripts/manage.py list-transactions\n```\n\n## Commands & Parameters\n\n### `list-subscriptions`\nLists subscriptions.\n- `--status`: Filter by status (`active`, `canceled`, `paused`, `past_due`, `trialing`)\n- `--limit`: Number of results (default: 10)\n\n### `get-subscription`\nRetrieves details of a specific subscription.\n- `subscription_id`: Paddle subscription ID (required)\n\n### `cancel`\nCancels a subscription at end of billing period.\n- `subscription_id`: Paddle subscription ID (required)\n- `--immediate`: Cancel immediately (flag)\n\n### `pause`\nPauses a subscription at end of billing period.\n- `subscription_id`: Paddle subscription ID (required)\n\n### `resume`\nResumes a paused subscription.\n- `subscription_id`: Paddle subscription ID (required)\n\n### `list-transactions`\nLists transactions for billing audits.\n- `--subscription-id`: Filter by subscription ID\n- `--limit`: Number of results (default: 10)\n\n## Environment Variables\n\n| Variable          | Required | Description               |\n|-------------------|----------|---------------------------|\n| `PADDLE_API_KEY`  | Yes      | Paddle API authentication key |"
            },
            {
              "slug": "lemonsqueezy-license",
              "name": "lemonsqueezy-license",
              "id": null,
              "version": "1.0.0",
              "description": "OC-0071: Lemon Squeezy License Check â€” Verify license keys, manage activations, and list products.",
              "commands": [],
              "env": [],
              "path": "system-integrations/commerce-payments/lemonsqueezy-license",
              "markdownBody": "# Lemon Squeezy License Check\n\nVerify license keys, manage activations, and browse products through the Lemon Squeezy API.\n\n## Capabilities\n\n1. **License Validation**: Validate a license key and check its activation status.\n2. **Activation Management**: Activate or deactivate license instances.\n3. **Product Catalog**: List available products.\n\n## Quick Start\n\n```bash\n# Validate a license key\npython3 skills/system-integrations/commerce-payments/lemonsqueezy-license/scripts/manage.py validate-key \"ABCD-1234-EFGH-5678\"\n\n# List all licenses\npython3 skills/system-integrations/commerce-payments/lemonsqueezy-license/scripts/manage.py list-licenses\n\n# Activate a license\npython3 skills/system-integrations/commerce-payments/lemonsqueezy-license/scripts/manage.py activate \"ABCD-1234-EFGH-5678\" --instance-name \"server-1\"\n\n# Deactivate a license instance\npython3 skills/system-integrations/commerce-payments/lemonsqueezy-license/scripts/manage.py deactivate \"ABCD-1234-EFGH-5678\" --instance-id \"ins_abc123\"\n\n# List products\npython3 skills/system-integrations/commerce-payments/lemonsqueezy-license/scripts/manage.py list-products\n```\n\n## Commands & Parameters\n\n### `validate-key`\nValidates a license key.\n- `license_key`: The license key to validate (required)\n\n### `list-licenses`\nLists all licenses in your store.\n- `--limit`: Number of results (default: 10)\n\n### `activate`\nActivates a license key for a specific instance.\n- `license_key`: The license key (required)\n- `--instance-name`: Name for this activation instance (required)\n\n### `deactivate`\nDeactivates a license key instance.\n- `license_key`: The license key (required)\n- `--instance-id`: The instance ID to deactivate (required)\n\n### `list-products`\nLists products in your Lemon Squeezy store.\n- `--limit`: Number of results (default: 10)\n\n## Environment Variables\n\n| Variable              | Required | Description                |\n|-----------------------|----------|----------------------------|\n| `LEMONSQUEEZY_API_KEY`| Yes      | Lemon Squeezy API key      |"
            }
          ]
        },
        {
          "slug": "communication",
          "name": "Communication",
          "skills": [
            {
              "slug": "twilio-sms",
              "name": "twilio-sms",
              "id": "OC-0076",
              "version": "1.0.0",
              "description": "Twilio SMS & WhatsApp â€“ Send and receive SMS/WhatsApp messages programmatically",
              "commands": [
                "send-sms",
                "send-whatsapp",
                "list-messages",
                "get-message",
                "list-phone-numbers"
              ],
              "env": [
                "TWILIO_ACCOUNT_SID",
                "TWILIO_AUTH_TOKEN",
                "TWILIO_PHONE_NUMBER"
              ],
              "path": "system-integrations/communication/twilio-sms",
              "markdownBody": "# Twilio SMS & WhatsApp\n\nSend and receive SMS and WhatsApp messages programmatically via the Twilio API.\n\n## Prerequisites\n\n- `TWILIO_ACCOUNT_SID` â€“ Twilio Account SID.\n- `TWILIO_AUTH_TOKEN` â€“ Twilio Auth Token.\n- `TWILIO_PHONE_NUMBER` â€“ Default Twilio phone number (E.164 format, e.g. +15551234567).\n\n## Commands\n\n| Command              | Description                              |\n|----------------------|------------------------------------------|\n| `send-sms`           | Send an SMS message                      |\n| `send-whatsapp`      | Send a WhatsApp message                  |\n| `list-messages`      | List recent messages                     |\n| `get-message`        | Get details for a specific message       |\n| `list-phone-numbers` | List phone numbers on the account        |\n\n## Usage\n\n```bash\nexport TWILIO_ACCOUNT_SID=\"your-account-sid\"\nexport TWILIO_AUTH_TOKEN=\"your-auth-token\"\nexport TWILIO_PHONE_NUMBER=\"+15551234567\"\npython3 scripts/twilio_sms.py send-sms --to \"+15559876543\" --body \"Hello from Twilio!\"\npython3 scripts/twilio_sms.py send-whatsapp --to \"+15559876543\" --body \"Hello from WhatsApp!\"\npython3 scripts/twilio_sms.py list-messages --limit 10\npython3 scripts/twilio_sms.py get-message --message-sid SM1234567890abcdef1234567890abcdef\npython3 scripts/twilio_sms.py list-phone-numbers\n```"
            },
            {
              "slug": "slack-bot",
              "name": "slack-bot",
              "id": "OC-0077",
              "version": "1.0.0",
              "description": "Slack Bot Publisher - Post messages and manage channels via Bot API",
              "commands": [
                "post-message",
                "list-channels",
                "list-members",
                "upload-file",
                "set-topic"
              ],
              "env": [
                "SLACK_BOT_TOKEN"
              ],
              "path": "system-integrations/communication/slack-bot",
              "markdownBody": "# Slack Bot Publisher\n\nPost messages, manage channels, and upload files via the Slack Bot API.\n\n## Prerequisites\n\n- A valid `SLACK_BOT_TOKEN` environment variable.\n\n## Commands\n\n| Command          | Description                          |\n|------------------|--------------------------------------|\n| `post-message`   | Post a message to a channel          |\n| `list-channels`  | List available channels              |\n| `list-members`   | List members of a channel            |\n| `upload-file`    | Upload a file to a channel           |\n| `set-topic`      | Set the topic of a channel           |\n\n## Usage\n\n```bash\nexport SLACK_BOT_TOKEN=\"xoxb-your-token\"\npython3 scripts/slack_bot.py list-channels\npython3 scripts/slack_bot.py post-message --channel \"#general\" --text \"Hello from the bot!\"\npython3 scripts/slack_bot.py list-members --channel C01ABCDEF\npython3 scripts/slack_bot.py upload-file --channels \"#general\" --content \"Log output here\"\npython3 scripts/slack_bot.py upload-file --channels \"#general\" --file ./report.csv --title \"Weekly Report\"\npython3 scripts/slack_bot.py set-topic --channel C01ABCDEF --topic \"Sprint 42 updates\"\n```"
            },
            {
              "slug": "resend-email",
              "name": "resend-email",
              "id": "OC-0075",
              "version": "1.0.0",
              "description": "Resend Email Sender â€“ Send transactional emails with templates",
              "commands": [
                "send",
                "list-emails",
                "get-email",
                "list-domains",
                "list-api-keys"
              ],
              "env": [
                "RESEND_API_KEY"
              ],
              "path": "system-integrations/communication/resend-email",
              "markdownBody": "# Resend Email Sender\n\nSend transactional emails, manage domains, and inspect API keys via the Resend API.\n\n## Prerequisites\n- A valid `RESEND_API_KEY` environment variable.\n\n## Commands\n| Command         | Description                     |\n|-----------------|---------------------------------|\n| `send`          | Send a transactional email      |\n| `list-emails`   | List recently sent emails       |\n| `get-email`     | Get details of a specific email |\n| `list-domains`  | List verified sending domains   |\n| `list-api-keys` | List API keys for the account   |\n\n## Usage\n```bash\nexport RESEND_API_KEY=\"re_your_api_key\"\npython3 scripts/resend_email.py send --from \"you@example.com\" --to \"user@example.com\" --subject \"Hello\" --html \"<h1>Hi</h1>\"\npython3 scripts/resend_email.py list-emails\npython3 scripts/resend_email.py get-email --email-id \"email_123\"\npython3 scripts/resend_email.py list-domains\npython3 scripts/resend_email.py list-api-keys\n```"
            },
            {
              "slug": "pagerduty-incident",
              "name": "pagerduty-incident",
              "id": "OC-0079",
              "version": "1.0.0",
              "description": "PagerDuty Incident Creator - Open and escalate incidents from monitoring triggers",
              "commands": [
                "create-incident",
                "list-incidents",
                "get-incident",
                "acknowledge",
                "resolve"
              ],
              "env": [
                "PAGERDUTY_API_KEY",
                "PAGERDUTY_FROM_EMAIL"
              ],
              "path": "system-integrations/communication/pagerduty-incident",
              "markdownBody": "# PagerDuty Incident Creator\n\nOpen and escalate PagerDuty incidents from monitoring triggers.\n\n## Prerequisites\n\n- `PAGERDUTY_API_KEY` â€“ PagerDuty REST API key.\n- `PAGERDUTY_FROM_EMAIL` â€“ Email address of the user making changes.\n\n## Commands\n\n| Command            | Description                              |\n|--------------------|------------------------------------------|\n| `create-incident`  | Create a new incident on a service       |\n| `list-incidents`   | List incidents with optional status filter |\n| `get-incident`     | Get details for a specific incident      |\n| `acknowledge`      | Acknowledge an incident                  |\n| `resolve`          | Resolve an incident                      |\n\n## Usage\n\n```bash\nexport PAGERDUTY_API_KEY=\"your-api-key\"\nexport PAGERDUTY_FROM_EMAIL=\"user@example.com\"\npython3 scripts/pagerduty_incident.py create-incident --title \"High CPU usage\" --service-id P000000 --urgency high --details \"CPU > 95% for 10 min\"\npython3 scripts/pagerduty_incident.py list-incidents --status triggered\npython3 scripts/pagerduty_incident.py get-incident --incident-id Q1234567890\npython3 scripts/pagerduty_incident.py acknowledge --incident-id Q1234567890\npython3 scripts/pagerduty_incident.py resolve --incident-id Q1234567890\n```"
            },
            {
              "slug": "novu-notifications",
              "name": "novu-notifications",
              "id": "OC-0081",
              "version": "1.0.0",
              "description": "Novu Notification Manager â€“ Trigger and manage in-app, email, and push notifications",
              "commands": [
                "trigger",
                "list-subscribers",
                "create-subscriber",
                "list-notifications",
                "list-topics"
              ],
              "env": [
                "NOVU_API_KEY"
              ],
              "path": "system-integrations/communication/novu-notifications",
              "markdownBody": "# Novu Notification Manager\n\nTrigger and manage in-app, email, and push notifications via the Novu platform.\n\n## Prerequisites\n\n- `NOVU_API_KEY` â€“ Novu API key.\n\n## Commands\n\n| Command              | Description                              |\n|----------------------|------------------------------------------|\n| `trigger`            | Trigger a notification workflow          |\n| `list-subscribers`   | List subscribers                         |\n| `create-subscriber`  | Create a new subscriber                  |\n| `list-notifications` | List sent notifications                  |\n| `list-topics`        | List notification topics                 |\n\n## Usage\n\n```bash\nexport NOVU_API_KEY=\"your-api-key\"\npython3 scripts/novu_notifications.py trigger --workflow my-workflow --subscriber-id user123 --payload '{\"message\": \"Hello\"}'\npython3 scripts/novu_notifications.py list-subscribers --page 0\npython3 scripts/novu_notifications.py create-subscriber --subscriber-id user456 --email user@example.com --first-name Jane --last-name Doe\npython3 scripts/novu_notifications.py list-notifications --page 0\npython3 scripts/novu_notifications.py list-topics --page 0\n```"
            },
            {
              "slug": "knock-orchestrator",
              "name": "knock-orchestrator",
              "id": "OC-0080",
              "version": "1.0.0",
              "description": "Knock Notification Orchestrator - Manage multi-channel notification workflows",
              "commands": [
                "trigger-workflow",
                "list-workflows",
                "get-message",
                "list-messages",
                "identify-user"
              ],
              "env": [
                "KNOCK_API_KEY"
              ],
              "path": "system-integrations/communication/knock-orchestrator",
              "markdownBody": "# Knock Notification Orchestrator\n\nManage multi-channel notification workflows, trigger notifications, inspect messages, and identify users via the Knock API.\n\n## Prerequisites\n\n- `KNOCK_API_KEY` â€“ Knock API secret key.\n\n## Commands\n\n| Command            | Description                                  |\n|--------------------|----------------------------------------------|\n| `trigger-workflow` | Trigger a notification workflow for recipients |\n| `list-workflows`   | List available notification workflows        |\n| `get-message`      | Get details for a specific message           |\n| `list-messages`    | List messages with optional status filter    |\n| `identify-user`    | Identify or create a user in Knock           |\n\n## Usage\n\n```bash\nexport KNOCK_API_KEY=\"your-key\"\npython3 scripts/knock_orchestrator.py trigger-workflow --workflow-key welcome --recipients user-1 user-2 --data '{\"message\": \"hello\"}'\npython3 scripts/knock_orchestrator.py list-workflows\npython3 scripts/knock_orchestrator.py get-message --message-id msg_123\npython3 scripts/knock_orchestrator.py list-messages --status delivered\npython3 scripts/knock_orchestrator.py identify-user --user-id user-1 --name \"Jane Doe\" --email jane@example.com\n```"
            },
            {
              "slug": "discord-webhook",
              "name": "discord-webhook",
              "id": "OC-0078",
              "version": "1.0.0",
              "description": "Discord Webhook Notifier - Push structured alerts and messages to Discord channels via webhooks",
              "commands": [
                "send",
                "send-embed",
                "get-message",
                "edit-message",
                "delete-message"
              ],
              "env": [
                "DISCORD_WEBHOOK_URL"
              ],
              "path": "system-integrations/communication/discord-webhook",
              "markdownBody": "# Discord Webhook Notifier\n\nPush structured alerts and messages to Discord channels via webhooks.\n\n## Prerequisites\n\n- A valid `DISCORD_WEBHOOK_URL` environment variable (the full webhook URL from Discord channel settings).\n\n## Commands\n\n| Command          | Description                                  |\n|------------------|----------------------------------------------|\n| `send`           | Send a plain text message                    |\n| `send-embed`     | Send a rich embed message with fields        |\n| `get-message`    | Retrieve a webhook message by ID             |\n| `edit-message`   | Edit a previously sent webhook message       |\n| `delete-message` | Delete a previously sent webhook message     |\n\n## Usage\n\n```bash\nexport DISCORD_WEBHOOK_URL=\"https://discord.com/api/webhooks/123/abc\"\npython3 scripts/discord_webhook.py send --content \"Deployment succeeded\"\npython3 scripts/discord_webhook.py send-embed --title \"Build Status\" --description \"All checks passed\" --color \"00ff00\" --field \"Branch:main\" --field \"Duration:2m30s\"\npython3 scripts/discord_webhook.py get-message --message-id 1234567890\npython3 scripts/discord_webhook.py edit-message --message-id 1234567890 --content \"Updated message\"\npython3 scripts/discord_webhook.py delete-message --message-id 1234567890\n```"
            }
          ]
        },
        {
          "slug": "database-storage",
          "name": "Database Storage",
          "skills": [
            {
              "slug": "upstash-redis",
              "name": "upstash-redis",
              "id": null,
              "version": "1.0.0",
              "description": "Upstash Redis CLI (OC-0030). Use serverless Redis for key-value jobs. Use when user asks to get, set, or manage keys in Upstash Redis.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/upstash-redis",
              "markdownBody": "# Upstash Redis CLI\n\nUse serverless Redis for key-value operations via the Upstash REST API.\n\n## Capabilities\n\n1. **Get**: Retrieve a value by key.\n2. **Set**: Store a key-value pair.\n3. **Del**: Delete a key.\n4. **Keys**: List keys matching a pattern.\n5. **Info**: Get server information.\n6. **TTL**: Check time-to-live of a key.\n7. **Expire**: Set expiration on a key.\n\n## Quick Start\n\n```bash\n# Set a key\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py set --key mykey --value \"hello world\"\n\n# Get a key\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py get --key mykey\n\n# List keys\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py keys --pattern \"user:*\"\n\n# Set TTL\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py expire --key mykey --seconds 3600\n\n# Check TTL\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py ttl --key mykey\n\n# Delete a key\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py del --key mykey\n\n# Server info\npython3 skills/system-integrations/database-storage/upstash-redis/scripts/manage.py info\n```\n\n## Commands & Parameters\n\n### `get`\nGets the value of a key.\n- `--key`: Key name (required).\n\n### `set`\nSets a key-value pair.\n- `--key`: Key name (required).\n- `--value`: Value to store (required).\n- `--ex`: Expiration in seconds (optional).\n\n### `del`\nDeletes a key.\n- `--key`: Key name (required).\n\n### `keys`\nLists keys matching a pattern.\n- `--pattern`: Glob pattern (default: *).\n\n### `info`\nReturns server information.\n- No required parameters.\n\n### `ttl`\nGets the TTL of a key in seconds.\n- `--key`: Key name (required).\n\n### `expire`\nSets expiration on a key.\n- `--key`: Key name (required).\n- `--seconds`: TTL in seconds (required).\n\n## Dependencies\n- `UPSTASH_REDIS_URL` environment variable (Upstash Redis REST URL).\n- `UPSTASH_REDIS_TOKEN` environment variable (Upstash Redis REST token).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "upstash-kafka",
              "name": "upstash-kafka",
              "id": null,
              "version": "1.0.0",
              "description": "Upstash Kafka Producer (OC-0031). Send events to serverless Kafka topics. Use when user asks to produce or consume messages on Upstash Kafka.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/upstash-kafka",
              "markdownBody": "# Upstash Kafka Producer\n\nSend events to serverless Kafka topics and consume messages via the Upstash Kafka REST API.\n\n## Capabilities\n\n1. **List Topics**: View all Kafka topics.\n2. **Produce**: Send messages to a topic.\n3. **Consume**: Read messages from a topic.\n4. **Create Topic**: Create a new topic.\n5. **Get Topic**: Get topic details.\n\n## Quick Start\n\n```bash\n# List topics\npython3 skills/system-integrations/database-storage/upstash-kafka/scripts/manage.py list-topics\n\n# Produce a message\npython3 skills/system-integrations/database-storage/upstash-kafka/scripts/manage.py produce --topic events --message '{\"type\":\"deploy\",\"env\":\"production\"}'\n\n# Consume messages\npython3 skills/system-integrations/database-storage/upstash-kafka/scripts/manage.py consume --topic events --group my-consumer --instance inst-1\n\n# Create a topic\npython3 skills/system-integrations/database-storage/upstash-kafka/scripts/manage.py create-topic --name events --partitions 3\n\n# Get topic details\npython3 skills/system-integrations/database-storage/upstash-kafka/scripts/manage.py get-topic --topic events\n```\n\n## Commands & Parameters\n\n### `list-topics`\nLists all Kafka topics.\n- No required parameters.\n\n### `produce`\nProduces a message to a topic.\n- `--topic`: Topic name (required).\n- `--message`: Message body (required).\n- `--key`: Message key (optional).\n\n### `consume`\nConsumes messages from a topic.\n- `--topic`: Topic name (required).\n- `--group`: Consumer group name (required).\n- `--instance`: Consumer instance name (required).\n- `--timeout`: Timeout in ms (default: 5000).\n\n### `create-topic`\nCreates a new Kafka topic.\n- `--name`: Topic name (required).\n- `--partitions`: Number of partitions (default: 1).\n- `--retention-ms`: Retention period in ms (default: 604800000).\n\n### `get-topic`\nGets details of a topic.\n- `--topic`: Topic name (required).\n\n## Dependencies\n- `UPSTASH_KAFKA_URL` environment variable (Upstash Kafka REST URL).\n- `UPSTASH_KAFKA_USERNAME` environment variable.\n- `UPSTASH_KAFKA_PASSWORD` environment variable.\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "turso-edge-db",
              "name": "turso-edge-db",
              "id": null,
              "version": "1.0.0",
              "description": "Turso Edge DB Manager (OC-0036). Manage SQLite at the edge with Turso. Use when user asks to create, manage, or query Turso databases.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/turso-edge-db",
              "markdownBody": "# Turso Edge DB Manager\n\nManage SQLite databases at the edge using the Turso Platform API.\n\n## Capabilities\n\n1. **List Databases**: View all databases in the organization.\n2. **Create DB**: Create a new edge database.\n3. **Delete DB**: Remove a database.\n4. **Shell**: Execute SQL against a database.\n5. **Get Stats**: View usage statistics for a database.\n\n## Quick Start\n\n```bash\n# List databases\npython3 skills/system-integrations/database-storage/turso-edge-db/scripts/manage.py list-databases\n\n# Create a database\npython3 skills/system-integrations/database-storage/turso-edge-db/scripts/manage.py create-db --name my-edge-db --group default\n\n# Execute SQL\npython3 skills/system-integrations/database-storage/turso-edge-db/scripts/manage.py shell --database my-edge-db --sql \"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT)\"\n\n# Get stats\npython3 skills/system-integrations/database-storage/turso-edge-db/scripts/manage.py get-stats --database my-edge-db\n\n# Delete a database\npython3 skills/system-integrations/database-storage/turso-edge-db/scripts/manage.py delete-db --database my-edge-db\n```\n\n## Commands & Parameters\n\n### `list-databases`\nLists all databases in the organization.\n- No required parameters.\n\n### `create-db`\nCreates a new database.\n- `--name`: Database name (required).\n- `--group`: Group name (default: default).\n\n### `delete-db`\nDeletes a database.\n- `--database`: Database name (required).\n\n### `shell`\nExecutes SQL against a database.\n- `--database`: Database name (required).\n- `--sql`: SQL statement to execute (required).\n\n### `get-stats`\nGets usage statistics for a database.\n- `--database`: Database name (required).\n\n## Dependencies\n- `TURSO_TOKEN` environment variable (Turso API token).\n- `TURSO_ORG` environment variable (organization slug).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "supabase-table",
              "name": "supabase-table",
              "id": null,
              "version": "1.0.0",
              "description": "Supabase Table Editor (OC-0027). Run safe read/write operations on Supabase tables. Use when user asks to query, insert, update, or delete rows in Supabase.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/supabase-table",
              "markdownBody": "# Supabase Table Editor\n\nRun safe read/write operations on Supabase Postgres tables via the REST API.\n\n## Capabilities\n\n1. **List Tables**: View all tables in the database.\n2. **Query**: Read rows with filters and ordering.\n3. **Insert**: Add new rows to a table.\n4. **Update**: Modify existing rows with filters.\n5. **Delete**: Remove rows matching a filter.\n\n## Quick Start\n\n```bash\n# List all tables\npython3 skills/system-integrations/database-storage/supabase-table/scripts/manage.py list-tables\n\n# Query rows\npython3 skills/system-integrations/database-storage/supabase-table/scripts/manage.py query --table users --select \"id,name,email\" --filter \"status=eq.active\" --limit 10\n\n# Insert a row\npython3 skills/system-integrations/database-storage/supabase-table/scripts/manage.py insert --table users --data '{\"name\":\"Alice\",\"email\":\"alice@example.com\"}'\n\n# Update rows\npython3 skills/system-integrations/database-storage/supabase-table/scripts/manage.py update --table users --filter \"id=eq.5\" --data '{\"status\":\"inactive\"}'\n\n# Delete rows\npython3 skills/system-integrations/database-storage/supabase-table/scripts/manage.py delete --table users --filter \"status=eq.inactive\"\n```\n\n## Commands & Parameters\n\n### `list-tables`\nLists all tables in the public schema.\n- No required parameters.\n\n### `query`\nReads rows from a table.\n- `--table`: Table name (required).\n- `--select`: Columns to select (default: *).\n- `--filter`: PostgREST filter (e.g., status=eq.active).\n- `--order`: Order by column (e.g., created_at.desc).\n- `--limit`: Max rows (default: 50).\n\n### `insert`\nInserts a row into a table.\n- `--table`: Table name (required).\n- `--data`: JSON object with column values (required).\n\n### `update`\nUpdates rows matching a filter.\n- `--table`: Table name (required).\n- `--filter`: PostgREST filter to match rows (required).\n- `--data`: JSON object with updated values (required).\n\n### `delete`\nDeletes rows matching a filter.\n- `--table`: Table name (required).\n- `--filter`: PostgREST filter to match rows (required).\n\n## Dependencies\n- `SUPABASE_URL` environment variable (Supabase project URL).\n- `SUPABASE_SERVICE_KEY` environment variable (service role key).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "supabase-bucket",
              "name": "supabase-bucket",
              "id": null,
              "version": "1.0.0",
              "description": "Supabase Bucket Manager (OC-0026). Manage heavy media assets in Supabase Storage. Use when user asks to upload, download, or manage files in Supabase buckets.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/supabase-bucket",
              "markdownBody": "# Supabase Bucket Manager\n\nManage heavy media assets in Supabase Storage buckets.\n\n## Capabilities\n\n1. **List Buckets**: View all storage buckets in a project.\n2. **Create Bucket**: Create a new storage bucket.\n3. **List Files**: Browse files in a bucket.\n4. **Upload**: Upload files to a bucket.\n5. **Download**: Download files from a bucket.\n6. **Delete File**: Remove files from a bucket.\n\n## Quick Start\n\n```bash\n# List all buckets\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py list-buckets\n\n# Create a new bucket\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py create-bucket --name media-assets --public\n\n# List files in a bucket\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py list-files --bucket media-assets\n\n# Upload a file\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py upload --bucket media-assets --file ./image.png --path uploads/image.png\n\n# Download a file\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py download --bucket media-assets --path uploads/image.png --output ./downloaded.png\n\n# Delete a file\npython3 skills/system-integrations/database-storage/supabase-bucket/scripts/manage.py delete-file --bucket media-assets --path uploads/image.png\n```\n\n## Commands & Parameters\n\n### `list-buckets`\nLists all storage buckets.\n- No required parameters.\n\n### `create-bucket`\nCreates a new storage bucket.\n- `--name`: Bucket name (required).\n- `--public`: Make bucket public (flag).\n\n### `list-files`\nLists files in a bucket.\n- `--bucket`: Bucket name (required).\n- `--prefix`: Path prefix to filter files.\n- `--limit`: Max results (default: 100).\n\n### `upload`\nUploads a local file to a bucket.\n- `--bucket`: Bucket name (required).\n- `--file`: Local file path (required).\n- `--path`: Destination path in bucket (required).\n\n### `download`\nDownloads a file from a bucket.\n- `--bucket`: Bucket name (required).\n- `--path`: File path in bucket (required).\n- `--output`: Local output path (required).\n\n### `delete-file`\nDeletes a file from a bucket.\n- `--bucket`: Bucket name (required).\n- `--path`: File path in bucket (required).\n\n## Dependencies\n- `SUPABASE_URL` environment variable (Supabase project URL).\n- `SUPABASE_SERVICE_KEY` environment variable (service role key).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "planetscale-inspector",
              "name": "planetscale-inspector",
              "id": null,
              "version": "1.0.0",
              "description": "PlanetScale Schema Inspector (OC-0028). Check migrations and schema diffs on PlanetScale. Use when user asks to inspect PlanetScale schemas, branches, or deploy requests.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/planetscale-inspector",
              "markdownBody": "# PlanetScale Schema Inspector\n\nCheck migrations and schema diffs on PlanetScale MySQL databases.\n\n## Capabilities\n\n1. **List Databases**: View all databases in the organization.\n2. **List Branches**: View database branches.\n3. **Get Schema**: Retrieve the schema for a branch.\n4. **Create Deploy Request**: Open a deploy request for schema changes.\n5. **Diff**: Compare schemas between two branches.\n\n## Quick Start\n\n```bash\n# List databases\npython3 skills/system-integrations/database-storage/planetscale-inspector/scripts/manage.py list-databases\n\n# List branches\npython3 skills/system-integrations/database-storage/planetscale-inspector/scripts/manage.py list-branches --database mydb\n\n# Get schema\npython3 skills/system-integrations/database-storage/planetscale-inspector/scripts/manage.py get-schema --database mydb --branch main\n\n# Create a deploy request\npython3 skills/system-integrations/database-storage/planetscale-inspector/scripts/manage.py create-deploy-request --database mydb --branch feature-xyz --into main\n\n# Diff branches\npython3 skills/system-integrations/database-storage/planetscale-inspector/scripts/manage.py diff --database mydb --branch feature-xyz --base main\n```\n\n## Commands & Parameters\n\n### `list-databases`\nLists all databases in the organization.\n- No required parameters.\n\n### `list-branches`\nLists branches for a database.\n- `--database`: Database name (required).\n\n### `get-schema`\nGets the schema for a branch.\n- `--database`: Database name (required).\n- `--branch`: Branch name (required).\n\n### `create-deploy-request`\nCreates a deploy request.\n- `--database`: Database name (required).\n- `--branch`: Source branch (required).\n- `--into`: Target branch (required).\n\n### `diff`\nShows schema diff between two branches.\n- `--database`: Database name (required).\n- `--branch`: Source branch (required).\n- `--base`: Base branch to compare against (required).\n\n## Dependencies\n- `PLANETSCALE_TOKEN` environment variable (PlanetScale service token).\n- `PLANETSCALE_ORG` environment variable (organization name).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "neon-branch-manager",
              "name": "neon-branch-manager",
              "id": null,
              "version": "1.0.0",
              "description": "Neon Branch Manager (OC-0025). Create instant Postgres branches for every PR. Use when user asks to manage Neon database branches, create dev branches, or list endpoints.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/neon-branch-manager",
              "markdownBody": "# Neon Branch Manager\n\nCreate and manage instant Postgres branches on Neon for every pull request or development environment.\n\n## Capabilities\n\n1. **List Branches**: View all branches in a Neon project.\n2. **Create Branch**: Spin up an instant Postgres branch from any parent.\n3. **Delete Branch**: Remove branches that are no longer needed.\n4. **Get Branch**: Inspect details of a specific branch.\n5. **List Endpoints**: View compute endpoints associated with branches.\n\n## Quick Start\n\n```bash\n# List all branches\npython3 skills/system-integrations/database-storage/neon-branch-manager/scripts/manage.py list-branches\n\n# Create a branch for a PR\npython3 skills/system-integrations/database-storage/neon-branch-manager/scripts/manage.py create-branch --name pr-42-preview\n\n# Get branch details\npython3 skills/system-integrations/database-storage/neon-branch-manager/scripts/manage.py get-branch --branch-id br-abc123\n\n# Delete a branch\npython3 skills/system-integrations/database-storage/neon-branch-manager/scripts/manage.py delete-branch --branch-id br-abc123\n\n# List endpoints\npython3 skills/system-integrations/database-storage/neon-branch-manager/scripts/manage.py list-endpoints\n```\n\n## Commands & Parameters\n\n### `list-branches`\nLists all branches in the Neon project.\n- No required parameters.\n\n### `create-branch`\nCreates a new database branch.\n- `--name`: Name for the new branch (required).\n- `--parent-id`: Parent branch ID (default: primary branch).\n\n### `delete-branch`\nDeletes a branch by ID.\n- `--branch-id`: Branch ID to delete (required).\n\n### `get-branch`\nGets details for a specific branch.\n- `--branch-id`: Branch ID (required).\n\n### `list-endpoints`\nLists compute endpoints for the project.\n- No required parameters.\n\n## Dependencies\n- `NEON_API_KEY` environment variable (Neon API key).\n- `NEON_PROJECT_ID` environment variable (Neon project ID).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "mongodb-monitor",
              "name": "mongodb-monitor",
              "id": null,
              "version": "1.0.0",
              "description": "MongoDB Atlas Cluster Monitor (OC-0029). Check connections and slow queries on MongoDB Atlas. Use when user asks to monitor MongoDB clusters, check metrics, or find slow queries.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/mongodb-monitor",
              "markdownBody": "# MongoDB Atlas Cluster Monitor\n\nCheck connections, metrics, and slow queries on MongoDB Atlas clusters.\n\n## Capabilities\n\n1. **List Clusters**: View all clusters in a project.\n2. **Get Metrics**: Retrieve cluster performance metrics.\n3. **Slow Queries**: Identify slow-running queries.\n4. **List Databases**: View databases in a cluster.\n5. **Get Alerts**: Check active alerts for the project.\n\n## Quick Start\n\n```bash\n# List clusters\npython3 skills/system-integrations/database-storage/mongodb-monitor/scripts/manage.py list-clusters\n\n# Get cluster metrics\npython3 skills/system-integrations/database-storage/mongodb-monitor/scripts/manage.py get-metrics --cluster myCluster --period PT1H\n\n# Find slow queries\npython3 skills/system-integrations/database-storage/mongodb-monitor/scripts/manage.py slow-queries --cluster myCluster\n\n# List databases\npython3 skills/system-integrations/database-storage/mongodb-monitor/scripts/manage.py list-databases --cluster myCluster\n\n# Get alerts\npython3 skills/system-integrations/database-storage/mongodb-monitor/scripts/manage.py get-alerts\n```\n\n## Commands & Parameters\n\n### `list-clusters`\nLists all clusters in the Atlas project.\n- No required parameters.\n\n### `get-metrics`\nGets performance metrics for a cluster.\n- `--cluster`: Cluster name (required).\n- `--metric`: Metric name (default: CONNECTIONS).\n- `--period`: Time period in ISO 8601 (default: PT1H).\n- `--granularity`: Data granularity (default: PT5M).\n\n### `slow-queries`\nLists slow queries on a cluster.\n- `--cluster`: Cluster name (required).\n- `--duration`: Min duration in ms (default: 100).\n\n### `list-databases`\nLists databases in a cluster.\n- `--cluster`: Cluster name (required).\n\n### `get-alerts`\nGets active alerts for the project.\n- No required parameters.\n\n## Dependencies\n- `MONGODB_PUBLIC_KEY` environment variable (Atlas public API key).\n- `MONGODB_PRIVATE_KEY` environment variable (Atlas private API key).\n- `MONGODB_GROUP_ID` environment variable (Atlas project/group ID).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "firebase-firestore",
              "name": "firebase-firestore",
              "id": null,
              "version": "1.0.0",
              "description": "Firebase Firestore Admin (OC-0033). Read/Write Firestore documents. Use when user asks to manage Firestore collections, documents, or queries.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/firebase-firestore",
              "markdownBody": "# Firebase Firestore Admin\n\nRead and write documents in Google Cloud Firestore via the REST API.\n\n## Capabilities\n\n1. **List Collections**: View top-level collections.\n2. **Get Document**: Read a specific document.\n3. **Set Document**: Create or overwrite a document.\n4. **Delete Document**: Remove a document.\n5. **Query**: Query documents in a collection with filters.\n\n## Quick Start\n\n```bash\n# List collections\npython3 skills/system-integrations/database-storage/firebase-firestore/scripts/manage.py list-collections --project my-project\n\n# Get a document\npython3 skills/system-integrations/database-storage/firebase-firestore/scripts/manage.py get-doc --project my-project --collection users --doc user-123\n\n# Set a document\npython3 skills/system-integrations/database-storage/firebase-firestore/scripts/manage.py set-doc --project my-project --collection users --doc user-456 --data '{\"name\":\"Alice\",\"role\":\"admin\"}'\n\n# Delete a document\npython3 skills/system-integrations/database-storage/firebase-firestore/scripts/manage.py delete-doc --project my-project --collection users --doc user-123\n\n# Query a collection\npython3 skills/system-integrations/database-storage/firebase-firestore/scripts/manage.py query --project my-project --collection users --field role --op EQUAL --value admin\n```\n\n## Commands & Parameters\n\n### `list-collections`\nLists top-level collections.\n- `--project`: GCP project ID (required).\n\n### `get-doc`\nGets a document by path.\n- `--project`: GCP project ID (required).\n- `--collection`: Collection name (required).\n- `--doc`: Document ID (required).\n\n### `set-doc`\nCreates or overwrites a document.\n- `--project`: GCP project ID (required).\n- `--collection`: Collection name (required).\n- `--doc`: Document ID (required).\n- `--data`: JSON data for the document (required).\n\n### `delete-doc`\nDeletes a document.\n- `--project`: GCP project ID (required).\n- `--collection`: Collection name (required).\n- `--doc`: Document ID (required).\n\n### `query`\nQueries a collection.\n- `--project`: GCP project ID (required).\n- `--collection`: Collection name (required).\n- `--field`: Field to filter on (required).\n- `--op`: Comparison operator (EQUAL, LESS_THAN, GREATER_THAN, etc.) (required).\n- `--value`: Filter value (required).\n- `--limit`: Max results (default: 20).\n\n## Dependencies\n- `GOOGLE_APPLICATION_CREDENTIALS` environment variable (path to service account JSON).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "dynamodb-browser",
              "name": "dynamodb-browser",
              "id": null,
              "version": "1.0.0",
              "description": "DynamoDB Item Browser (OC-0032). Query NoSQL data efficiently using the AWS CLI. Use when user asks to browse, query, or manage items in DynamoDB tables.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/dynamodb-browser",
              "markdownBody": "# DynamoDB Item Browser\n\nQuery and manage NoSQL data in AWS DynamoDB efficiently using the AWS CLI.\n\n## Capabilities\n\n1. **List Tables**: View all DynamoDB tables.\n2. **Scan**: Scan a table for items.\n3. **Query**: Query items by partition key.\n4. **Get Item**: Retrieve a specific item by key.\n5. **Put Item**: Write an item to a table.\n6. **Delete Item**: Remove an item by key.\n\n## Quick Start\n\n```bash\n# List tables\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py list-tables\n\n# Scan a table\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py scan --table Users --limit 10\n\n# Query by partition key\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py query --table Users --key-condition \"userId = :uid\" --values '{\":uid\":{\"S\":\"user-123\"}}'\n\n# Get a specific item\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py get-item --table Users --key '{\"userId\":{\"S\":\"user-123\"}}'\n\n# Put an item\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py put-item --table Users --item '{\"userId\":{\"S\":\"user-456\"},\"name\":{\"S\":\"Alice\"}}'\n\n# Delete an item\npython3 skills/system-integrations/database-storage/dynamodb-browser/scripts/manage.py delete-item --table Users --key '{\"userId\":{\"S\":\"user-123\"}}'\n```\n\n## Commands & Parameters\n\n### `list-tables`\nLists all DynamoDB tables in the account.\n- `--region`: AWS region (optional, uses default).\n\n### `scan`\nScans a table.\n- `--table`: Table name (required).\n- `--limit`: Max items (default: 25).\n- `--region`: AWS region (optional).\n\n### `query`\nQueries items by key condition.\n- `--table`: Table name (required).\n- `--key-condition`: Key condition expression (required).\n- `--values`: Expression attribute values as JSON (required).\n- `--region`: AWS region (optional).\n\n### `get-item`\nGets a single item by key.\n- `--table`: Table name (required).\n- `--key`: Key as JSON (required).\n- `--region`: AWS region (optional).\n\n### `put-item`\nWrites an item to a table.\n- `--table`: Table name (required).\n- `--item`: Item as JSON (required).\n- `--region`: AWS region (optional).\n\n### `delete-item`\nDeletes an item by key.\n- `--table`: Table name (required).\n- `--key`: Key as JSON (required).\n- `--region`: AWS region (optional).\n\n## Dependencies\n- AWS CLI v2 installed and configured (`aws configure`).\n- Appropriate IAM permissions for DynamoDB operations."
            },
            {
              "slug": "cockroachdb-runner",
              "name": "cockroachdb-runner",
              "id": null,
              "version": "1.0.0",
              "description": "CockroachDB Query Runner (OC-0035). Execute distributed SQL queries on CockroachDB. Use when user asks to run SQL, list databases, or describe tables in CockroachDB.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/cockroachdb-runner",
              "markdownBody": "# CockroachDB Query Runner\n\nExecute distributed SQL queries on CockroachDB clusters.\n\n## Capabilities\n\n1. **Query**: Run a SELECT query and display results.\n2. **List Databases**: Show all databases.\n3. **List Tables**: Show tables in a database.\n4. **Describe**: Describe a table schema.\n5. **Execute**: Run DDL/DML statements (INSERT, UPDATE, CREATE, etc.).\n\n## Quick Start\n\n```bash\n# List databases\npython3 skills/system-integrations/database-storage/cockroachdb-runner/scripts/manage.py list-databases\n\n# List tables\npython3 skills/system-integrations/database-storage/cockroachdb-runner/scripts/manage.py list-tables --database defaultdb\n\n# Describe a table\npython3 skills/system-integrations/database-storage/cockroachdb-runner/scripts/manage.py describe --table users\n\n# Run a query\npython3 skills/system-integrations/database-storage/cockroachdb-runner/scripts/manage.py query --sql \"SELECT * FROM users LIMIT 10\"\n\n# Execute a statement\npython3 skills/system-integrations/database-storage/cockroachdb-runner/scripts/manage.py execute --sql \"INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com')\"\n```\n\n## Commands & Parameters\n\n### `query`\nRuns a SELECT query.\n- `--sql`: SQL query string (required).\n\n### `list-databases`\nLists all databases.\n- No required parameters.\n\n### `list-tables`\nLists tables in a database.\n- `--database`: Database name (default: defaultdb).\n\n### `describe`\nDescribes a table schema.\n- `--table`: Table name (required).\n\n### `execute`\nExecutes a DDL/DML statement.\n- `--sql`: SQL statement (required).\n\n## Dependencies\n- `COCKROACH_URL` environment variable (CockroachDB connection string, e.g., `postgresql://user:pass@host:26257/defaultdb?sslmode=verify-full`).\n- Python `psycopg2` library (`pip install psycopg2-binary`)."
            },
            {
              "slug": "airtable-sync",
              "name": "airtable-sync",
              "id": null,
              "version": "1.0.0",
              "description": "Airtable Record Sync (OC-0034). Treat Airtable as a lightweight CMS/DB. Use when user asks to list, create, update, or delete records in Airtable.",
              "commands": [],
              "env": [],
              "path": "system-integrations/database-storage/airtable-sync",
              "markdownBody": "# Airtable Record Sync\n\nTreat Airtable as a lightweight CMS/DB for managing structured records.\n\n## Capabilities\n\n1. **List Bases**: View accessible Airtable bases.\n2. **List Records**: Browse records in a table.\n3. **Create Record**: Add a new record to a table.\n4. **Update Record**: Modify an existing record.\n5. **Delete Record**: Remove a record.\n\n## Quick Start\n\n```bash\n# List bases\npython3 skills/system-integrations/database-storage/airtable-sync/scripts/manage.py list-bases\n\n# List records\npython3 skills/system-integrations/database-storage/airtable-sync/scripts/manage.py list-records --table Tasks --max-records 10\n\n# Create a record\npython3 skills/system-integrations/database-storage/airtable-sync/scripts/manage.py create-record --table Tasks --fields '{\"Name\":\"Fix bug\",\"Status\":\"Todo\"}'\n\n# Update a record\npython3 skills/system-integrations/database-storage/airtable-sync/scripts/manage.py update-record --table Tasks --record-id rec123 --fields '{\"Status\":\"Done\"}'\n\n# Delete a record\npython3 skills/system-integrations/database-storage/airtable-sync/scripts/manage.py delete-record --table Tasks --record-id rec123\n```\n\n## Commands & Parameters\n\n### `list-bases`\nLists all accessible Airtable bases.\n- No required parameters.\n\n### `list-records`\nLists records in a table.\n- `--table`: Table name (required).\n- `--view`: View name (optional).\n- `--max-records`: Max records to return (default: 50).\n- `--formula`: Filter formula (optional).\n\n### `create-record`\nCreates a new record.\n- `--table`: Table name (required).\n- `--fields`: JSON object with field values (required).\n\n### `update-record`\nUpdates an existing record.\n- `--table`: Table name (required).\n- `--record-id`: Record ID (required).\n- `--fields`: JSON object with updated field values (required).\n\n### `delete-record`\nDeletes a record.\n- `--table`: Table name (required).\n- `--record-id`: Record ID (required).\n\n## Dependencies\n- `AIRTABLE_API_KEY` environment variable (Airtable personal access token).\n- `AIRTABLE_BASE_ID` environment variable (base ID, e.g., appXXXXXXXXXXXX).\n- Python `requests` library (`pip install requests`)."
            }
          ]
        },
        {
          "slug": "deployment",
          "name": "Deployment",
          "skills": [
            {
              "slug": "vercel-deployer",
              "name": "vercel-deployer",
              "id": "OC-0009",
              "version": "1.0.0",
              "description": "Vercel Deployment Manager - Trigger builds, manage env vars, alias domains",
              "commands": [
                "list-projects",
                "deploy",
                "list-deployments",
                "set-env",
                "alias-domain"
              ],
              "env": [
                "VERCEL_TOKEN"
              ],
              "path": "system-integrations/deployment/vercel-deployer",
              "markdownBody": "# Vercel Deployment Manager\n\nManage Vercel projects, deployments, environment variables, and domain aliases.\n\n## Prerequisites\n\n- A valid `VERCEL_TOKEN` environment variable.\n\n## Commands\n\n| Command            | Description                        |\n|--------------------|------------------------------------|\n| `list-projects`    | List all Vercel projects           |\n| `deploy`           | Trigger a new deployment           |\n| `list-deployments` | List recent deployments            |\n| `set-env`          | Set an environment variable        |\n| `alias-domain`     | Assign a domain alias to a deploy  |\n\n## Usage\n\n```bash\nexport VERCEL_TOKEN=\"your-token\"\npython3 scripts/vercel_deployer.py list-projects\npython3 scripts/vercel_deployer.py deploy --project my-app\npython3 scripts/vercel_deployer.py set-env --project my-app --key DB_URL --value \"postgres://...\"\npython3 scripts/vercel_deployer.py alias-domain --deployment-id dpl_xxx --domain app.example.com\n```"
            },
            {
              "slug": "render-manager",
              "name": "render-manager",
              "id": "OC-0012",
              "version": "1.0.0",
              "description": "Render Service Manager - Scale services up/down",
              "commands": [
                "list-services",
                "get-service",
                "scale",
                "restart",
                "get-deploys"
              ],
              "env": [
                "RENDER_API_KEY"
              ],
              "path": "system-integrations/deployment/render-manager",
              "markdownBody": "# Render Service Manager\n\nManage Render services, scaling, restarts, and deployments.\n\n## Prerequisites\n\n- A valid `RENDER_API_KEY` environment variable.\n\n## Commands\n\n| Command         | Description                        |\n|-----------------|------------------------------------|\n| `list-services` | List all Render services           |\n| `get-service`   | Get details of a specific service  |\n| `scale`         | Scale a service instance count     |\n| `restart`       | Restart a service                  |\n| `get-deploys`   | List recent deploys for a service  |\n\n## Usage\n\n```bash\nexport RENDER_API_KEY=\"your-key\"\npython3 scripts/render_manager.py list-services\npython3 scripts/render_manager.py scale --service-id srv-xxx --num-instances 3\npython3 scripts/render_manager.py restart --service-id srv-xxx\n```"
            },
            {
              "slug": "railway-deployer",
              "name": "railway-deployer",
              "id": "OC-0011",
              "version": "1.0.0",
              "description": "Railway Project Deployer - Spin up new service instances",
              "commands": [
                "list-projects",
                "deploy",
                "list-services",
                "get-logs",
                "set-variable"
              ],
              "env": [
                "RAILWAY_TOKEN"
              ],
              "path": "system-integrations/deployment/railway-deployer",
              "markdownBody": "# Railway Project Deployer\n\nManage Railway projects, services, deployments, and environment variables.\n\n## Prerequisites\n\n- A valid `RAILWAY_TOKEN` environment variable.\n\n## Commands\n\n| Command          | Description                        |\n|------------------|------------------------------------|\n| `list-projects`  | List all Railway projects          |\n| `deploy`         | Trigger a new deployment           |\n| `list-services`  | List services in a project         |\n| `get-logs`       | Fetch deployment logs              |\n| `set-variable`   | Set an environment variable        |\n\n## Usage\n\n```bash\nexport RAILWAY_TOKEN=\"your-token\"\npython3 scripts/railway_deployer.py list-projects\npython3 scripts/railway_deployer.py deploy --project-id xxx --service-id yyy\npython3 scripts/railway_deployer.py set-variable --project-id xxx --name KEY --value val\n```"
            },
            {
              "slug": "netlify-controller",
              "name": "netlify-controller",
              "id": "OC-0010",
              "version": "1.0.0",
              "description": "Netlify Site Controller - Manage redirects, forms, split testing",
              "commands": [
                "list-sites",
                "deploy",
                "get-site",
                "list-forms",
                "list-submissions"
              ],
              "env": [
                "NETLIFY_TOKEN"
              ],
              "path": "system-integrations/deployment/netlify-controller",
              "markdownBody": "# Netlify Site Controller\n\nControl Netlify sites, deployments, forms, and form submissions.\n\n## Prerequisites\n\n- A valid `NETLIFY_TOKEN` environment variable.\n\n## Commands\n\n| Command            | Description                        |\n|--------------------|------------------------------------|\n| `list-sites`       | List all Netlify sites             |\n| `deploy`           | Trigger a new site deploy          |\n| `get-site`         | Get details of a specific site     |\n| `list-forms`       | List forms for a site              |\n| `list-submissions` | List form submissions              |\n\n## Usage\n\n```bash\nexport NETLIFY_TOKEN=\"your-token\"\npython3 scripts/netlify_controller.py list-sites\npython3 scripts/netlify_controller.py deploy --site-id abc123\npython3 scripts/netlify_controller.py list-forms --site-id abc123\n```"
            },
            {
              "slug": "iac-runner",
              "name": "iac-runner",
              "id": "OC-0024",
              "version": "1.0.0",
              "description": "Pulumi/Terraform Runner - Execute IaC plans",
              "commands": [
                "init",
                "plan",
                "apply",
                "destroy",
                "list-stacks"
              ],
              "env": [],
              "path": "system-integrations/deployment/iac-runner",
              "markdownBody": "# Pulumi/Terraform Runner\n\nRun Infrastructure-as-Code operations using Terraform or Pulumi.\n\n## Prerequisites\n\n- `terraform` and/or `pulumi` CLI installed.\n\n## Commands\n\n| Command       | Description                          |\n|---------------|--------------------------------------|\n| `init`        | Initialize the IaC workspace         |\n| `plan`        | Preview changes                      |\n| `apply`       | Apply changes                        |\n| `destroy`     | Tear down resources                  |\n| `list-stacks` | List stacks (Pulumi) or workspaces   |\n\n## Usage\n\n```bash\npython3 scripts/iac_runner.py --tool terraform init --dir ./infra\npython3 scripts/iac_runner.py --tool terraform plan --dir ./infra\npython3 scripts/iac_runner.py --tool pulumi list-stacks\npython3 scripts/iac_runner.py --tool terraform apply --dir ./infra --auto-approve\n```"
            },
            {
              "slug": "heroku-scaler",
              "name": "heroku-scaler",
              "id": "OC-0020",
              "version": "1.0.0",
              "description": "Heroku Dyno Scaler - Adjust resources dynamically",
              "commands": [
                "list-apps",
                "scale",
                "restart",
                "get-logs",
                "list-dynos"
              ],
              "env": [
                "HEROKU_API_KEY"
              ],
              "path": "system-integrations/deployment/heroku-scaler",
              "markdownBody": "# Heroku Dyno Scaler\n\nManage Heroku apps, scale dynos, restart, and fetch logs.\n\n## Prerequisites\n\n- `HEROKU_API_KEY` environment variable or `heroku` CLI authenticated.\n\n## Commands\n\n| Command       | Description                          |\n|---------------|--------------------------------------|\n| `list-apps`   | List all Heroku apps                 |\n| `scale`       | Scale dynos for an app               |\n| `restart`     | Restart app dynos                    |\n| `get-logs`    | Fetch recent app logs                |\n| `list-dynos`  | List running dynos                   |\n\n## Usage\n\n```bash\nexport HEROKU_API_KEY=\"your-key\"\npython3 scripts/heroku_scaler.py list-apps\npython3 scripts/heroku_scaler.py scale --app my-app --type web --qty 2\npython3 scripts/heroku_scaler.py get-logs --app my-app --lines 100\n```"
            },
            {
              "slug": "gcloud-storage",
              "name": "gcloud-storage",
              "id": "OC-0017",
              "version": "1.0.0",
              "description": "Google Cloud Storage Manager - Manage buckets and lifecycle",
              "commands": [
                "list-buckets",
                "list-objects",
                "upload",
                "download",
                "set-lifecycle"
              ],
              "env": [
                "GOOGLE_CLOUD_PROJECT"
              ],
              "path": "system-integrations/deployment/gcloud-storage",
              "markdownBody": "# Google Cloud Storage Manager\n\nManage GCS buckets, objects, and lifecycle policies.\n\n## Prerequisites\n\n- `gcloud`/`gsutil` CLI authenticated and `GOOGLE_CLOUD_PROJECT` set.\n\n## Commands\n\n| Command         | Description                          |\n|-----------------|--------------------------------------|\n| `list-buckets`  | List all GCS buckets                 |\n| `list-objects`  | List objects in a bucket             |\n| `upload`        | Upload a file to GCS                 |\n| `download`      | Download an object from GCS          |\n| `set-lifecycle` | Set bucket lifecycle rules           |\n\n## Usage\n\n```bash\nexport GOOGLE_CLOUD_PROJECT=\"my-project\"\npython3 scripts/gcloud_storage.py list-buckets\npython3 scripts/gcloud_storage.py upload --bucket my-bucket --file ./data.csv --dest data/data.csv\npython3 scripts/gcloud_storage.py set-lifecycle --bucket my-bucket --rules lifecycle.json\n```"
            },
            {
              "slug": "gcloud-run",
              "name": "gcloud-run",
              "id": "OC-0016",
              "version": "1.0.0",
              "description": "Google Cloud Run Deployer - Deploy containerized apps",
              "commands": [
                "list-services",
                "deploy",
                "describe",
                "set-env",
                "get-logs"
              ],
              "env": [
                "GOOGLE_CLOUD_PROJECT"
              ],
              "path": "system-integrations/deployment/gcloud-run",
              "markdownBody": "# Google Cloud Run Deployer\n\nDeploy, manage, and monitor Cloud Run services.\n\n## Prerequisites\n\n- `gcloud` CLI authenticated and `GOOGLE_CLOUD_PROJECT` set.\n\n## Commands\n\n| Command         | Description                          |\n|-----------------|--------------------------------------|\n| `list-services` | List all Cloud Run services          |\n| `deploy`        | Deploy a container image             |\n| `describe`      | Describe a specific service          |\n| `set-env`       | Update environment variables         |\n| `get-logs`      | Fetch service logs                   |\n\n## Usage\n\n```bash\nexport GOOGLE_CLOUD_PROJECT=\"my-project\"\npython3 scripts/gcloud_run.py list-services --region us-central1\npython3 scripts/gcloud_run.py deploy --service my-svc --image gcr.io/proj/img:latest --region us-central1\n```"
            },
            {
              "slug": "flyio-manager",
              "name": "flyio-manager",
              "id": "OC-0023",
              "version": "1.0.0",
              "description": "Fly.io App Manager - Deploy and scale apps globally",
              "commands": [
                "list-apps",
                "deploy",
                "scale",
                "get-status",
                "list-regions"
              ],
              "env": [],
              "path": "system-integrations/deployment/flyio-manager",
              "markdownBody": "# Fly.io App Manager\n\nDeploy, scale, and manage Fly.io applications across global regions.\n\n## Prerequisites\n\n- `flyctl` CLI installed and authenticated (`fly auth login`).\n\n## Commands\n\n| Command        | Description                          |\n|----------------|--------------------------------------|\n| `list-apps`    | List all Fly.io apps                 |\n| `deploy`       | Deploy the current app               |\n| `scale`        | Scale VM count/size                  |\n| `get-status`   | Get app status and allocations       |\n| `list-regions` | List available Fly.io regions        |\n\n## Usage\n\n```bash\npython3 scripts/flyio_manager.py list-apps\npython3 scripts/flyio_manager.py deploy --app my-app\npython3 scripts/flyio_manager.py scale --app my-app --count 3 --vm-size shared-cpu-1x\n```"
            },
            {
              "slug": "digitalocean-droplet",
              "name": "digitalocean-droplet",
              "id": "OC-0022",
              "version": "1.0.0",
              "description": "DigitalOcean Droplet Sniper - Create short-lived VPS",
              "commands": [
                "list-droplets",
                "create",
                "destroy",
                "get-droplet",
                "list-snapshots"
              ],
              "env": [
                "DIGITALOCEAN_TOKEN"
              ],
              "path": "system-integrations/deployment/digitalocean-droplet",
              "markdownBody": "# DigitalOcean Droplet Sniper\n\nCreate, manage, and destroy DigitalOcean droplets.\n\n## Prerequisites\n\n- A valid `DIGITALOCEAN_TOKEN` environment variable.\n\n## Commands\n\n| Command          | Description                          |\n|------------------|--------------------------------------|\n| `list-droplets`  | List all droplets                    |\n| `create`         | Create a new droplet                 |\n| `destroy`        | Destroy a droplet                    |\n| `get-droplet`    | Get droplet details                  |\n| `list-snapshots` | List available snapshots             |\n\n## Usage\n\n```bash\nexport DIGITALOCEAN_TOKEN=\"your-token\"\npython3 scripts/digitalocean_droplet.py list-droplets\npython3 scripts/digitalocean_droplet.py create --name temp-box --region nyc3 --size s-1vcpu-1gb --image ubuntu-22-04-x64\npython3 scripts/digitalocean_droplet.py destroy --droplet-id 123456\n```"
            },
            {
              "slug": "cloudflare-workers",
              "name": "cloudflare-workers",
              "id": "OC-0018",
              "version": "1.0.0",
              "description": "Cloudflare Worker Manager - Update edge scripts",
              "commands": [
                "list-workers",
                "deploy",
                "get-worker",
                "delete",
                "tail-logs"
              ],
              "env": [
                "CLOUDFLARE_API_TOKEN",
                "CLOUDFLARE_ACCOUNT_ID"
              ],
              "path": "system-integrations/deployment/cloudflare-workers",
              "markdownBody": "# Cloudflare Worker Manager\n\nManage Cloudflare Workers â€“ deploy, inspect, delete, and tail logs.\n\n## Prerequisites\n\n- `CLOUDFLARE_API_TOKEN` and `CLOUDFLARE_ACCOUNT_ID` environment variables.\n\n## Commands\n\n| Command        | Description                          |\n|----------------|--------------------------------------|\n| `list-workers` | List all Workers scripts             |\n| `deploy`       | Upload/update a Worker script        |\n| `get-worker`   | Get Worker script metadata           |\n| `delete`       | Delete a Worker                      |\n| `tail-logs`    | Tail Worker logs in real time        |\n\n## Usage\n\n```bash\nexport CLOUDFLARE_API_TOKEN=\"your-token\"\nexport CLOUDFLARE_ACCOUNT_ID=\"your-account-id\"\npython3 scripts/cloudflare_workers.py list-workers\npython3 scripts/cloudflare_workers.py deploy --name my-worker --script worker.js\npython3 scripts/cloudflare_workers.py tail-logs --name my-worker\n```"
            },
            {
              "slug": "cloudflare-dns",
              "name": "cloudflare-dns",
              "id": "OC-0019",
              "version": "1.0.0",
              "description": "Cloudflare DNS Manager - Update records programmatically",
              "commands": [
                "list-zones",
                "list-records",
                "create-record",
                "update-record",
                "delete-record"
              ],
              "env": [
                "CLOUDFLARE_API_TOKEN"
              ],
              "path": "system-integrations/deployment/cloudflare-dns",
              "markdownBody": "# Cloudflare DNS Manager\n\nManage DNS zones and records via the Cloudflare API.\n\n## Prerequisites\n\n- A valid `CLOUDFLARE_API_TOKEN` environment variable.\n\n## Commands\n\n| Command         | Description                          |\n|-----------------|--------------------------------------|\n| `list-zones`    | List all DNS zones                   |\n| `list-records`  | List records in a zone               |\n| `create-record` | Create a new DNS record              |\n| `update-record` | Update an existing DNS record        |\n| `delete-record` | Delete a DNS record                  |\n\n## Usage\n\n```bash\nexport CLOUDFLARE_API_TOKEN=\"your-token\"\npython3 scripts/cloudflare_dns.py list-zones\npython3 scripts/cloudflare_dns.py create-record --zone-id xxx --type A --name sub.example.com --content 1.2.3.4\npython3 scripts/cloudflare_dns.py update-record --zone-id xxx --record-id yyy --content 5.6.7.8\n```"
            },
            {
              "slug": "azure-resources",
              "name": "azure-resources",
              "id": "OC-0021",
              "version": "1.0.0",
              "description": "Azure Resource Manager - List and audit resource groups",
              "commands": [
                "list-groups",
                "list-resources",
                "get-resource",
                "list-tags",
                "audit"
              ],
              "env": [
                "AZURE_SUBSCRIPTION_ID"
              ],
              "path": "system-integrations/deployment/azure-resources",
              "markdownBody": "# Azure Resource Manager\n\nList, inspect, and audit Azure resource groups and resources.\n\n## Prerequisites\n\n- `az` CLI authenticated and `AZURE_SUBSCRIPTION_ID` set.\n\n## Commands\n\n| Command          | Description                          |\n|------------------|--------------------------------------|\n| `list-groups`    | List all resource groups             |\n| `list-resources` | List resources in a group            |\n| `get-resource`   | Get details of a specific resource   |\n| `list-tags`      | List tags for a resource group       |\n| `audit`          | Audit untagged resources             |\n\n## Usage\n\n```bash\nexport AZURE_SUBSCRIPTION_ID=\"your-sub-id\"\npython3 scripts/azure_resources.py list-groups\npython3 scripts/azure_resources.py list-resources --group my-rg\npython3 scripts/azure_resources.py audit --group my-rg\n```"
            },
            {
              "slug": "aws-s3",
              "name": "aws-s3",
              "id": "OC-0013",
              "version": "1.0.0",
              "description": "AWS S3 Bucket Explorer - Upload assets, presigned URLs",
              "commands": [
                "list-buckets",
                "list-objects",
                "upload",
                "download",
                "presign"
              ],
              "env": [
                "AWS_ACCESS_KEY_ID",
                "AWS_SECRET_ACCESS_KEY",
                "AWS_DEFAULT_REGION"
              ],
              "path": "system-integrations/deployment/aws-s3",
              "markdownBody": "# AWS S3 Bucket Explorer\n\nManage S3 buckets, upload/download objects, and generate presigned URLs.\n\n## Prerequisites\n\n- AWS CLI configured or `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, and `AWS_DEFAULT_REGION` set.\n\n## Commands\n\n| Command        | Description                          |\n|----------------|--------------------------------------|\n| `list-buckets` | List all S3 buckets                  |\n| `list-objects` | List objects in a bucket             |\n| `upload`       | Upload a local file to S3            |\n| `download`     | Download an S3 object locally        |\n| `presign`      | Generate a presigned URL for an obj  |\n\n## Usage\n\n```bash\npython3 scripts/aws_s3.py list-buckets\npython3 scripts/aws_s3.py upload --bucket my-bucket --key assets/logo.png --file ./logo.png\npython3 scripts/aws_s3.py presign --bucket my-bucket --key assets/logo.png --expires 3600\n```"
            },
            {
              "slug": "aws-lambda",
              "name": "aws-lambda",
              "id": "OC-0015",
              "version": "1.0.0",
              "description": "AWS Lambda Invoker - Trigger and monitor serverless functions",
              "commands": [
                "list-functions",
                "invoke",
                "get-logs",
                "get-function",
                "update-code"
              ],
              "env": [
                "AWS_ACCESS_KEY_ID",
                "AWS_SECRET_ACCESS_KEY",
                "AWS_DEFAULT_REGION"
              ],
              "path": "system-integrations/deployment/aws-lambda",
              "markdownBody": "# AWS Lambda Invoker\n\nInvoke, inspect, update, and monitor AWS Lambda functions.\n\n## Prerequisites\n\n- AWS CLI configured or standard AWS environment variables set.\n\n## Commands\n\n| Command          | Description                          |\n|------------------|--------------------------------------|\n| `list-functions` | List all Lambda functions            |\n| `invoke`         | Invoke a function                    |\n| `get-logs`       | Fetch recent CloudWatch logs         |\n| `get-function`   | Get function configuration           |\n| `update-code`    | Update function code from a zip      |\n\n## Usage\n\n```bash\npython3 scripts/aws_lambda.py list-functions\npython3 scripts/aws_lambda.py invoke --function-name my-func --payload '{\"key\": \"val\"}'\npython3 scripts/aws_lambda.py update-code --function-name my-func --zip-file ./deploy.zip\n```"
            },
            {
              "slug": "aws-ec2",
              "name": "aws-ec2",
              "id": "OC-0014",
              "version": "1.0.0",
              "description": "AWS EC2 Instance Control - Start/stop dev servers",
              "commands": [
                "list-instances",
                "start",
                "stop",
                "get-status",
                "describe"
              ],
              "env": [
                "AWS_ACCESS_KEY_ID",
                "AWS_SECRET_ACCESS_KEY",
                "AWS_DEFAULT_REGION"
              ],
              "path": "system-integrations/deployment/aws-ec2",
              "markdownBody": "# AWS EC2 Instance Control\n\nStart, stop, describe, and monitor EC2 instances.\n\n## Prerequisites\n\n- AWS CLI configured or standard AWS environment variables set.\n\n## Commands\n\n| Command          | Description                          |\n|------------------|--------------------------------------|\n| `list-instances` | List all EC2 instances               |\n| `start`          | Start a stopped instance             |\n| `stop`           | Stop a running instance              |\n| `get-status`     | Get instance status checks           |\n| `describe`       | Describe a specific instance         |\n\n## Usage\n\n```bash\npython3 scripts/aws_ec2.py list-instances\npython3 scripts/aws_ec2.py start --instance-id i-0abc123\npython3 scripts/aws_ec2.py stop --instance-id i-0abc123\n```"
            }
          ]
        },
        {
          "slug": "monitoring-analytics",
          "name": "Monitoring Analytics",
          "skills": [
            {
              "slug": "sentry-triage",
              "name": "sentry-triage",
              "id": "OC-0050",
              "version": "1.0.0",
              "description": "Sentry Error Triage - Fetch recent exceptions and assign to developers",
              "commands": [
                "list-issues",
                "get-issue",
                "assign",
                "resolve",
                "list-events"
              ],
              "env": [
                "SENTRY_AUTH_TOKEN",
                "SENTRY_ORG",
                "SENTRY_PROJECT"
              ],
              "path": "system-integrations/monitoring-analytics/sentry-triage",
              "markdownBody": "# Sentry Error Triage\n\nFetch recent Sentry exceptions, inspect details, assign to developers, and resolve issues.\n\n## Prerequisites\n\n- `SENTRY_AUTH_TOKEN` â€“ Sentry API auth token.\n- `SENTRY_ORG` â€“ Sentry organization slug.\n- `SENTRY_PROJECT` â€“ Sentry project slug.\n\n## Commands\n\n| Command       | Description                              |\n|---------------|------------------------------------------|\n| `list-issues` | List recent unresolved issues            |\n| `get-issue`   | Get details for a specific issue         |\n| `assign`      | Assign an issue to a developer           |\n| `resolve`     | Mark an issue as resolved                |\n| `list-events` | List recent events for an issue          |\n\n## Usage\n\n```bash\nexport SENTRY_AUTH_TOKEN=\"your-token\"\nexport SENTRY_ORG=\"my-org\"\nexport SENTRY_PROJECT=\"my-project\"\npython3 scripts/sentry_triage.py list-issues --limit 10\npython3 scripts/sentry_triage.py get-issue --issue-id 12345\npython3 scripts/sentry_triage.py assign --issue-id 12345 --user user@example.com\npython3 scripts/sentry_triage.py resolve --issue-id 12345\npython3 scripts/sentry_triage.py list-events --issue-id 12345\n```"
            },
            {
              "slug": "posthog-flags",
              "name": "posthog-flags",
              "id": "OC-0055",
              "version": "1.0.0",
              "description": "PostHog Feature Flag Manager - Toggle features for users/cohorts",
              "commands": [
                "list-flags",
                "create-flag",
                "update-flag",
                "delete-flag",
                "evaluate"
              ],
              "env": [
                "POSTHOG_URL",
                "POSTHOG_API_KEY"
              ],
              "path": "system-integrations/monitoring-analytics/posthog-flags",
              "markdownBody": "# PostHog Feature Flag Manager\n\nManage PostHog feature flags: list, create, update, delete, and evaluate flags for users.\n\n## Prerequisites\n\n- `POSTHOG_URL` â€“ PostHog instance URL (e.g. `https://app.posthog.com`).\n- `POSTHOG_API_KEY` â€“ PostHog personal API key.\n\n## Commands\n\n| Command       | Description                              |\n|---------------|------------------------------------------|\n| `list-flags`  | List all feature flags                   |\n| `create-flag` | Create a new feature flag                |\n| `update-flag` | Update an existing feature flag          |\n| `delete-flag` | Delete a feature flag                    |\n| `evaluate`    | Evaluate a flag for a given user         |\n\n## Usage\n\n```bash\nexport POSTHOG_URL=\"https://app.posthog.com\"\nexport POSTHOG_API_KEY=\"your-api-key\"\npython3 scripts/posthog_flags.py list-flags\npython3 scripts/posthog_flags.py create-flag --key new-feature --rollout 50\npython3 scripts/posthog_flags.py update-flag --flag-id 123 --active true\npython3 scripts/posthog_flags.py delete-flag --flag-id 123\npython3 scripts/posthog_flags.py evaluate --key new-feature --distinct-id user-42\n```"
            },
            {
              "slug": "plausible-reporter",
              "name": "plausible-reporter",
              "id": "OC-0058",
              "version": "1.0.0",
              "description": "Plausible Analytics Reporter - Pull web analytics summaries",
              "commands": [
                "realtime",
                "aggregate",
                "timeseries",
                "breakdown",
                "list-sites"
              ],
              "env": [
                "PLAUSIBLE_URL",
                "PLAUSIBLE_API_KEY"
              ],
              "path": "system-integrations/monitoring-analytics/plausible-reporter",
              "markdownBody": "# Plausible Analytics Reporter\n\nQuery Plausible Analytics for real-time visitors, aggregate stats, time series, and breakdowns.\n\n## Prerequisites\n\n- `PLAUSIBLE_URL` â€“ Plausible instance URL (e.g. `https://plausible.io`).\n- `PLAUSIBLE_API_KEY` â€“ Plausible API key.\n\n## Commands\n\n| Command       | Description                              |\n|---------------|------------------------------------------|\n| `realtime`    | Get current real-time visitor count      |\n| `aggregate`   | Get aggregate stats for a period         |\n| `timeseries`  | Get time series data for a metric        |\n| `breakdown`   | Break down stats by a property           |\n| `list-sites`  | List sites in the account                |\n\n## Usage\n\n```bash\nexport PLAUSIBLE_URL=\"https://plausible.io\"\nexport PLAUSIBLE_API_KEY=\"your-api-key\"\npython3 scripts/plausible_reporter.py realtime --site-id example.com\npython3 scripts/plausible_reporter.py aggregate --site-id example.com --period 30d\npython3 scripts/plausible_reporter.py timeseries --site-id example.com --period 7d\npython3 scripts/plausible_reporter.py breakdown --site-id example.com --property visit:source\npython3 scripts/plausible_reporter.py list-sites\n```"
            },
            {
              "slug": "mixpanel-analyzer",
              "name": "mixpanel-analyzer",
              "id": "OC-0054",
              "version": "1.0.0",
              "description": "Mixpanel Cohort Analyzer - Query retention and funnel data",
              "commands": [
                "query-events",
                "retention",
                "funnels",
                "list-cohorts",
                "export"
              ],
              "env": [
                "MIXPANEL_PROJECT_ID",
                "MIXPANEL_SERVICE_ACCOUNT",
                "MIXPANEL_SECRET"
              ],
              "path": "system-integrations/monitoring-analytics/mixpanel-analyzer",
              "markdownBody": "# Mixpanel Cohort Analyzer\n\nQuery Mixpanel for event analytics, retention curves, funnel conversion, and cohort data.\n\n## Prerequisites\n\n- `MIXPANEL_PROJECT_ID` â€“ Mixpanel project ID.\n- `MIXPANEL_SERVICE_ACCOUNT` â€“ Mixpanel service account username.\n- `MIXPANEL_SECRET` â€“ Mixpanel service account secret.\n\n## Commands\n\n| Command        | Description                              |\n|----------------|------------------------------------------|\n| `query-events` | Query event counts over a date range     |\n| `retention`    | Get retention data for an event          |\n| `funnels`      | Query funnel conversion data             |\n| `list-cohorts` | List saved cohorts                       |\n| `export`       | Export raw event data                    |\n\n## Usage\n\n```bash\nexport MIXPANEL_PROJECT_ID=\"12345\"\nexport MIXPANEL_SERVICE_ACCOUNT=\"user.abc123.mp-service-account\"\nexport MIXPANEL_SECRET=\"your-secret\"\npython3 scripts/mixpanel_analyzer.py query-events --event \"Sign Up\" --from-date 2024-01-01 --to-date 2024-01-31\npython3 scripts/mixpanel_analyzer.py retention --event \"Login\" --from-date 2024-01-01 --to-date 2024-01-31\npython3 scripts/mixpanel_analyzer.py funnels --funnel-id 67890\npython3 scripts/mixpanel_analyzer.py list-cohorts\npython3 scripts/mixpanel_analyzer.py export --from-date 2024-01-01 --to-date 2024-01-02\n```"
            },
            {
              "slug": "logrocket-finder",
              "name": "logrocket-finder",
              "id": "OC-0053",
              "version": "1.0.0",
              "description": "LogRocket Session Finder - Find user sessions with errors",
              "commands": [
                "list-sessions",
                "search",
                "get-session",
                "list-errors",
                "get-url"
              ],
              "env": [
                "LOGROCKET_APP_ID",
                "LOGROCKET_API_KEY"
              ],
              "path": "system-integrations/monitoring-analytics/logrocket-finder",
              "markdownBody": "# LogRocket Session Finder\n\nSearch LogRocket sessions for user errors, replay URLs, and session details.\n\n## Prerequisites\n\n- `LOGROCKET_APP_ID` â€“ LogRocket application ID.\n- `LOGROCKET_API_KEY` â€“ LogRocket API key.\n\n## Commands\n\n| Command         | Description                              |\n|-----------------|------------------------------------------|\n| `list-sessions` | List recent sessions                     |\n| `search`        | Search sessions by email or user ID      |\n| `get-session`   | Get details for a specific session       |\n| `list-errors`   | List errors in a session                 |\n| `get-url`       | Get the replay URL for a session         |\n\n## Usage\n\n```bash\nexport LOGROCKET_APP_ID=\"your-app-id\"\nexport LOGROCKET_API_KEY=\"your-api-key\"\npython3 scripts/logrocket_finder.py list-sessions --limit 10\npython3 scripts/logrocket_finder.py search --email user@example.com\npython3 scripts/logrocket_finder.py get-session --session-id abc123\npython3 scripts/logrocket_finder.py list-errors --session-id abc123\npython3 scripts/logrocket_finder.py get-url --session-id abc123\n```"
            },
            {
              "slug": "grafana-alerts",
              "name": "grafana-alerts",
              "id": "OC-0052",
              "version": "1.0.0",
              "description": "Grafana Alert Manager - Silence or acknowledge alerts",
              "commands": [
                "list-alerts",
                "silence",
                "acknowledge",
                "list-silences",
                "delete-silence"
              ],
              "env": [
                "GRAFANA_URL",
                "GRAFANA_API_KEY"
              ],
              "path": "system-integrations/monitoring-analytics/grafana-alerts",
              "markdownBody": "# Grafana Alert Manager\n\nManage Grafana alerts: list firing alerts, create silences, acknowledge, and remove silences.\n\n## Prerequisites\n\n- `GRAFANA_URL` â€“ Base URL of your Grafana instance (e.g. `https://grafana.example.com`).\n- `GRAFANA_API_KEY` â€“ Grafana API key with alerting permissions.\n\n## Commands\n\n| Command          | Description                              |\n|------------------|------------------------------------------|\n| `list-alerts`    | List currently firing alerts             |\n| `silence`        | Create a silence for a matcher           |\n| `acknowledge`    | Acknowledge a firing alert               |\n| `list-silences`  | List active silences                     |\n| `delete-silence` | Delete a silence by ID                   |\n\n## Usage\n\n```bash\nexport GRAFANA_URL=\"https://grafana.example.com\"\nexport GRAFANA_API_KEY=\"your-api-key\"\npython3 scripts/grafana_alerts.py list-alerts\npython3 scripts/grafana_alerts.py silence --matcher \"alertname=HighCPU\" --duration 2h\npython3 scripts/grafana_alerts.py acknowledge --alert-id abc123\npython3 scripts/grafana_alerts.py list-silences\npython3 scripts/grafana_alerts.py delete-silence --silence-id def456\n```"
            },
            {
              "slug": "datadog-snapshotter",
              "name": "datadog-snapshotter",
              "id": "OC-0051",
              "version": "1.0.0",
              "description": "Datadog Dashboard Snapshotter - Get PNG of health metrics",
              "commands": [
                "list-dashboards",
                "snapshot",
                "list-monitors",
                "get-monitor",
                "mute-monitor"
              ],
              "env": [
                "DD_API_KEY",
                "DD_APP_KEY"
              ],
              "path": "system-integrations/monitoring-analytics/datadog-snapshotter",
              "markdownBody": "# Datadog Dashboard Snapshotter\n\nCapture dashboard snapshots, list monitors, and mute alerts via the Datadog API.\n\n## Prerequisites\n\n- `DD_API_KEY` â€“ Datadog API key.\n- `DD_APP_KEY` â€“ Datadog application key.\n\n## Commands\n\n| Command           | Description                              |\n|-------------------|------------------------------------------|\n| `list-dashboards` | List all dashboards                      |\n| `snapshot`        | Take a PNG snapshot of a metric graph    |\n| `list-monitors`   | List all monitors                        |\n| `get-monitor`     | Get details for a specific monitor       |\n| `mute-monitor`    | Mute a monitor                           |\n\n## Usage\n\n```bash\nexport DD_API_KEY=\"your-api-key\"\nexport DD_APP_KEY=\"your-app-key\"\npython3 scripts/datadog_snapshotter.py list-dashboards\npython3 scripts/datadog_snapshotter.py snapshot --metric \"avg:system.cpu.user{*}\" --start 1h\npython3 scripts/datadog_snapshotter.py list-monitors\npython3 scripts/datadog_snapshotter.py mute-monitor --monitor-id 12345\n```"
            },
            {
              "slug": "betterstack-monitor",
              "name": "betterstack-monitor",
              "id": "OC-0057",
              "version": "1.0.0",
              "description": "Better Stack Monitor - Check uptime incidents",
              "commands": [
                "list-monitors",
                "get-monitor",
                "list-incidents",
                "acknowledge",
                "resolve"
              ],
              "env": [
                "BETTERSTACK_API_TOKEN"
              ],
              "path": "system-integrations/monitoring-analytics/betterstack-monitor",
              "markdownBody": "# Better Stack Monitor\n\nMonitor uptime, list incidents, acknowledge, and resolve via the Better Stack API.\n\n## Prerequisites\n\n- `BETTERSTACK_API_TOKEN` â€“ Better Stack API token.\n\n## Commands\n\n| Command          | Description                              |\n|------------------|------------------------------------------|\n| `list-monitors`  | List all uptime monitors                 |\n| `get-monitor`    | Get details for a specific monitor       |\n| `list-incidents` | List recent incidents                    |\n| `acknowledge`    | Acknowledge an incident                  |\n| `resolve`        | Resolve an incident                      |\n\n## Usage\n\n```bash\nexport BETTERSTACK_API_TOKEN=\"your-token\"\npython3 scripts/betterstack_monitor.py list-monitors\npython3 scripts/betterstack_monitor.py get-monitor --monitor-id 12345\npython3 scripts/betterstack_monitor.py list-incidents\npython3 scripts/betterstack_monitor.py acknowledge --incident-id 67890\npython3 scripts/betterstack_monitor.py resolve --incident-id 67890\n```"
            },
            {
              "slug": "axiom-logs",
              "name": "axiom-logs",
              "id": "OC-0056",
              "version": "1.0.0",
              "description": "Axiom Log Query - Run structured log queries",
              "commands": [
                "query",
                "list-datasets",
                "ingest",
                "get-dataset",
                "stream"
              ],
              "env": [
                "AXIOM_TOKEN",
                "AXIOM_ORG_ID"
              ],
              "path": "system-integrations/monitoring-analytics/axiom-logs",
              "markdownBody": "# Axiom Log Query\n\nRun structured log queries, manage datasets, and ingest data via the Axiom API.\n\n## Prerequisites\n\n- `AXIOM_TOKEN` â€“ Axiom API token.\n- `AXIOM_ORG_ID` â€“ Axiom organization ID.\n\n## Commands\n\n| Command         | Description                              |\n|-----------------|------------------------------------------|\n| `query`         | Run an APL query against a dataset       |\n| `list-datasets` | List available datasets                  |\n| `ingest`        | Ingest JSON data into a dataset          |\n| `get-dataset`   | Get metadata for a dataset               |\n| `stream`        | Stream recent log entries                |\n\n## Usage\n\n```bash\nexport AXIOM_TOKEN=\"your-token\"\nexport AXIOM_ORG_ID=\"your-org-id\"\npython3 scripts/axiom_logs.py list-datasets\npython3 scripts/axiom_logs.py query --dataset logs --apl \"['logs'] | where severity == 'error' | limit 10\"\npython3 scripts/axiom_logs.py ingest --dataset logs --file data.json\npython3 scripts/axiom_logs.py get-dataset --dataset logs\npython3 scripts/axiom_logs.py stream --dataset logs --limit 20\n```"
            }
          ]
        },
        {
          "slug": "search-vector",
          "name": "Search Vector",
          "skills": [
            {
              "slug": "weaviate-manager",
              "name": "Weaviate Schema Manager",
              "id": "OC-0038",
              "version": "1.0.0",
              "description": "Update and manage Weaviate class definitions and objects.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/weaviate-manager",
              "markdownBody": "# Weaviate Schema Manager\n\nManage Weaviate schemas, classes, and objects for vector search applications.\n\n## Capabilities\n\n- Retrieve and inspect the full schema\n- Create and delete classes with custom properties\n- List objects and run semantic queries\n\n## Quick Start\n\n```bash\nexport WEAVIATE_URL=\"http://localhost:8080\"\nexport WEAVIATE_API_KEY=\"your-api-key\"\npython3 scripts/weaviate_manager.py get-schema\npython3 scripts/weaviate_manager.py create-class --name Article --properties '[{\"name\":\"title\",\"dataType\":[\"text\"]}]'\npython3 scripts/weaviate_manager.py query --class-name Article --query \"machine learning\" --limit 5\n```\n\n## Commands & Parameters\n\n| Command         | Parameters                                       | Description                  |\n| --------------- | ------------------------------------------------ | ---------------------------- |\n| `get-schema`    | â€”                                                | Get the full schema          |\n| `create-class`  | `--name`, `--properties` (JSON)                  | Create a new class           |\n| `delete-class`  | `--name`                                         | Delete a class               |\n| `list-objects`  | `--class-name`, `--limit`                        | List objects in a class      |\n| `query`         | `--class-name`, `--query`, `--limit`             | Semantic search              |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `WEAVIATE_URL`, `WEAVIATE_API_KEY`"
            },
            {
              "slug": "qdrant-manager",
              "name": "Qdrant Collection Manager",
              "id": "OC-0041",
              "version": "1.0.0",
              "description": "Manage Qdrant collections and run similarity queries.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/qdrant-manager",
              "markdownBody": "# Qdrant Collection Manager\n\nCreate, manage, and query Qdrant vector collections for similarity search.\n\n## Capabilities\n\n- List, create, and delete collections\n- Get detailed collection info and statistics\n- Upsert points with vectors and payloads\n- Run similarity search queries\n\n## Quick Start\n\n```bash\nexport QDRANT_URL=\"http://localhost:6333\"\nexport QDRANT_API_KEY=\"your-api-key\"\npython3 scripts/qdrant_manager.py list-collections\npython3 scripts/qdrant_manager.py create-collection --name docs --size 1536 --distance cosine\npython3 scripts/qdrant_manager.py search --name docs --vector '[0.1, 0.2, ...]' --limit 5\n```\n\n## Commands & Parameters\n\n| Command              | Parameters                                      | Description                     |\n| -------------------- | ----------------------------------------------- | ------------------------------- |\n| `list-collections`   | â€”                                               | List all collections            |\n| `create-collection`  | `--name`, `--size`, `--distance`                | Create a collection             |\n| `delete-collection`  | `--name`                                        | Delete a collection             |\n| `upsert`             | `--name`, `--points` (JSON)                     | Upsert points with vectors      |\n| `search`             | `--name`, `--vector` (JSON), `--limit`          | Similarity search               |\n| `get-info`           | `--name`                                        | Get collection details          |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `QDRANT_URL`, `QDRANT_API_KEY`"
            },
            {
              "slug": "pinecone-manager",
              "name": "Pinecone Index Manager",
              "id": "OC-0037",
              "version": "1.0.0",
              "description": "Create, delete, and manage vector indexes for RAG applications using Pinecone.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/pinecone-manager",
              "markdownBody": "# Pinecone Index Manager\n\nManage Pinecone vector indexes for retrieval-augmented generation (RAG) applications.\n\n## Capabilities\n\n- List, create, describe, and delete Pinecone indexes\n- Upsert vectors with metadata into an index\n- Query indexes with vector similarity search\n\n## Quick Start\n\n```bash\nexport PINECONE_API_KEY=\"your-api-key\"\npython3 scripts/pinecone_manager.py list-indexes\npython3 scripts/pinecone_manager.py create-index --name my-index --dimension 1536 --metric cosine\npython3 scripts/pinecone_manager.py query --name my-index --vector '[0.1, 0.2, ...]' --top-k 5\n```\n\n## Commands & Parameters\n\n| Command          | Parameters                                      | Description                    |\n| ---------------- | ----------------------------------------------- | ------------------------------ |\n| `list-indexes`   | â€”                                               | List all indexes               |\n| `create-index`   | `--name`, `--dimension`, `--metric`             | Create a new index             |\n| `delete-index`   | `--name`                                        | Delete an index                |\n| `describe-index` | `--name`                                        | Show index details             |\n| `upsert`         | `--name`, `--vectors` (JSON)                    | Upsert vectors into an index   |\n| `query`          | `--name`, `--vector` (JSON), `--top-k`          | Query by vector similarity     |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variable: `PINECONE_API_KEY`"
            },
            {
              "slug": "meilisearch-settings",
              "name": "MeiliSearch Settings",
              "id": "OC-0040",
              "version": "1.0.0",
              "description": "Configure MeiliSearch ranking rules, stop words, and index settings.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/meilisearch-settings",
              "markdownBody": "# MeiliSearch Settings\n\nConfigure and manage MeiliSearch indexes, documents, and search settings.\n\n## Capabilities\n\n- List, create, and inspect indexes\n- Add documents and perform full-text search\n- Get and update settings (ranking rules, stop words, synonyms, etc.)\n\n## Quick Start\n\n```bash\nexport MEILISEARCH_URL=\"http://localhost:7700\"\nexport MEILISEARCH_API_KEY=\"your-master-key\"\npython3 scripts/meilisearch_settings.py list-indexes\npython3 scripts/meilisearch_settings.py create-index --uid movies --primary-key id\npython3 scripts/meilisearch_settings.py update-settings --uid movies --settings '{\"rankingRules\":[\"words\",\"typo\",\"proximity\"]}'\n```\n\n## Commands & Parameters\n\n| Command            | Parameters                                    | Description                    |\n| ------------------ | --------------------------------------------- | ------------------------------ |\n| `list-indexes`     | â€”                                             | List all indexes               |\n| `create-index`     | `--uid`, `--primary-key`                      | Create a new index             |\n| `search`           | `--uid`, `--query`                            | Search an index                |\n| `get-settings`     | `--uid`                                       | Get index settings             |\n| `update-settings`  | `--uid`, `--settings` (JSON)                  | Update index settings          |\n| `add-documents`    | `--uid`, `--documents` (JSON)                 | Add documents to an index      |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `MEILISEARCH_URL`, `MEILISEARCH_API_KEY`"
            },
            {
              "slug": "chroma-manager",
              "name": "Chroma DB Manager",
              "id": "OC-0042",
              "version": "1.0.0",
              "description": "Manage Chroma vector stores for RAG pipelines.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/chroma-manager",
              "markdownBody": "# Chroma DB Manager\n\nManage ChromaDB collections and documents for retrieval-augmented generation pipelines.\n\n## Capabilities\n\n- List, create, and delete collections\n- Add documents with embeddings and metadata\n- Query collections by vector similarity\n- Get document counts per collection\n\n## Quick Start\n\n```bash\nexport CHROMA_URL=\"http://localhost:8000\"\npython3 scripts/chroma_manager.py list-collections\npython3 scripts/chroma_manager.py create-collection --name docs\npython3 scripts/chroma_manager.py add --name docs --documents '[\"hello world\"]' --ids '[\"doc1\"]'\npython3 scripts/chroma_manager.py query --name docs --texts '[\"hello\"]' --n-results 5\n```\n\n## Commands & Parameters\n\n| Command              | Parameters                                                 | Description                  |\n| -------------------- | ---------------------------------------------------------- | ---------------------------- |\n| `list-collections`   | â€”                                                          | List all collections         |\n| `create-collection`  | `--name`                                                   | Create a collection          |\n| `delete-collection`  | `--name`                                                   | Delete a collection          |\n| `add`                | `--name`, `--documents` (JSON), `--ids` (JSON)             | Add documents                |\n| `query`              | `--name`, `--texts` (JSON), `--n-results`                  | Query by text similarity     |\n| `count`              | `--name`                                                   | Get document count           |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variable: `CHROMA_URL` (defaults to `http://localhost:8000`)"
            },
            {
              "slug": "algolia-indexer",
              "name": "Algolia Indexer",
              "id": "OC-0039",
              "version": "1.0.0",
              "description": "Push content updates and manage search indices with Algolia.",
              "commands": [],
              "env": [],
              "path": "system-integrations/search-vector/algolia-indexer",
              "markdownBody": "# Algolia Indexer\n\nManage Algolia search indices, push records, and configure settings.\n\n## Capabilities\n\n- List indices and inspect settings\n- Add and delete records in an index\n- Perform full-text search queries\n- Update index settings (searchable attributes, ranking, etc.)\n\n## Quick Start\n\n```bash\nexport ALGOLIA_APP_ID=\"your-app-id\"\nexport ALGOLIA_API_KEY=\"your-admin-api-key\"\npython3 scripts/algolia_indexer.py list-indices\npython3 scripts/algolia_indexer.py add-records --index products --records '[{\"objectID\":\"1\",\"name\":\"Widget\"}]'\npython3 scripts/algolia_indexer.py search --index products --query \"widget\"\n```\n\n## Commands & Parameters\n\n| Command         | Parameters                                       | Description                     |\n| --------------- | ------------------------------------------------ | ------------------------------- |\n| `list-indices`  | â€”                                                | List all indices                |\n| `search`        | `--index`, `--query`                             | Search an index                 |\n| `add-records`   | `--index`, `--records` (JSON)                    | Add records to an index         |\n| `delete-record` | `--index`, `--object-id`                         | Delete a record by objectID     |\n| `get-settings`  | `--index`                                        | Get index settings              |\n| `set-settings`  | `--index`, `--settings` (JSON)                   | Update index settings           |\n\n## Dependencies\n\n- Python 3.8+\n- `requests` library\n- Environment variables: `ALGOLIA_APP_ID`, `ALGOLIA_API_KEY`"
            }
          ]
        },
        {
          "slug": "version-control",
          "name": "Version Control",
          "skills": [
            {
              "slug": "gitlab-pipeline",
              "name": "gitlab-pipeline",
              "id": null,
              "version": "1.0.0",
              "description": "GitLab Pipeline Monitor. Watch CI/CD pipeline status and report failures. Use when user asks to monitor GitLab pipelines, check job status, or retry failed jobs.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/gitlab-pipeline",
              "markdownBody": "# GitLab Pipeline Monitor\n\nMonitor GitLab CI/CD pipelines, check job statuses, and manage pipeline execution.\n\n## Capabilities\n\n1. **List Pipelines**: View recent pipelines for a project.\n2. **Pipeline Details**: Get detailed status of a specific pipeline.\n3. **Job Inspection**: List and inspect individual jobs within a pipeline.\n4. **Retry Jobs**: Retry failed jobs.\n5. **Cancel Pipelines**: Cancel running pipelines.\n\n## Quick Start\n\n```bash\n# List recent pipelines\npython3 skills/system-integrations/version-control/gitlab-pipeline/scripts/pipeline.py list-pipelines --project my-group/my-project\n\n# Get pipeline details\npython3 skills/system-integrations/version-control/gitlab-pipeline/scripts/pipeline.py get-pipeline --project my-group/my-project --pipeline-id 12345\n\n# List jobs in a pipeline\npython3 skills/system-integrations/version-control/gitlab-pipeline/scripts/pipeline.py get-jobs --project my-group/my-project --pipeline-id 12345\n\n# Retry a failed job\npython3 skills/system-integrations/version-control/gitlab-pipeline/scripts/pipeline.py retry-job --project my-group/my-project --job-id 67890\n\n# Cancel a pipeline\npython3 skills/system-integrations/version-control/gitlab-pipeline/scripts/pipeline.py cancel-pipeline --project my-group/my-project --pipeline-id 12345\n```\n\n## Commands & Parameters\n\n### `list-pipelines`\nLists recent pipelines for a project.\n- `--project`: GitLab project path (group/project) (required)\n- `--status`: Filter by status (running, pending, success, failed, canceled)\n- `--limit`: Max pipelines to return (default: 20)\n- `--ref`: Filter by branch/tag\n\n### `get-pipeline`\nGets details of a specific pipeline.\n- `--project`: GitLab project path (required)\n- `--pipeline-id`: Pipeline ID (required)\n\n### `get-jobs`\nLists jobs in a pipeline.\n- `--project`: GitLab project path (required)\n- `--pipeline-id`: Pipeline ID (required)\n\n### `retry-job`\nRetries a failed job.\n- `--project`: GitLab project path (required)\n- `--job-id`: Job ID (required)\n\n### `cancel-pipeline`\nCancels a running pipeline.\n- `--project`: GitLab project path (required)\n- `--pipeline-id`: Pipeline ID (required)\n\n## Dependencies\n- `GITLAB_TOKEN` environment variable (GitLab personal access token).\n- `GITLAB_URL` environment variable (default: https://gitlab.com).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "gitlab-merge-request",
              "name": "gitlab-merge-request",
              "id": null,
              "version": "1.0.0",
              "description": "GitLab Merge Request Manager. Auto-assign reviewers and manage MR lifecycle. Use when user asks to create, review, approve, or merge GitLab merge requests.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/gitlab-merge-request",
              "markdownBody": "# GitLab Merge Request Manager\n\nManage GitLab merge requests including creation, reviewer assignment, approval, and merging.\n\n## Capabilities\n\n1. **List MRs**: List merge requests in a project.\n2. **Create MRs**: Create new merge requests with title, description, and assignees.\n3. **Assign Reviewers**: Auto-assign or manually assign reviewers to MRs.\n4. **Approve MRs**: Approve merge requests.\n5. **Merge MRs**: Merge approved merge requests.\n\n## Quick Start\n\n```bash\n# List open MRs\npython3 skills/system-integrations/version-control/gitlab-merge-request/scripts/merge_request.py list-mrs --project my-group/my-project\n\n# Create a merge request\npython3 skills/system-integrations/version-control/gitlab-merge-request/scripts/merge_request.py create-mr --project my-group/my-project --source feature-branch --target main --title \"Add new feature\"\n\n# Assign reviewers\npython3 skills/system-integrations/version-control/gitlab-merge-request/scripts/merge_request.py assign-reviewers --project my-group/my-project --mr-id 10 --reviewers user1,user2\n\n# Approve a MR\npython3 skills/system-integrations/version-control/gitlab-merge-request/scripts/merge_request.py approve-mr --project my-group/my-project --mr-id 10\n\n# Merge a MR\npython3 skills/system-integrations/version-control/gitlab-merge-request/scripts/merge_request.py merge-mr --project my-group/my-project --mr-id 10\n```\n\n## Commands & Parameters\n\n### `list-mrs`\nLists merge requests in a project.\n- `--project`: GitLab project path (group/project) (required)\n- `--state`: Filter by state: opened, closed, merged, all (default: opened)\n- `--limit`: Max MRs to return (default: 20)\n\n### `create-mr`\nCreates a new merge request.\n- `--project`: GitLab project path (required)\n- `--source`: Source branch (required)\n- `--target`: Target branch (default: main)\n- `--title`: MR title (required)\n- `--description`: MR description\n\n### `assign-reviewers`\nAssigns reviewers to a merge request.\n- `--project`: GitLab project path (required)\n- `--mr-id`: Merge request IID (required)\n- `--reviewers`: Comma-separated reviewer usernames (required)\n\n### `approve-mr`\nApproves a merge request.\n- `--project`: GitLab project path (required)\n- `--mr-id`: Merge request IID (required)\n\n### `merge-mr`\nMerges a merge request.\n- `--project`: GitLab project path (required)\n- `--mr-id`: Merge request IID (required)\n- `--squash`: Squash commits on merge (flag)\n- `--delete-branch`: Delete source branch after merge (flag)\n\n## Dependencies\n- `GITLAB_TOKEN` environment variable (GitLab personal access token).\n- `GITLAB_URL` environment variable (default: https://gitlab.com).\n- Python `requests` library (`pip install requests`)."
            },
            {
              "slug": "github-repo-manager",
              "name": "github-repo-manager",
              "id": "OC-0001",
              "version": "1.0.0",
              "description": "GitHub Repo Manager. Create, list, delete repos; manage collaborators. Use when user asks to manage GitHub repositories or collaborators.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/github-repo-manager",
              "markdownBody": "# GitHub Repo Manager\n\nCreate, list, delete GitHub repositories and manage collaborator access from the command line.\n\n## Capabilities\n\n1. **List Repos**: List repos for the authenticated user or an organization.\n2. **Create Repo**: Create a new public or private repository.\n3. **Delete Repo**: Delete a repository (requires confirmation).\n4. **Get Info**: Show metadata for a specific repository.\n5. **Add Collaborator**: Add a collaborator with a specified permission level.\n6. **Remove Collaborator**: Remove a collaborator from a repository.\n7. **List Collaborators**: List all collaborators and their permissions.\n\n## Quick Start\n\n```bash\n# List your repositories\npython3 skills/system-integrations/version-control/github-repo-manager/scripts/repo_manager.py list-repos\n\n# Create a new private repo\npython3 skills/system-integrations/version-control/github-repo-manager/scripts/repo_manager.py create-repo --name my-project --private --description \"My new project\"\n\n# Add a collaborator\npython3 skills/system-integrations/version-control/github-repo-manager/scripts/repo_manager.py add-collaborator --repo owner/my-project --user johndoe --permission write\n```\n\n## Commands & Parameters\n\n### `list-repos`\nLists repositories for the authenticated user or an org.\n- `--org`: Organization name (optional; defaults to authenticated user)\n- `--limit`: Max repos to return (default: 30)\n- `--visibility`: Filter by visibility: public, private, all (default: all)\n\n### `create-repo`\nCreates a new repository.\n- `--name`: Repository name (required)\n- `--description`: Short description\n- `--private`: Make the repo private (flag)\n- `--org`: Create under an organization instead of personal account\n\n### `delete-repo`\nDeletes a repository. Prompts for confirmation unless `--confirm` is passed.\n- `--repo`: Repository (owner/name) (required)\n- `--confirm`: Skip interactive confirmation (flag)\n\n### `get-info`\nShows metadata for a repository.\n- `--repo`: Repository (owner/name) (required)\n\n### `add-collaborator`\nAdds a collaborator with a given permission level.\n- `--repo`: Repository (owner/name) (required)\n- `--user`: GitHub username to add (required)\n- `--permission`: Permission level: pull, push, maintain, triage, admin (default: push)\n\n### `remove-collaborator`\nRemoves a collaborator from a repository.\n- `--repo`: Repository (owner/name) (required)\n- `--user`: GitHub username to remove (required)\n\n### `list-collaborators`\nLists all collaborators in a repository.\n- `--repo`: Repository (owner/name) (required)\n\n## Dependencies\n- `gh` CLI installed and authenticated.\n- `GITHUB_TOKEN` environment variable (or `gh auth login`)."
            },
            {
              "slug": "github-pr-reviewer",
              "name": "github-pr-reviewer",
              "id": null,
              "version": "1.0.0",
              "description": "GitHub PR Automated Reviewer. Verify diffs against style guides and flag violations. Use when user asks to review PRs, check code style, or summarize diffs.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/github-pr-reviewer",
              "markdownBody": "# GitHub PR Automated Reviewer\n\nAutomatically review pull requests, check diffs against style conventions, and generate summaries.\n\n## Capabilities\n\n1. **PR Review**: Analyze PR diffs and post review comments.\n2. **PR Listing**: List open pull requests in a repository.\n3. **Style Checking**: Flag common style violations in diffs.\n4. **Diff Summarization**: Generate human-readable summaries of PR changes.\n\n## Quick Start\n\n```bash\n# List open PRs\npython3 skills/system-integrations/version-control/github-pr-reviewer/scripts/reviewer.py list-prs --repo owner/repo\n\n# Review a specific PR\npython3 skills/system-integrations/version-control/github-pr-reviewer/scripts/reviewer.py review-pr --repo owner/repo --pr 42\n\n# Check style violations in a PR\npython3 skills/system-integrations/version-control/github-pr-reviewer/scripts/reviewer.py check-style --repo owner/repo --pr 42\n\n# Summarize a PR diff\npython3 skills/system-integrations/version-control/github-pr-reviewer/scripts/reviewer.py summarize-diff --repo owner/repo --pr 42\n```\n\n## Commands & Parameters\n\n### `list-prs`\nLists open pull requests.\n- `--repo`: Repository (owner/name) (required)\n- `--state`: Filter by state: open, closed, merged, all (default: open)\n- `--limit`: Max PRs to return (default: 30)\n\n### `review-pr`\nAnalyzes a PR diff and posts a review.\n- `--repo`: Repository (owner/name) (required)\n- `--pr`: Pull request number (required)\n- `--post-comment`: Post findings as a PR comment (flag)\n\n### `check-style`\nChecks for common style violations in a PR diff.\n- `--repo`: Repository (owner/name) (required)\n- `--pr`: Pull request number (required)\n- `--max-line-length`: Max line length to enforce (default: 120)\n\n### `summarize-diff`\nGenerates a human-readable summary of PR changes.\n- `--repo`: Repository (owner/name) (required)\n- `--pr`: Pull request number (required)\n\n## Dependencies\n- `gh` CLI installed and authenticated.\n- `GITHUB_TOKEN` environment variable (or `gh auth login`)."
            },
            {
              "slug": "github-issues",
              "name": "github-issues",
              "id": null,
              "version": "1.0.0",
              "description": "GitHub Issues Agent. Label, triage, close, and prioritize issues automatically. Use when user asks to manage, triage, or organize GitHub issues.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/github-issues",
              "markdownBody": "# GitHub Issues Agent\n\nAutomate GitHub issue management including labeling, triaging, closing, and prioritizing issues.\n\n## Capabilities\n\n1. **Issue Listing**: List and filter issues in a repository.\n2. **Issue Creation**: Create new issues with labels and assignees.\n3. **Labeling**: Add or update labels on issues.\n4. **Closing**: Close issues with a comment.\n5. **Triage**: Auto-label issues based on title and body content.\n6. **Prioritization**: Assign priority labels based on keyword analysis.\n\n## Quick Start\n\n```bash\n# List open issues\npython3 skills/system-integrations/version-control/github-issues/scripts/issues.py list-issues --repo owner/repo\n\n# Create a new issue\npython3 skills/system-integrations/version-control/github-issues/scripts/issues.py create-issue --repo owner/repo --title \"Bug: login fails\" --body \"Steps to reproduce...\"\n\n# Auto-triage issues\npython3 skills/system-integrations/version-control/github-issues/scripts/issues.py triage --repo owner/repo\n\n# Prioritize issues\npython3 skills/system-integrations/version-control/github-issues/scripts/issues.py prioritize --repo owner/repo\n```\n\n## Commands & Parameters\n\n### `list-issues`\nLists issues in a repository.\n- `--repo`: Repository (owner/name) (required)\n- `--state`: Filter by state: open, closed, all (default: open)\n- `--limit`: Max issues to return (default: 30)\n- `--label`: Filter by label\n\n### `create-issue`\nCreates a new issue.\n- `--repo`: Repository (owner/name) (required)\n- `--title`: Issue title (required)\n- `--body`: Issue body\n- `--labels`: Comma-separated labels\n- `--assignee`: Assignee username\n\n### `label-issue`\nAdds labels to an issue.\n- `--repo`: Repository (owner/name) (required)\n- `--issue`: Issue number (required)\n- `--labels`: Comma-separated labels to add (required)\n\n### `close-issue`\nCloses an issue with an optional comment.\n- `--repo`: Repository (owner/name) (required)\n- `--issue`: Issue number (required)\n- `--comment`: Closing comment\n\n### `triage`\nAuto-labels issues based on content analysis.\n- `--repo`: Repository (owner/name) (required)\n- `--limit`: Number of issues to triage (default: 20)\n\n### `prioritize`\nAssigns priority labels based on keyword analysis.\n- `--repo`: Repository (owner/name) (required)\n- `--limit`: Number of issues to analyze (default: 20)\n\n## Dependencies\n- `gh` CLI installed and authenticated.\n- `GITHUB_TOKEN` environment variable (or `gh auth login`)."
            },
            {
              "slug": "github-actions",
              "name": "github-actions",
              "id": null,
              "version": "1.0.0",
              "description": "GitHub Actions Trigger. Manually dispatch workflows, monitor runs, and manage CI/CD from agent commands. Use when user asks to trigger, monitor, or cancel GitHub Actions workflows.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/github-actions",
              "markdownBody": "# GitHub Actions Trigger\n\nTrigger, monitor, and manage GitHub Actions workflows from agent commands.\n\n## Capabilities\n\n1. **List Workflows**: Discover available workflows in a repository.\n2. **Trigger Workflows**: Manually dispatch workflow runs.\n3. **Run Status**: Check the status of workflow runs.\n4. **List Runs**: View recent workflow run history.\n5. **Cancel Runs**: Cancel in-progress workflow runs.\n\n## Quick Start\n\n```bash\n# List workflows\npython3 skills/system-integrations/version-control/github-actions/scripts/actions.py list-workflows --repo owner/repo\n\n# Trigger a workflow\npython3 skills/system-integrations/version-control/github-actions/scripts/actions.py trigger-workflow --repo owner/repo --workflow ci.yml --ref main\n\n# Get run status\npython3 skills/system-integrations/version-control/github-actions/scripts/actions.py get-run-status --repo owner/repo --run-id 12345\n\n# List recent runs\npython3 skills/system-integrations/version-control/github-actions/scripts/actions.py list-runs --repo owner/repo\n\n# Cancel a run\npython3 skills/system-integrations/version-control/github-actions/scripts/actions.py cancel-run --repo owner/repo --run-id 12345\n```\n\n## Commands & Parameters\n\n### `list-workflows`\nLists available workflows in a repository.\n- `--repo`: Repository (owner/name) (required)\n\n### `trigger-workflow`\nManually dispatches a workflow.\n- `--repo`: Repository (owner/name) (required)\n- `--workflow`: Workflow filename or ID (required)\n- `--ref`: Git ref (branch/tag) to run on (default: main)\n- `--inputs`: JSON string of workflow inputs\n\n### `get-run-status`\nGets the status of a specific workflow run.\n- `--repo`: Repository (owner/name) (required)\n- `--run-id`: Workflow run ID (required)\n\n### `list-runs`\nLists recent workflow runs.\n- `--repo`: Repository (owner/name) (required)\n- `--workflow`: Filter by workflow filename\n- `--limit`: Max runs to return (default: 20)\n- `--status`: Filter by status (queued, in_progress, completed)\n\n### `cancel-run`\nCancels an in-progress workflow run.\n- `--repo`: Repository (owner/name) (required)\n- `--run-id`: Workflow run ID (required)\n\n## Dependencies\n- `gh` CLI installed and authenticated.\n- `GITHUB_TOKEN` environment variable (or `gh auth login`)."
            },
            {
              "slug": "changelog-generator",
              "name": "changelog-generator",
              "id": null,
              "version": "1.0.0",
              "description": "Changelog Generator. Auto-generate changelogs from commit history and PR titles. Use when user asks to generate, preview, or update a CHANGELOG.md file.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/changelog-generator",
              "markdownBody": "# Changelog Generator\n\nAutomatically generate changelogs from git commit history and merged PR titles.\n\n## Capabilities\n\n1. **Generate**: Create a full CHANGELOG.md from git history and PR titles.\n2. **Preview**: Preview changelog output without writing to file.\n3. **Append**: Append a new version section to an existing CHANGELOG.md.\n\n## Quick Start\n\n```bash\n# Generate a changelog\npython3 skills/system-integrations/version-control/changelog-generator/scripts/changelog.py generate --repo owner/repo\n\n# Preview without writing\npython3 skills/system-integrations/version-control/changelog-generator/scripts/changelog.py preview --repo owner/repo --since v1.0.0\n\n# Append a new version\npython3 skills/system-integrations/version-control/changelog-generator/scripts/changelog.py append --repo owner/repo --version 1.2.0 --since v1.1.0\n```\n\n## Commands & Parameters\n\n### `generate`\nGenerates a full CHANGELOG.md from git log and merged PRs.\n- `--repo`: Repository (owner/name) (required)\n- `--output`: Output file path (default: CHANGELOG.md)\n- `--since`: Start from tag/ref (optional, generates from all history if omitted)\n- `--group-by`: Group entries by type (default: type)\n\n### `preview`\nPreviews changelog output to stdout without writing.\n- `--repo`: Repository (owner/name) (required)\n- `--since`: Start from tag/ref\n- `--group-by`: Group entries by type (default: type)\n\n### `append`\nAppends a new version section to existing CHANGELOG.md.\n- `--repo`: Repository (owner/name) (required)\n- `--version`: Version string for the new section (required)\n- `--since`: Start from tag/ref (required)\n- `--output`: Output file path (default: CHANGELOG.md)\n\n## Dependencies\n- `gh` CLI installed and authenticated.\n- `git` CLI available (for local commit history).\n- `GITHUB_TOKEN` environment variable (or `gh auth login`)."
            },
            {
              "slug": "bitbucket-integration",
              "name": "bitbucket-integration",
              "id": null,
              "version": "1.0.0",
              "description": "Bitbucket Integration. Sync Jira tickets with commits and manage repositories. Use when user asks to list Bitbucket repos, PRs, commits, or link Jira tickets.",
              "commands": [],
              "env": [],
              "path": "system-integrations/version-control/bitbucket-integration",
              "markdownBody": "# Bitbucket Integration\n\nManage Bitbucket repositories, pull requests, and link Jira tickets to commits.\n\n## Capabilities\n\n1. **List Repos**: List repositories in a workspace.\n2. **List PRs**: List pull requests in a repository.\n3. **Get Commits**: View commit history for a repository.\n4. **Link Jira**: Associate Jira ticket IDs with commits.\n5. **List Branches**: List branches in a repository.\n\n## Quick Start\n\n```bash\n# List repositories\npython3 skills/system-integrations/version-control/bitbucket-integration/scripts/bitbucket.py list-repos --workspace my-workspace\n\n# List pull requests\npython3 skills/system-integrations/version-control/bitbucket-integration/scripts/bitbucket.py list-prs --workspace my-workspace --repo my-repo\n\n# Get commits\npython3 skills/system-integrations/version-control/bitbucket-integration/scripts/bitbucket.py get-commits --workspace my-workspace --repo my-repo\n\n# Link Jira tickets from commits\npython3 skills/system-integrations/version-control/bitbucket-integration/scripts/bitbucket.py link-jira --workspace my-workspace --repo my-repo\n\n# List branches\npython3 skills/system-integrations/version-control/bitbucket-integration/scripts/bitbucket.py list-branches --workspace my-workspace --repo my-repo\n```\n\n## Commands & Parameters\n\n### `list-repos`\nLists repositories in a Bitbucket workspace.\n- `--workspace`: Bitbucket workspace slug (required)\n- `--limit`: Max repos to return (default: 25)\n\n### `list-prs`\nLists pull requests in a repository.\n- `--workspace`: Bitbucket workspace slug (required)\n- `--repo`: Repository slug (required)\n- `--state`: Filter by state: OPEN, MERGED, DECLINED, SUPERSEDED (default: OPEN)\n\n### `get-commits`\nLists recent commits for a repository.\n- `--workspace`: Bitbucket workspace slug (required)\n- `--repo`: Repository slug (required)\n- `--limit`: Max commits to return (default: 20)\n- `--branch`: Filter by branch\n\n### `link-jira`\nScans commits for Jira ticket references and reports linkages.\n- `--workspace`: Bitbucket workspace slug (required)\n- `--repo`: Repository slug (required)\n- `--limit`: Max commits to scan (default: 50)\n\n### `list-branches`\nLists branches in a repository.\n- `--workspace`: Bitbucket workspace slug (required)\n- `--repo`: Repository slug (required)\n\n## Dependencies\n- `BITBUCKET_USERNAME` environment variable.\n- `BITBUCKET_APP_PASSWORD` environment variable.\n- Python `requests` library (`pip install requests`)."
            }
          ]
        }
      ],
      "skills": [],
      "skillCount": 81
    },
    {
      "slug": "ai-media-generation",
      "name": "Ai Media Generation",
      "icon": "ðŸŽ¨",
      "subcategories": [
        {
          "slug": "audio-music",
          "name": "Audio Music",
          "skills": [
            {
              "slug": "whisper-transcriber",
              "name": "whisper-transcriber",
              "id": "OC-0104",
              "version": "1.0.0",
              "description": "OpenAI Whisper transcription â€“ transcribe, translate, and detect language in audio",
              "commands": [
                "transcribe",
                "translate",
                "detect-language"
              ],
              "env": [
                "OPENAI_API_KEY"
              ],
              "path": "ai-media-generation/audio-music/whisper-transcriber",
              "markdownBody": "# Whisper Transcriber\n\nTranscribe, translate, and detect language in audio files using OpenAI's Whisper API.\n\n## Prerequisites\n- A valid `OPENAI_API_KEY` environment variable.\n\n## Commands\n| Command           | Description                                    |\n|-------------------|------------------------------------------------|\n| `transcribe`      | Transcribe audio to text                       |\n| `translate`       | Transcribe and translate audio to English      |\n| `detect-language` | Detect the language spoken in an audio file    |\n\n## Usage\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\npython3 scripts/whisper_transcriber.py transcribe --input audio.mp3 --format srt --output captions.srt\npython3 scripts/whisper_transcriber.py transcribe --input lecture.mp3 --language fr --format text --output transcript.txt\npython3 scripts/whisper_transcriber.py translate --input spanish_audio.mp3 --output english_transcript.txt\npython3 scripts/whisper_transcriber.py detect-language --input audio.mp3\n```"
            },
            {
              "slug": "udio-composer",
              "name": "udio-composer",
              "id": "OC-0101",
              "version": "1.0.0",
              "description": "Udio AI music generation â€“ compose and download original music tracks",
              "commands": [
                "generate",
                "get-track",
                "list-tracks",
                "download"
              ],
              "env": [
                "UDIO_AUTH_TOKEN"
              ],
              "path": "ai-media-generation/audio-music/udio-composer",
              "markdownBody": "# Udio Composer\n\nGenerate original AI music tracks in any style using Udio's composition engine.\n\n## Prerequisites\n- A valid `UDIO_AUTH_TOKEN` environment variable.\n\n## Commands\n| Command       | Description                             |\n|---------------|-----------------------------------------|\n| `generate`    | Generate a new music track from a prompt|\n| `get-track`   | Get details and status of a track       |\n| `list-tracks` | List recently generated tracks          |\n| `download`    | Download a track to an MP3 file         |\n\n## Usage\n```bash\nexport UDIO_AUTH_TOKEN=\"your_token\"\npython3 scripts/udio_composer.py generate --prompt \"Cinematic orchestral score, epic battle scene\" --wait --output-dir ./music\npython3 scripts/udio_composer.py get-track --track-id \"track_abc123\"\npython3 scripts/udio_composer.py list-tracks --limit 10\npython3 scripts/udio_composer.py download --track-id \"track_abc123\" --output track.mp3\n```"
            },
            {
              "slug": "suno-songwriter",
              "name": "suno-songwriter",
              "id": "OC-0100",
              "version": "1.0.0",
              "description": "Suno AI music generation â€“ create full songs with vocals from text prompts",
              "commands": [
                "generate",
                "get-song",
                "list-songs",
                "download"
              ],
              "env": [
                "SUNO_COOKIE"
              ],
              "path": "ai-media-generation/audio-music/suno-songwriter",
              "markdownBody": "# Suno Songwriter\n\nGenerate full AI-composed songs with vocals using Suno AI from text descriptions.\n\n## Prerequisites\n- A valid `SUNO_COOKIE` environment variable (session cookie from studio.suno.ai).\n\n## Commands\n| Command      | Description                                |\n|--------------|--------------------------------------------|\n| `generate`   | Generate a new song from a prompt          |\n| `get-song`   | Get details and status of a song           |\n| `list-songs` | List recently generated songs              |\n| `download`   | Download a song to an MP3 file             |\n\n## Usage\n```bash\nexport SUNO_COOKIE=\"your_session_cookie\"\npython3 scripts/suno_songwriter.py generate --prompt \"Upbeat pop song about summer adventures\" --wait --output-dir ./music\npython3 scripts/suno_songwriter.py generate --prompt \"Sad blues piano ballad\" --make-instrumental --wait --output-dir ./music\npython3 scripts/suno_songwriter.py get-song --song-id \"song_abc123\"\npython3 scripts/suno_songwriter.py list-songs --limit 10\npython3 scripts/suno_songwriter.py download --song-id \"song_abc123\" --output song.mp3\n```"
            },
            {
              "slug": "sound-effect-foley",
              "name": "sound-effect-foley",
              "id": "OC-0103",
              "version": "1.0.0",
              "description": "Generate sound effects using ElevenLabs sound generation API",
              "commands": [
                "generate",
                "list-examples"
              ],
              "env": [
                "ELEVENLABS_API_KEY"
              ],
              "path": "ai-media-generation/audio-music/sound-effect-foley",
              "markdownBody": "# Sound Effect Foley\n\nGenerate realistic sound effects from text descriptions using ElevenLabs' sound generation API.\n\n## Prerequisites\n- A valid `ELEVENLABS_API_KEY` environment variable.\n\n## Commands\n| Command          | Description                                   |\n|------------------|-----------------------------------------------|\n| `generate`       | Generate a sound effect from a text prompt    |\n| `list-examples`  | Show example prompts for various SFX types    |\n\n## Usage\n```bash\nexport ELEVENLABS_API_KEY=\"your_key\"\npython3 scripts/sound_effect_foley.py generate --text \"Heavy rain on a tin roof with distant thunder\" --output rain.mp3\npython3 scripts/sound_effect_foley.py generate --text \"Gunshot in a large empty warehouse\" --duration 2.0 --output shot.mp3\npython3 scripts/sound_effect_foley.py list-examples\n```"
            },
            {
              "slug": "elevenlabs-voice",
              "name": "elevenlabs-voice",
              "id": "OC-0102",
              "version": "1.0.0",
              "description": "ElevenLabs TTS with voice cloning â€“ generate speech in any voice",
              "commands": [
                "speak",
                "list-voices",
                "clone-voice",
                "get-voice",
                "delete-voice",
                "list-models"
              ],
              "env": [
                "ELEVENLABS_API_KEY"
              ],
              "path": "ai-media-generation/audio-music/elevenlabs-voice",
              "markdownBody": "# ElevenLabs Voice\n\nGenerate ultra-realistic speech and clone voices using ElevenLabs' TTS platform.\n\n## Prerequisites\n- A valid `ELEVENLABS_API_KEY` environment variable.\n\n## Commands\n| Command        | Description                              |\n|----------------|------------------------------------------|\n| `speak`        | Convert text to speech                   |\n| `list-voices`  | List all available voices with IDs       |\n| `clone-voice`  | Create a voice clone from audio samples  |\n| `get-voice`    | Get details of a specific voice          |\n| `delete-voice` | Delete a cloned voice                    |\n| `list-models`  | List available TTS models                |\n\n## Usage\n```bash\nexport ELEVENLABS_API_KEY=\"your_key\"\npython3 scripts/elevenlabs_voice.py speak --text \"Hello, welcome to our platform!\" --output greeting.mp3\npython3 scripts/elevenlabs_voice.py speak --text \"Narration text here\" --voice-id \"voice_id\" --model eleven_multilingual_v2 --output narration.mp3\npython3 scripts/elevenlabs_voice.py list-voices\npython3 scripts/elevenlabs_voice.py clone-voice --name \"My Voice\" --files sample1.mp3 sample2.mp3 --description \"Custom voice clone\"\npython3 scripts/elevenlabs_voice.py get-voice --voice-id \"voice_id\"\npython3 scripts/elevenlabs_voice.py delete-voice --voice-id \"voice_id\"\npython3 scripts/elevenlabs_voice.py list-models\n```"
            },
            {
              "slug": "audio-stem-splitter",
              "name": "audio-stem-splitter",
              "id": "OC-0105",
              "version": "1.0.0",
              "description": "Split audio into stems using Demucs via Replicate â€“ separate vocals, bass, drums, other",
              "commands": [
                "split",
                "split-four-stems",
                "list-models"
              ],
              "env": [
                "REPLICATE_API_TOKEN"
              ],
              "path": "ai-media-generation/audio-music/audio-stem-splitter",
              "markdownBody": "# Audio Stem Splitter\n\nSeparate audio tracks into individual stems (vocals, bass, drums, other) using Demucs on Replicate.\n\n## Prerequisites\n- A valid `REPLICATE_API_TOKEN` environment variable.\n\n## Commands\n| Command             | Description                                        |\n|---------------------|----------------------------------------------------|\n| `split`             | Split audio into selected stems                    |\n| `split-four-stems`  | Split audio into all four stems at once            |\n| `list-models`       | List available stem separation models              |\n\n## Usage\n```bash\nexport REPLICATE_API_TOKEN=\"r8_...\"\npython3 scripts/audio_stem_splitter.py split --input song.mp3 --stems vocals --output-dir ./stems\npython3 scripts/audio_stem_splitter.py split --input song.mp3 --stems all --output-dir ./stems\npython3 scripts/audio_stem_splitter.py split-four-stems --input song.mp3 --output-dir ./stems\npython3 scripts/audio_stem_splitter.py list-models\n```"
            }
          ]
        },
        {
          "slug": "image-editing",
          "name": "Image Editing",
          "skills": [
            {
              "slug": "style-transfer",
              "name": "style-transfer",
              "id": "OC-0092",
              "version": "1.0.0",
              "description": "Apply artistic styles to images using fofr/style-transfer via Replicate",
              "commands": [
                "transfer",
                "list-styles"
              ],
              "env": [
                "REPLICATE_API_TOKEN"
              ],
              "path": "ai-media-generation/image-editing/style-transfer",
              "markdownBody": "# Style Transfer\n\nApply any artistic style to images using Replicate's style-transfer model.\n\n## Prerequisites\n- A valid `REPLICATE_API_TOKEN` environment variable.\n\n## Commands\n| Command        | Description                              |\n|----------------|------------------------------------------|\n| `transfer`     | Apply a style image to a content image   |\n| `list-styles`  | Show popular style preset descriptions   |\n\n## Usage\n```bash\nexport REPLICATE_API_TOKEN=\"r8_...\"\npython3 scripts/style_transfer.py transfer --content photo.jpg --style artwork.jpg --output styled.png\npython3 scripts/style_transfer.py transfer --content portrait.jpg --style monet.jpg --style-strength 0.7 --output monet_portrait.png\npython3 scripts/style_transfer.py list-styles\n```"
            },
            {
              "slug": "inpainting-agent",
              "name": "inpainting-agent",
              "id": "OC-0091",
              "version": "1.0.0",
              "description": "AI image inpainting â€“ fill, erase, and search-replace image regions via Stability AI",
              "commands": [
                "inpaint",
                "erase",
                "search-and-replace"
              ],
              "env": [
                "STABILITY_API_KEY"
              ],
              "path": "ai-media-generation/image-editing/inpainting-agent",
              "markdownBody": "# Inpainting Agent\n\nFill, erase, or replace regions in images using Stability AI's inpainting API.\n\n## Prerequisites\n- A valid `STABILITY_API_KEY` environment variable.\n\n## Commands\n| Command               | Description                                        |\n|-----------------------|----------------------------------------------------|\n| `inpaint`             | Fill a masked region using a text prompt           |\n| `erase`               | Erase a masked region from an image                |\n| `search-and-replace`  | Find and replace an object described in a prompt   |\n\n## Usage\n```bash\nexport STABILITY_API_KEY=\"sk-...\"\npython3 scripts/inpainting_agent.py inpaint --input scene.png --mask mask.png --prompt \"A red sports car\" --output result.png\npython3 scripts/inpainting_agent.py erase --input photo.png --mask watermark_mask.png --output clean.png\npython3 scripts/inpainting_agent.py search-and-replace --input photo.png --search-prompt \"blue car\" --prompt \"red Ferrari\" --output swapped.png\n```"
            },
            {
              "slug": "face-restoration",
              "name": "face-restoration",
              "id": "OC-0093",
              "version": "1.0.0",
              "description": "Restore and enhance faces in photos using GFPGAN via Replicate",
              "commands": [
                "restore",
                "enhance"
              ],
              "env": [
                "REPLICATE_API_TOKEN"
              ],
              "path": "ai-media-generation/image-editing/face-restoration",
              "markdownBody": "# Face Restoration\n\nRestore and enhance degraded faces using GFPGAN running on Replicate.\n\n## Prerequisites\n- A valid `REPLICATE_API_TOKEN` environment variable.\n\n## Commands\n| Command    | Description                                        |\n|------------|----------------------------------------------------|\n| `restore`  | Restore faces in an image using GFPGAN             |\n| `enhance`  | Restore faces with optional background upsampling  |\n\n## Usage\n```bash\nexport REPLICATE_API_TOKEN=\"r8_...\"\npython3 scripts/face_restoration.py restore --input old_photo.jpg --scale 2 --output restored.png\npython3 scripts/face_restoration.py enhance --input portrait.jpg --scale 4 --bg-upsampler --output enhanced.png\n```"
            },
            {
              "slug": "background-remover",
              "name": "background-remover",
              "id": "OC-0089",
              "version": "1.0.0",
              "description": "Remove image backgrounds instantly using the remove.bg API",
              "commands": [
                "remove",
                "bulk-remove"
              ],
              "env": [
                "REMOVEBG_API_KEY"
              ],
              "path": "ai-media-generation/image-editing/background-remover",
              "markdownBody": "# Background Remover\n\nRemove backgrounds from images with high accuracy using the remove.bg API.\n\n## Prerequisites\n- A valid `REMOVEBG_API_KEY` environment variable.\n\n## Commands\n| Command        | Description                                    |\n|----------------|------------------------------------------------|\n| `remove`       | Remove background from a single image          |\n| `bulk-remove`  | Remove backgrounds from all images in a folder |\n\n## Usage\n```bash\nexport REMOVEBG_API_KEY=\"your_key\"\npython3 scripts/background_remover.py remove --input photo.jpg --output nobg.png --size hd --type person\npython3 scripts/background_remover.py bulk-remove --input-dir ./photos --output-dir ./nobg --size regular\n```"
            },
            {
              "slug": "ai-upscaler",
              "name": "ai-upscaler",
              "id": "OC-0090",
              "version": "1.0.0",
              "description": "AI image upscaling using Real-ESRGAN via Replicate â€“ enhance resolution up to 8x",
              "commands": [
                "upscale",
                "batch-upscale"
              ],
              "env": [
                "REPLICATE_API_TOKEN"
              ],
              "path": "ai-media-generation/image-editing/ai-upscaler",
              "markdownBody": "# AI Upscaler\n\nUpscale images up to 8x using Real-ESRGAN via Replicate with optional face enhancement.\n\n## Prerequisites\n- A valid `REPLICATE_API_TOKEN` environment variable.\n\n## Commands\n| Command          | Description                                |\n|------------------|--------------------------------------------|\n| `upscale`        | Upscale a single image                     |\n| `batch-upscale`  | Upscale all images in a directory          |\n\n## Usage\n```bash\nexport REPLICATE_API_TOKEN=\"r8_...\"\npython3 scripts/ai_upscaler.py upscale --input photo.jpg --scale 4 --output upscaled.png\npython3 scripts/ai_upscaler.py upscale --input portrait.jpg --scale 2 --face-enhance --output enhanced.png\npython3 scripts/ai_upscaler.py batch-upscale --input-dir ./originals --output-dir ./upscaled --scale 4\n```"
            }
          ]
        },
        {
          "slug": "image-generation",
          "name": "Image Generation",
          "skills": [
            {
              "slug": "stable-diffusion",
              "name": "stable-diffusion",
              "id": "OC-0084",
              "version": "1.0.0",
              "description": "Stability AI SDXL image generation â€“ generate, upscale, and inpaint images",
              "commands": [
                "generate",
                "upscale",
                "inpaint",
                "list-engines"
              ],
              "env": [
                "STABILITY_API_KEY"
              ],
              "path": "ai-media-generation/image-generation/stable-diffusion",
              "markdownBody": "# Stable Diffusion (SDXL)\n\nGenerate, upscale, and inpaint images using Stability AI's SDXL models.\n\n## Prerequisites\n- A valid `STABILITY_API_KEY` environment variable.\n\n## Commands\n| Command         | Description                                |\n|-----------------|--------------------------------------------|\n| `generate`      | Generate an image from a text prompt       |\n| `upscale`       | Upscale an existing image                  |\n| `inpaint`       | Fill a masked region with generated content|\n| `list-engines`  | List available Stability AI engines        |\n\n## Usage\n```bash\nexport STABILITY_API_KEY=\"sk-...\"\npython3 scripts/stable_diffusion.py generate --prompt \"A wolf howling at the moon\" --width 1024 --height 1024 --output wolf.png\npython3 scripts/stable_diffusion.py upscale --input image.png --width 2048 --output upscaled.png\npython3 scripts/stable_diffusion.py inpaint --init-image base.png --mask-image mask.png --prompt \"A garden\" --output result.png\npython3 scripts/stable_diffusion.py list-engines\n```"
            },
            {
              "slug": "midjourney-prompter",
              "name": "midjourney-prompter",
              "id": "OC-0083",
              "version": "1.0.0",
              "description": "Midjourney image generation â€“ create and manage AI-generated artwork via useapi.net",
              "commands": [
                "imagine",
                "upscale",
                "variations",
                "status",
                "list-jobs"
              ],
              "env": [
                "MIDJOURNEY_API_KEY"
              ],
              "path": "ai-media-generation/image-generation/midjourney-prompter",
              "markdownBody": "# Midjourney Prompter\n\nGenerate stunning AI artwork using Midjourney via the useapi.net unofficial API.\n\n## Prerequisites\n- A valid `MIDJOURNEY_API_KEY` environment variable (from useapi.net).\n\n## Commands\n| Command       | Description                                      |\n|---------------|--------------------------------------------------|\n| `imagine`     | Generate an image from a prompt                  |\n| `upscale`     | Upscale a specific image from a job              |\n| `variations`  | Create variations of a job image                 |\n| `status`      | Get status of a job                              |\n| `list-jobs`   | List recent generation jobs                      |\n\n## Usage\n```bash\nexport MIDJOURNEY_API_KEY=\"your_key\"\npython3 scripts/midjourney_prompter.py imagine --prompt \"A serene mountain lake, photorealistic\" --ar 16:9 --output mountain.png\npython3 scripts/midjourney_prompter.py upscale --job-id \"abc123\" --index 1\npython3 scripts/midjourney_prompter.py variations --job-id \"abc123\" --index 2\npython3 scripts/midjourney_prompter.py status --job-id \"abc123\"\npython3 scripts/midjourney_prompter.py list-jobs --limit 5\n```"
            },
            {
              "slug": "leonardo-ai",
              "name": "leonardo-ai",
              "id": "OC-0086",
              "version": "1.0.0",
              "description": "Leonardo.ai image generation â€“ create images with fine-tuned models",
              "commands": [
                "generate",
                "get-generation",
                "list-models",
                "list-generations"
              ],
              "env": [
                "LEONARDO_API_KEY"
              ],
              "path": "ai-media-generation/image-generation/leonardo-ai",
              "markdownBody": "# Leonardo.ai\n\nGenerate images using Leonardo.ai's fine-tuned models with full parameter control.\n\n## Prerequisites\n- A valid `LEONARDO_API_KEY` environment variable.\n\n## Commands\n| Command            | Description                            |\n|--------------------|----------------------------------------|\n| `generate`         | Generate images from a prompt          |\n| `get-generation`   | Get details of a generation by ID      |\n| `list-models`      | List available Leonardo models         |\n| `list-generations` | List recent generations                |\n\n## Usage\n```bash\nexport LEONARDO_API_KEY=\"your_key\"\npython3 scripts/leonardo_ai.py generate --prompt \"Portrait of an astronaut\" --num-images 2 --output-dir ./output\npython3 scripts/leonardo_ai.py get-generation --generation-id \"gen_abc123\"\npython3 scripts/leonardo_ai.py list-models\npython3 scripts/leonardo_ai.py list-generations --limit 5\n```"
            },
            {
              "slug": "ideogram-typographer",
              "name": "ideogram-typographer",
              "id": "OC-0087",
              "version": "1.0.0",
              "description": "Ideogram AI image generation â€“ excels at rendering readable text within images",
              "commands": [
                "generate",
                "remix",
                "describe",
                "list-styles"
              ],
              "env": [
                "IDEOGRAM_API_KEY"
              ],
              "path": "ai-media-generation/image-generation/ideogram-typographer",
              "markdownBody": "# Ideogram Typographer\n\nGenerate images with accurate text rendering using Ideogram AI's V2 model.\n\n## Prerequisites\n- A valid `IDEOGRAM_API_KEY` environment variable.\n\n## Commands\n| Command        | Description                                    |\n|----------------|------------------------------------------------|\n| `generate`     | Generate an image from a prompt                |\n| `remix`        | Remix an existing image with a new prompt      |\n| `describe`     | Get a text description of an image             |\n| `list-styles`  | List available style types                     |\n\n## Usage\n```bash\nexport IDEOGRAM_API_KEY=\"your_key\"\npython3 scripts/ideogram_typographer.py generate --prompt \"A coffee shop menu with bold text\" --style-type DESIGN --output menu.png\npython3 scripts/ideogram_typographer.py remix --input original.png --prompt \"Same but in dark mode\" --strength 0.6 --output remixed.png\npython3 scripts/ideogram_typographer.py describe --input photo.png\npython3 scripts/ideogram_typographer.py list-styles\n```"
            },
            {
              "slug": "flux-generator",
              "name": "flux-generator",
              "id": "OC-0085",
              "version": "1.0.0",
              "description": "FLUX image generation â€“ fast high-quality images via Replicate (Schnell/Dev)",
              "commands": [
                "generate",
                "list-models"
              ],
              "env": [
                "REPLICATE_API_TOKEN"
              ],
              "path": "ai-media-generation/image-generation/flux-generator",
              "markdownBody": "# FLUX Generator\n\nGenerate high-quality images using FLUX Schnell or Dev models via Replicate.\n\n## Prerequisites\n- A valid `REPLICATE_API_TOKEN` environment variable.\n\n## Commands\n| Command        | Description                          |\n|----------------|--------------------------------------|\n| `generate`     | Generate an image from a prompt      |\n| `list-models`  | List available FLUX models           |\n\n## Usage\n```bash\nexport REPLICATE_API_TOKEN=\"r8_...\"\npython3 scripts/flux_generator.py generate --prompt \"Neon cyberpunk street at night\" --model schnell --output image.png\npython3 scripts/flux_generator.py generate --prompt \"Oil painting of a lighthouse\" --model dev --steps 25 --output painting.png\npython3 scripts/flux_generator.py list-models\n```"
            },
            {
              "slug": "dalle3-artist",
              "name": "dalle3-artist",
              "id": "OC-0082",
              "version": "1.0.0",
              "description": "DALL-E 3 image generation â€“ generate high-quality images from text prompts",
              "commands": [
                "generate",
                "variations",
                "list-models"
              ],
              "env": [
                "OPENAI_API_KEY"
              ],
              "path": "ai-media-generation/image-generation/dalle3-artist",
              "markdownBody": "# DALL-E 3 Artist\n\nGenerate high-quality images from text prompts using OpenAI's DALL-E 3 model.\n\n## Prerequisites\n- A valid `OPENAI_API_KEY` environment variable.\n\n## Commands\n| Command        | Description                              |\n|----------------|------------------------------------------|\n| `generate`     | Generate an image from a text prompt     |\n| `variations`   | Create variations of an existing image   |\n| `list-models`  | List available DALL-E models             |\n\n## Usage\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\npython3 scripts/dalle3_artist.py generate --prompt \"A futuristic city at sunset\" --size 1024x1024 --quality hd --output city.png\npython3 scripts/dalle3_artist.py variations --input image.png --n 2 --output variation.png\npython3 scripts/dalle3_artist.py list-models\n```"
            },
            {
              "slug": "adobe-firefly",
              "name": "adobe-firefly",
              "id": "OC-0088",
              "version": "1.0.0",
              "description": "Adobe Firefly image generation â€“ generate, expand, and edit images via Adobe's API",
              "commands": [
                "generate",
                "expand",
                "remove-background",
                "generative-fill",
                "list-styles"
              ],
              "env": [
                "FIREFLY_CLIENT_ID",
                "FIREFLY_CLIENT_SECRET"
              ],
              "path": "ai-media-generation/image-generation/adobe-firefly",
              "markdownBody": "# Adobe Firefly\n\nGenerate and manipulate images using Adobe Firefly's commercial-safe generative AI.\n\n## Prerequisites\n- A valid `FIREFLY_CLIENT_ID` environment variable.\n- A valid `FIREFLY_CLIENT_SECRET` environment variable.\n\n## Commands\n| Command               | Description                                    |\n|-----------------------|------------------------------------------------|\n| `generate`            | Generate images from a text prompt             |\n| `expand`              | Expand image canvas with AI-generated content  |\n| `remove-background`   | Remove the background from an image            |\n| `generative-fill`     | Fill a masked area with generated content      |\n| `list-styles`         | List available content styles                  |\n\n## Usage\n```bash\nexport FIREFLY_CLIENT_ID=\"your_client_id\"\nexport FIREFLY_CLIENT_SECRET=\"your_client_secret\"\npython3 scripts/adobe_firefly.py generate --prompt \"A serene Japanese garden\" --output-dir ./output\npython3 scripts/adobe_firefly.py expand --input photo.png --right 512 --prompt \"More garden\" --output expanded.png\npython3 scripts/adobe_firefly.py remove-background --input portrait.png --output nobg.png\npython3 scripts/adobe_firefly.py generative-fill --input photo.png --mask mask.png --prompt \"A stone fountain\" --output filled.png\npython3 scripts/adobe_firefly.py list-styles\n```"
            }
          ]
        },
        {
          "slug": "video-generation",
          "name": "Video Generation",
          "skills": [
            {
              "slug": "runway-gen3",
              "name": "runway-gen3",
              "id": "OC-0094",
              "version": "1.0.0",
              "description": "Runway Gen-3 Alpha video generation â€“ create videos from text or images",
              "commands": [
                "generate",
                "image-to-video",
                "get-task",
                "list-tasks"
              ],
              "env": [
                "RUNWAYML_API_SECRET"
              ],
              "path": "ai-media-generation/video-generation/runway-gen3",
              "markdownBody": "# Runway Gen-3\n\nGenerate cinematic videos from text prompts or images using Runway Gen-3 Alpha.\n\n## Prerequisites\n- A valid `RUNWAYML_API_SECRET` environment variable.\n\n## Commands\n| Command          | Description                              |\n|------------------|------------------------------------------|\n| `generate`       | Generate a video from a text prompt      |\n| `image-to-video` | Animate an image with a text prompt      |\n| `get-task`       | Get status and result of a video task    |\n| `list-tasks`     | List recent generation tasks             |\n\n## Usage\n```bash\nexport RUNWAYML_API_SECRET=\"your_secret\"\npython3 scripts/runway_gen3.py generate --prompt \"A drone shot flying over a forest\" --duration 10 --output-dir ./videos\npython3 scripts/runway_gen3.py image-to-video --input photo.jpg --prompt \"The scene comes to life\" --output-dir ./videos\npython3 scripts/runway_gen3.py get-task --task-id \"task_abc123\"\npython3 scripts/runway_gen3.py list-tasks --limit 5\n```"
            },
            {
              "slug": "pika-animator",
              "name": "pika-animator",
              "id": "OC-0095",
              "version": "1.0.0",
              "description": "Pika Labs video animation â€“ animate images and generate videos from text",
              "commands": [
                "animate",
                "text-to-video",
                "get-video",
                "list-videos"
              ],
              "env": [
                "PIKA_API_KEY"
              ],
              "path": "ai-media-generation/video-generation/pika-animator",
              "markdownBody": "# Pika Animator\n\nAnimate images and generate videos from text using Pika Labs' AI video platform.\n\n## Prerequisites\n- A valid `PIKA_API_KEY` environment variable.\n\n## Commands\n| Command          | Description                                |\n|------------------|--------------------------------------------|\n| `animate`        | Animate a static image                     |\n| `text-to-video`  | Generate a video from a text prompt        |\n| `get-video`      | Get status and download URL of a video     |\n| `list-videos`    | List recent video generations              |\n\n## Usage\n```bash\nexport PIKA_API_KEY=\"your_key\"\npython3 scripts/pika_animator.py animate --input photo.jpg --prompt \"Gentle breeze\" --motion-strength 3 --output-dir ./videos\npython3 scripts/pika_animator.py text-to-video --prompt \"A rocket launching into space\" --duration 5 --ratio 16:9 --output-dir ./videos\npython3 scripts/pika_animator.py get-video --video-id \"vid_abc123\"\npython3 scripts/pika_animator.py list-videos --limit 10\n```"
            },
            {
              "slug": "luma-dream-machine",
              "name": "luma-dream-machine",
              "id": "OC-0096",
              "version": "1.0.0",
              "description": "Luma AI Dream Machine â€“ generate and extend videos from text or images",
              "commands": [
                "generate",
                "image-to-video",
                "extend",
                "get-generation",
                "list-generations"
              ],
              "env": [
                "LUMAAI_API_KEY"
              ],
              "path": "ai-media-generation/video-generation/luma-dream-machine",
              "markdownBody": "# Luma Dream Machine\n\nGenerate high-quality, realistic videos using Luma AI's Dream Machine model.\n\n## Prerequisites\n- A valid `LUMAAI_API_KEY` environment variable.\n\n## Commands\n| Command            | Description                              |\n|--------------------|------------------------------------------|\n| `generate`         | Generate a video from a text prompt      |\n| `image-to-video`   | Create a video starting from an image    |\n| `extend`           | Extend an existing video generation      |\n| `get-generation`   | Get status/result of a generation        |\n| `list-generations` | List recent video generations            |\n\n## Usage\n```bash\nexport LUMAAI_API_KEY=\"your_key\"\npython3 scripts/luma_dream_machine.py generate --prompt \"Waves crashing on a rocky shore\" --aspect-ratio 16:9 --output-dir ./videos\npython3 scripts/luma_dream_machine.py image-to-video --input photo.jpg --prompt \"The scene slowly pans right\" --output-dir ./videos\npython3 scripts/luma_dream_machine.py extend --generation-id \"gen_abc123\" --prompt \"Continue zooming out\" --output-dir ./videos\npython3 scripts/luma_dream_machine.py get-generation --generation-id \"gen_abc123\"\npython3 scripts/luma_dream_machine.py list-generations --limit 5\n```"
            },
            {
              "slug": "kling-generator",
              "name": "kling-generator",
              "id": "OC-0097",
              "version": "1.0.0",
              "description": "Kling AI video generation â€“ create videos from text or images with KLING models",
              "commands": [
                "text-to-video",
                "image-to-video",
                "get-task",
                "list-tasks"
              ],
              "env": [
                "KLING_ACCESS_KEY",
                "KLING_SECRET_KEY"
              ],
              "path": "ai-media-generation/video-generation/kling-generator",
              "markdownBody": "# Kling Generator\n\nGenerate high-quality videos from text or images using Kling AI's video models.\n\n## Prerequisites\n- A valid `KLING_ACCESS_KEY` environment variable.\n- A valid `KLING_SECRET_KEY` environment variable.\n\n## Commands\n| Command           | Description                              |\n|-------------------|------------------------------------------|\n| `text-to-video`   | Generate a video from a text prompt      |\n| `image-to-video`  | Animate an image into a video            |\n| `get-task`        | Get status and result of a task          |\n| `list-tasks`      | List recent video generation tasks       |\n\n## Usage\n```bash\nexport KLING_ACCESS_KEY=\"your_access_key\"\nexport KLING_SECRET_KEY=\"your_secret_key\"\npython3 scripts/kling_generator.py text-to-video --prompt \"A bird flying over mountains\" --duration 5 --mode pro --output-dir ./videos\npython3 scripts/kling_generator.py image-to-video --input scene.jpg --prompt \"The clouds begin to move\" --output-dir ./videos\npython3 scripts/kling_generator.py get-task --task-id \"task_abc123\"\npython3 scripts/kling_generator.py list-tasks --limit 10\n```"
            },
            {
              "slug": "ffmpeg-processor",
              "name": "ffmpeg-processor",
              "id": "OC-0098",
              "version": "1.0.0",
              "description": "FFmpeg video processing â€“ cut, merge, transcode, watermark, and more",
              "commands": [
                "cut",
                "merge",
                "transcode",
                "watermark",
                "extract-audio",
                "resize",
                "info"
              ],
              "env": [],
              "path": "ai-media-generation/video-generation/ffmpeg-processor",
              "markdownBody": "# FFmpeg Processor\n\nProcess videos locally using FFmpeg: cut, merge, transcode, add watermarks, and extract audio.\n\n## Prerequisites\n- `ffmpeg` and `ffprobe` must be installed and available in your PATH.\n\n## Commands\n| Command          | Description                                    |\n|------------------|------------------------------------------------|\n| `cut`            | Cut a clip from a video by time range          |\n| `merge`          | Concatenate multiple videos into one           |\n| `transcode`      | Re-encode a video with a different codec       |\n| `watermark`      | Overlay an image watermark onto a video        |\n| `extract-audio`  | Extract the audio track from a video           |\n| `resize`         | Resize video to specific dimensions or scale   |\n| `info`           | Display video metadata and stream information  |\n\n## Usage\n```bash\npython3 scripts/ffmpeg_processor.py cut --input video.mp4 --start 00:00:10 --end 00:01:30 --output clip.mp4\npython3 scripts/ffmpeg_processor.py merge --inputs clip1.mp4 clip2.mp4 clip3.mp4 --output merged.mp4\npython3 scripts/ffmpeg_processor.py transcode --input video.mp4 --output output.mp4 --codec libx265 --crf 28\npython3 scripts/ffmpeg_processor.py watermark --input video.mp4 --watermark logo.png --position bottom-right --output branded.mp4\npython3 scripts/ffmpeg_processor.py extract-audio --input video.mp4 --output audio.mp3\npython3 scripts/ffmpeg_processor.py resize --input video.mp4 --width 1280 --height 720 --output resized.mp4\npython3 scripts/ffmpeg_processor.py info --input video.mp4\n```"
            },
            {
              "slug": "auto-subtitle",
              "name": "auto-subtitle",
              "id": "OC-0099",
              "version": "1.0.0",
              "description": "Auto-generate and burn subtitles using OpenAI Whisper API and FFmpeg",
              "commands": [
                "transcribe",
                "burn-subtitles",
                "generate-srt"
              ],
              "env": [
                "OPENAI_API_KEY"
              ],
              "path": "ai-media-generation/video-generation/auto-subtitle",
              "markdownBody": "# Auto Subtitle\n\nAutomatically transcribe speech and burn subtitles into videos using Whisper and FFmpeg.\n\n## Prerequisites\n- A valid `OPENAI_API_KEY` environment variable.\n- `ffmpeg` must be installed and available in your PATH.\n\n## Commands\n| Command           | Description                                        |\n|-------------------|----------------------------------------------------|\n| `transcribe`      | Transcribe audio/video to a subtitle file          |\n| `burn-subtitles`  | Burn a subtitle file permanently into a video      |\n| `generate-srt`    | Transcribe and save directly as SRT in one step    |\n\n## Usage\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\npython3 scripts/auto_subtitle.py transcribe --input video.mp4 --output captions.srt\npython3 scripts/auto_subtitle.py burn-subtitles --video video.mp4 --subtitles captions.srt --output captioned.mp4\npython3 scripts/auto_subtitle.py generate-srt --input video.mp4 --language en --output captions.srt\n```"
            }
          ]
        }
      ],
      "skills": [],
      "skillCount": 24
    },
    {
      "slug": "productivity",
      "name": "Productivity",
      "icon": "ðŸ“‹",
      "subcategories": [],
      "skills": [
        {
          "slug": "todoist-sync",
          "name": "todoist-sync",
          "id": "OC-0129",
          "version": "1.0.0",
          "description": "Todoist Sync - Manage Todoist tasks and projects via REST API v2",
          "commands": [
            "list-tasks",
            "add-task",
            "complete-task",
            "list-projects",
            "move-task"
          ],
          "env": [
            "TODOIST_API_TOKEN"
          ],
          "path": "productivity/todoist-sync",
          "markdownBody": "# Todoist Sync\n\nManage Todoist tasks and projects from the CLI using the Todoist REST API v2.\n\n## Prerequisites\n\n- `TODOIST_API_TOKEN` â€” Todoist API token (Settings â†’ Integrations â†’ Developer â†’ API token)\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-tasks` | List tasks, optionally filtered by project or filter string |\n| `add-task` | Add a new task |\n| `complete-task` | Mark a task as complete |\n| `list-projects` | List all projects |\n| `move-task` | Move a task to a different project |\n\n## Usage\n\n```bash\n# List all tasks\npython todoist_sync.py list-tasks\n\n# List tasks in a specific project\npython todoist_sync.py list-tasks --project-id 12345678\n\n# Add a task\npython todoist_sync.py add-task --content \"Write report\" --due-string \"tomorrow\" --priority 4\n\n# Complete a task\npython todoist_sync.py complete-task --id TASK_ID\n\n# List all projects\npython todoist_sync.py list-projects\n\n# Move task to another project\npython todoist_sync.py move-task --id TASK_ID --project-id NEW_PROJECT_ID\n```"
        },
        {
          "slug": "timezone-converter",
          "name": "timezone-converter",
          "id": "OC-0136",
          "version": "1.0.0",
          "description": "Time Zone Converter - Resolve scheduling across multiple time zones intelligently",
          "commands": [
            "convert",
            "list-zones",
            "best-time",
            "now"
          ],
          "env": [],
          "path": "productivity/timezone-converter",
          "markdownBody": "# Time Zone Converter\n\nResolve scheduling across multiple time zones. Convert times, find overlapping business hours, and pick the best meeting time for distributed teams.\n\n## Prerequisites\n\n- Python 3.8+\n- `pytz` library (`pip install pytz`)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `convert` | Convert a time from one zone to others |\n| `list-zones` | List common time zones by region |\n| `best-time` | Find best meeting overlap for a set of zones |\n| `now` | Show current time in multiple zones |\n\n## Usage\n\n```bash\n# Convert a specific time to multiple zones\npython3 scripts/timezone_converter.py convert --time \"2024-12-15 09:00\" --from-zone \"America/New_York\" --to-zones \"Europe/London,Asia/Tokyo,America/Los_Angeles\"\n\n# Show current time in multiple zones\npython3 scripts/timezone_converter.py now --zones \"America/New_York,Europe/London,Asia/Singapore\"\n\n# Find best meeting time (9am-5pm overlap) for multiple zones\npython3 scripts/timezone_converter.py best-time --zones \"America/New_York,Europe/London,Asia/Tokyo\"\n\n# List all zones in a region\npython3 scripts/timezone_converter.py list-zones --region US\n```"
        },
        {
          "slug": "outlook-manager",
          "name": "outlook-manager",
          "id": "OC-0138",
          "version": "1.0.0",
          "description": "Outlook Mail Manager - Manage emails and calendar within Microsoft 365",
          "commands": [
            "list-unread",
            "send-email",
            "reply",
            "move-to-folder",
            "list-folders",
            "search"
          ],
          "env": [
            "OUTLOOK_TOKEN"
          ],
          "path": "productivity/outlook-manager",
          "markdownBody": "# Outlook Mail Manager\n\nManage Microsoft 365 emails and calendar events from the terminal via Microsoft Graph API.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OUTLOOK_TOKEN` â€” OAuth 2.0 bearer token with `Mail.ReadWrite`, `Mail.Send` scopes\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-unread` | List unread emails |\n| `send-email` | Send a new email |\n| `reply` | Reply to an email |\n| `move-to-folder` | Move email to a folder |\n| `list-folders` | List all mail folders |\n| `search` | Search emails by keyword |\n\n## Usage\n\n```bash\nexport OUTLOOK_TOKEN=\"your_graph_api_token\"\n\n# List up to 20 unread emails\npython3 scripts/outlook_manager.py list-unread --top 20\n\n# Send an email\npython3 scripts/outlook_manager.py send-email --to \"user@example.com\" --subject \"Hello\" --body \"Hi there!\"\n\n# Reply to an email\npython3 scripts/outlook_manager.py reply --message-id MESSAGE_ID --body \"Thanks for reaching out.\"\n\n# Move email to a folder\npython3 scripts/outlook_manager.py move-to-folder --message-id MESSAGE_ID --folder \"Archive\"\n\n# List all mail folders\npython3 scripts/outlook_manager.py list-folders\n\n# Search emails\npython3 scripts/outlook_manager.py search --query \"invoice\" --top 10\n```"
        },
        {
          "slug": "notion-task-manager",
          "name": "notion-task-manager",
          "id": "OC-0130",
          "version": "1.0.0",
          "description": "Notion Task Manager - Manage Notion database tasks via REST API",
          "commands": [
            "list-tasks",
            "create-task",
            "update-task",
            "filter-tasks",
            "archive-task"
          ],
          "env": [
            "NOTION_API_KEY",
            "NOTION_DATABASE_ID"
          ],
          "path": "productivity/notion-task-manager",
          "markdownBody": "# Notion Task Manager\n\nManage tasks stored in a Notion database via the Notion REST API.\n\n## Prerequisites\n\n- `NOTION_API_KEY` â€” Notion integration token (notion.so/my-integrations)\n- `NOTION_DATABASE_ID` â€” The ID of your Notion task database\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-tasks` | List all tasks with optional status filter |\n| `create-task` | Create a new task in the database |\n| `update-task` | Update a task's status or title |\n| `filter-tasks` | Filter tasks by a property value |\n| `archive-task` | Archive (soft-delete) a task page |\n\n## Usage\n\n```bash\n# List all tasks\npython notion_task_manager.py list-tasks\n\n# List tasks with status filter\npython notion_task_manager.py list-tasks --status-filter \"In Progress\"\n\n# Create a new task\npython notion_task_manager.py create-task --title \"Write docs\" --status \"Todo\" --due-date \"2024-12-31\"\n\n# Update a task\npython notion_task_manager.py update-task --page-id PAGE_ID --status \"Done\"\n\n# Filter tasks by property\npython notion_task_manager.py filter-tasks --property \"Priority\" --value \"High\"\n\n# Archive a task\npython notion_task_manager.py archive-task --page-id PAGE_ID\n```"
        },
        {
          "slug": "meeting-prep-briefer",
          "name": "meeting-prep-briefer",
          "id": "OC-0135",
          "version": "1.0.0",
          "description": "Meeting Prep Briefer - Summarize attendees, agenda, and relevant docs before a meeting",
          "commands": [
            "brief",
            "list-upcoming",
            "summarize-doc"
          ],
          "env": [
            "GOOGLE_CALENDAR_TOKEN",
            "OPENAI_API_KEY"
          ],
          "path": "productivity/meeting-prep-briefer",
          "markdownBody": "# Meeting Prep Briefer\n\nPrepare comprehensive briefings for upcoming meetings by pulling calendar events, attendee info, and generating AI summaries.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `GOOGLE_CALENDAR_TOKEN` â€” OAuth 2.0 bearer token with calendar scope\n- `OPENAI_API_KEY` â€” OpenAI API key (for AI-generated summaries)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-upcoming` | List meetings scheduled in the next N hours |\n| `brief` | Generate a prep briefing for a specific event |\n| `summarize-doc` | Summarize a document URL for meeting context |\n\n## Usage\n\n```bash\nexport GOOGLE_CALENDAR_TOKEN=\"your_token\"\nexport OPENAI_API_KEY=\"your_key\"\n\n# List upcoming meetings in the next 24 hours\npython3 scripts/meeting_prep_briefer.py list-upcoming --hours 24\n\n# Generate a briefing for the next meeting\npython3 scripts/meeting_prep_briefer.py brief --event-id EVENT_ID\n\n# Summarize a document for context\npython3 scripts/meeting_prep_briefer.py summarize-doc --url \"https://docs.google.com/...\"\n```"
        },
        {
          "slug": "linear-issue-manager",
          "name": "linear-issue-manager",
          "id": "OC-0127",
          "version": "1.0.0",
          "description": "Linear Issue Manager - Manage Linear issues, cycles, and assignments via GraphQL API",
          "commands": [
            "list-issues",
            "create-issue",
            "update-issue",
            "list-cycles",
            "assign-issue"
          ],
          "env": [
            "LINEAR_API_KEY"
          ],
          "path": "productivity/linear-issue-manager",
          "markdownBody": "# Linear Issue Manager\n\nManage Linear issues, cycles, and team assignments directly from the CLI using the Linear GraphQL API.\n\n## Prerequisites\n\n- `LINEAR_API_KEY` â€” Linear personal API key (Settings â†’ API â†’ Personal API keys)\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-issues` | List issues for a team filtered by state |\n| `create-issue` | Create a new issue in a team |\n| `update-issue` | Update issue state or priority |\n| `list-cycles` | List cycles (sprints) for a team |\n| `assign-issue` | Assign an issue to a team member |\n\n## Usage\n\n```bash\n# List active issues for a team\npython linear_issue_manager.py list-issues --team-id TEAM_ID\n\n# List issues with a specific state\npython linear_issue_manager.py list-issues --team-id TEAM_ID --state \"In Progress\"\n\n# Create a new issue\npython linear_issue_manager.py create-issue --team-id TEAM_ID --title \"Fix login bug\" --description \"Users cannot log in\" --priority 2\n\n# Update an issue\npython linear_issue_manager.py update-issue --id ISSUE_ID --state \"Done\" --priority 1\n\n# List cycles for a team\npython linear_issue_manager.py list-cycles --team-id TEAM_ID\n\n# Assign issue to a user\npython linear_issue_manager.py assign-issue --id ISSUE_ID --assignee-id USER_ID\n```"
        },
        {
          "slug": "jira-ticket-handler",
          "name": "jira-ticket-handler",
          "id": "OC-0128",
          "version": "1.0.0",
          "description": "Jira Ticket Handler - Manage Jira tickets, sprints, and workflow transitions",
          "commands": [
            "list-issues",
            "create-ticket",
            "update-ticket",
            "list-sprints",
            "move-to-sprint"
          ],
          "env": [
            "JIRA_BASE_URL",
            "JIRA_EMAIL",
            "JIRA_API_TOKEN"
          ],
          "path": "productivity/jira-ticket-handler",
          "markdownBody": "# Jira Ticket Handler\n\nManage Jira issues, sprints, and workflow directly from the CLI using the Jira REST API v3.\n\n## Prerequisites\n\n- `JIRA_BASE_URL` â€” Your Jira instance URL (e.g., `https://yourcompany.atlassian.net`)\n- `JIRA_EMAIL` â€” Your Atlassian account email\n- `JIRA_API_TOKEN` â€” API token (Atlassian account settings â†’ Security â†’ API tokens)\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-issues` | List issues in a project with optional JQL filter |\n| `create-ticket` | Create a new Jira ticket |\n| `update-ticket` | Update ticket status or assignee |\n| `list-sprints` | List sprints on an agile board |\n| `move-to-sprint` | Move a ticket to a specific sprint |\n\n## Usage\n\n```bash\n# List issues in a project\npython jira_ticket_handler.py list-issues --project-key PROJ\n\n# List with JQL filter\npython jira_ticket_handler.py list-issues --project-key PROJ --jql \"status = 'In Progress'\"\n\n# Create a ticket\npython jira_ticket_handler.py create-ticket --project-key PROJ --summary \"Fix login bug\" --description \"Users cannot log in on mobile\"\n\n# Create a Bug type ticket\npython jira_ticket_handler.py create-ticket --project-key PROJ --summary \"NPE in auth\" --issue-type Bug\n\n# Update ticket status\npython jira_ticket_handler.py update-ticket --key PROJ-123 --status \"In Progress\"\n\n# List sprints on a board\npython jira_ticket_handler.py list-sprints --board-id 1\n\n# Move ticket to sprint\npython jira_ticket_handler.py move-to-sprint --ticket-key PROJ-123 --sprint-id 42\n```"
        },
        {
          "slug": "google-tasks",
          "name": "google-tasks",
          "id": "OC-0131",
          "version": "1.0.0",
          "description": "Google Tasks - Manage Google Tasks lists and tasks via REST API",
          "commands": [
            "list-tasks",
            "add-task",
            "complete-task",
            "list-lists",
            "delete-task"
          ],
          "env": [
            "GOOGLE_TASKS_TOKEN"
          ],
          "path": "productivity/google-tasks",
          "markdownBody": "# Google Tasks\n\nManage Google Tasks lists and individual tasks from the CLI using the Google Tasks API.\n\n## Prerequisites\n\n- `GOOGLE_TASKS_TOKEN` â€” OAuth 2.0 bearer access token with `tasks` scope\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-tasks` | List tasks in a task list |\n| `add-task` | Add a new task to a list |\n| `complete-task` | Mark a task as completed |\n| `list-lists` | List all task lists |\n| `delete-task` | Delete a task from a list |\n\n## Usage\n\n```bash\n# List all task lists\npython google_tasks.py list-lists\n\n# List tasks in the default list\npython google_tasks.py list-tasks --list-id @default\n\n# List tasks including completed\npython google_tasks.py list-tasks --list-id LIST_ID --show-completed\n\n# Add a task\npython google_tasks.py add-task --list-id @default --title \"Buy groceries\" --notes \"Milk, eggs\" --due \"2024-12-31T00:00:00.000Z\"\n\n# Complete a task\npython google_tasks.py complete-task --list-id @default --task-id TASK_ID\n\n# Delete a task\npython google_tasks.py delete-task --list-id @default --task-id TASK_ID\n```"
        },
        {
          "slug": "google-calendar",
          "name": "google-calendar",
          "id": "OC-0133",
          "version": "1.0.0",
          "description": "Google Calendar - Manage Google Calendar events and check availability",
          "commands": [
            "list-events",
            "create-event",
            "update-event",
            "delete-event",
            "check-availability"
          ],
          "env": [
            "GOOGLE_CALENDAR_TOKEN",
            "GOOGLE_CALENDAR_ID"
          ],
          "path": "productivity/google-calendar",
          "markdownBody": "# Google Calendar\n\nManage Google Calendar events and check availability from the CLI using the Google Calendar API.\n\n## Prerequisites\n\n- `GOOGLE_CALENDAR_TOKEN` â€” OAuth 2.0 bearer access token with `calendar` scope\n- `GOOGLE_CALENDAR_ID` â€” Calendar ID (default: `primary`)\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-events` | List upcoming calendar events |\n| `create-event` | Create a new calendar event |\n| `update-event` | Update an existing event |\n| `delete-event` | Delete an event |\n| `check-availability` | Check if a time slot is free |\n\n## Usage\n\n```bash\n# List upcoming events\npython google_calendar.py list-events\n\n# List events in a date range\npython google_calendar.py list-events --time-min \"2024-12-01T00:00:00Z\" --time-max \"2024-12-31T23:59:59Z\" --max-results 20\n\n# Create an event\npython google_calendar.py create-event --title \"Team Standup\" --start \"2024-12-15T09:00:00\" --end \"2024-12-15T09:30:00\" --description \"Daily sync\"\n\n# Create event with attendees\npython google_calendar.py create-event --title \"Meeting\" --start \"2024-12-15T14:00:00\" --end \"2024-12-15T15:00:00\" --attendees \"alice@example.com,bob@example.com\"\n\n# Update an event\npython google_calendar.py update-event --event-id EVENT_ID --title \"Updated Title\"\n\n# Delete an event\npython google_calendar.py delete-event --event-id EVENT_ID\n\n# Check availability\npython google_calendar.py check-availability --start \"2024-12-15T14:00:00Z\" --end \"2024-12-15T15:00:00Z\"\n```"
        },
        {
          "slug": "gmail-triage",
          "name": "gmail-triage",
          "id": "OC-0137",
          "version": "1.0.0",
          "description": "Gmail Inbox Triage - Summarize, label, and draft replies to unread emails",
          "commands": [
            "list-unread",
            "summarize",
            "label",
            "archive",
            "draft-reply"
          ],
          "env": [
            "GMAIL_TOKEN"
          ],
          "path": "productivity/gmail-triage",
          "markdownBody": "# Gmail Inbox Triage\n\nManage your Gmail inbox from the terminal: list unread emails, auto-summarize threads, add labels, archive, and draft AI-powered replies.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `GMAIL_TOKEN` â€” OAuth 2.0 bearer token with `gmail.modify` scope\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-unread` | List unread emails in inbox |\n| `summarize` | Summarize a specific email thread |\n| `label` | Add a label to an email |\n| `archive` | Archive (remove from inbox) an email |\n| `draft-reply` | Generate and save a draft reply |\n\n## Usage\n\n```bash\nexport GMAIL_TOKEN=\"your_oauth_token\"\n\n# List up to 20 unread emails\npython3 scripts/gmail_triage.py list-unread --max-results 20\n\n# Summarize a thread\npython3 scripts/gmail_triage.py summarize --message-id MESSAGE_ID\n\n# Add a label to an email\npython3 scripts/gmail_triage.py label --message-id MESSAGE_ID --label-name \"Follow Up\"\n\n# Archive an email\npython3 scripts/gmail_triage.py archive --message-id MESSAGE_ID\n\n# Generate a draft reply\npython3 scripts/gmail_triage.py draft-reply --message-id MESSAGE_ID --tone \"professional\"\n```"
        },
        {
          "slug": "followup-reminder",
          "name": "followup-reminder",
          "id": "OC-0140",
          "version": "1.0.0",
          "description": "Follow-up Reminder - Track sent emails and flag those awaiting a response",
          "commands": [
            "scan",
            "list-pending",
            "mark-resolved",
            "add-manual"
          ],
          "env": [
            "GMAIL_TOKEN"
          ],
          "path": "productivity/followup-reminder",
          "markdownBody": "# Follow-up Reminder\n\nTrack sent emails and flag those awaiting a response. Scans your Sent folder for emails without replies after a configurable number of days.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `GMAIL_TOKEN` â€” OAuth 2.0 bearer token with `gmail.readonly` scope\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `scan` | Scan sent emails for those without replies |\n| `list-pending` | Show all tracked pending follow-ups |\n| `mark-resolved` | Mark a follow-up as resolved |\n| `add-manual` | Manually add a follow-up reminder |\n\n## Usage\n\n```bash\nexport GMAIL_TOKEN=\"your_token\"\n\n# Scan sent emails for unanswered threads (after 3+ days)\npython3 scripts/followup_reminder.py scan --days 3 --max-results 50\n\n# List all pending follow-ups from local tracker\npython3 scripts/followup_reminder.py list-pending\n\n# Mark a follow-up as resolved\npython3 scripts/followup_reminder.py mark-resolved --thread-id THREAD_ID\n\n# Add a manual follow-up reminder\npython3 scripts/followup_reminder.py add-manual --subject \"Invoice payment\" --recipient \"client@example.com\" --days 5\n```"
        },
        {
          "slug": "email-tone-adjuster",
          "name": "email-tone-adjuster",
          "id": "OC-0139",
          "version": "1.0.0",
          "description": "Email Tone Adjuster - Rewrite drafts to match a target tone (formal, concise, friendly)",
          "commands": [
            "adjust",
            "analyze",
            "suggest-subject"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "productivity/email-tone-adjuster",
          "markdownBody": "# Email Tone Adjuster\n\nRewrite email drafts to match a target tone using AI. Supports formal, concise, friendly, assertive, and empathetic styles.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” OpenAI API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `adjust` | Rewrite an email draft in a new tone |\n| `analyze` | Analyze the current tone of an email |\n| `suggest-subject` | Generate subject line suggestions |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Adjust tone from a file\npython3 scripts/email_tone_adjuster.py adjust --file draft.txt --tone formal\n\n# Adjust tone from inline text\npython3 scripts/email_tone_adjuster.py adjust --text \"Hey can u send me the report asap\" --tone professional\n\n# Analyze the tone of an email\npython3 scripts/email_tone_adjuster.py analyze --file draft.txt\n\n# Generate subject line suggestions\npython3 scripts/email_tone_adjuster.py suggest-subject --file draft.txt --count 5\n```"
        },
        {
          "slug": "clickup-manager",
          "name": "clickup-manager",
          "id": "OC-0132",
          "version": "1.0.0",
          "description": "ClickUp Manager - Manage ClickUp tasks, spaces, and lists via REST API v2",
          "commands": [
            "list-tasks",
            "create-task",
            "update-task",
            "list-spaces",
            "list-lists"
          ],
          "env": [
            "CLICKUP_API_TOKEN",
            "CLICKUP_WORKSPACE_ID"
          ],
          "path": "productivity/clickup-manager",
          "markdownBody": "# ClickUp Manager\n\nManage ClickUp tasks, spaces, and lists from the CLI using the ClickUp REST API v2.\n\n## Prerequisites\n\n- `CLICKUP_API_TOKEN` â€” ClickUp personal API token (Settings â†’ Apps â†’ API Token)\n- `CLICKUP_WORKSPACE_ID` â€” Your workspace/team ID (needed for list-spaces)\n- `pip install requests`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-tasks` | List tasks in a list with optional status filter |\n| `create-task` | Create a new task in a list |\n| `update-task` | Update task status or priority |\n| `list-spaces` | List all spaces in the workspace |\n| `list-lists` | List all lists in a space |\n\n## Usage\n\n```bash\n# List spaces in workspace\npython clickup_manager.py list-spaces\n\n# List lists in a space\npython clickup_manager.py list-lists --space-id SPACE_ID\n\n# List tasks in a list\npython clickup_manager.py list-tasks --list-id LIST_ID\n\n# Filter by status\npython clickup_manager.py list-tasks --list-id LIST_ID --status-filter \"in progress\"\n\n# Create a task\npython clickup_manager.py create-task --list-id LIST_ID --name \"Fix bug\" --description \"Details here\" --priority 2\n\n# Update a task\npython clickup_manager.py update-task --task-id TASK_ID --status \"complete\" --priority 1\n```"
        },
        {
          "slug": "calendly-generator",
          "name": "calendly-generator",
          "id": "OC-0134",
          "version": "1.0.0",
          "description": "Calendly Link Generator - Create one-off scheduling links with custom constraints",
          "commands": [
            "list-event-types",
            "create-link",
            "list-links",
            "deactivate-link",
            "get-scheduled-events"
          ],
          "env": [
            "CALENDLY_TOKEN"
          ],
          "path": "productivity/calendly-generator",
          "markdownBody": "# Calendly Link Generator\n\nGenerate one-off Calendly scheduling links with custom constraints directly from the terminal.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `CALENDLY_TOKEN` â€” Personal access token from Calendly developer settings\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `list-event-types` | List all available event types |\n| `create-link` | Create a single-use scheduling link |\n| `list-links` | List existing single-use links |\n| `deactivate-link` | Deactivate a single-use link |\n| `get-scheduled-events` | List scheduled events |\n\n## Usage\n\n```bash\nexport CALENDLY_TOKEN=\"your_token_here\"\n\n# List all event types\npython3 scripts/calendly_generator.py list-event-types\n\n# Create a one-time scheduling link for a specific event type\npython3 scripts/calendly_generator.py create-link --event-type-uri \"https://api.calendly.com/event_types/UUID\"\n\n# Create a link with max uses\npython3 scripts/calendly_generator.py create-link --event-type-uri \"https://api.calendly.com/event_types/UUID\" --max-event-count 1\n\n# List all single-use links\npython3 scripts/calendly_generator.py list-links\n\n# Deactivate a link\npython3 scripts/calendly_generator.py deactivate-link --link-uri \"https://api.calendly.com/one_off_event_type_invites/UUID\"\n\n# Get scheduled events (next 7 days)\npython3 scripts/calendly_generator.py get-scheduled-events --days 7\n```"
        }
      ],
      "skillCount": 14
    },
    {
      "slug": "ai-utilities",
      "name": "Ai Utilities",
      "icon": "ðŸ¤–",
      "subcategories": [],
      "skills": [
        {
          "slug": "tool-use-validator",
          "name": "tool-use-validator",
          "id": "OC-0123",
          "version": "1.0.0",
          "description": "Tool Use Validator - Validate JSON tool call arguments against expected schemas",
          "commands": [
            "validate",
            "validate-file",
            "generate-schema",
            "list-rules"
          ],
          "env": [],
          "path": "ai-utilities/tool-use-validator",
          "markdownBody": "# Tool Use Validator\n\nValidate JSON tool call arguments against expected schemas.\n\n## Prerequisites\n\n- No API keys required\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `validate` | ... |\n| `validate-file` | ... |\n| `generate-schema` | ... |\n| `list-rules` | ... |\n\n## Usage\n\n```bash\npython3 scripts/tool_use_validator.py validate\npython3 scripts/tool_use_validator.py validate-file\npython3 scripts/tool_use_validator.py generate-schema\n```"
        },
        {
          "slug": "token-cost-estimator",
          "name": "token-cost-estimator",
          "id": "OC-0116",
          "version": "1.0.0",
          "description": "Token Cost Estimator - Calculate token counts and costs before running prompts",
          "commands": [
            "estimate",
            "estimate-file",
            "compare-models",
            "show-pricing"
          ],
          "env": [],
          "path": "ai-utilities/token-cost-estimator",
          "markdownBody": "# Token Cost Estimator\n\nEstimate token counts and API costs for prompts across multiple models before running them.\n\n## Prerequisites\n\n- Optional: `pip install tiktoken` for accurate tokenization\n- Falls back to character-based approximation if tiktoken unavailable\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `estimate` | Estimate tokens and cost for inline text |\n| `estimate-file` | Estimate tokens and cost for a file |\n| `compare-models` | Compare cost across top models |\n| `show-pricing` | Show current per-token pricing table |\n\n## Usage\n\n```bash\npython3 scripts/token_cost_estimator.py estimate --text \"Your prompt here\" --model gpt-4o\npython3 scripts/token_cost_estimator.py estimate-file --file prompt.txt --model claude-3-5-sonnet\npython3 scripts/token_cost_estimator.py compare-models --text \"Your prompt here\"\npython3 scripts/token_cost_estimator.py show-pricing\n```"
        },
        {
          "slug": "system-prompt-optimizer",
          "name": "system-prompt-optimizer",
          "id": "OC-0121",
          "version": "1.0.0",
          "description": "System Prompt Optimizer - Iteratively improve system prompts via meta-prompting",
          "commands": [
            "optimize",
            "evaluate",
            "compare-versions",
            "apply"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/system-prompt-optimizer",
          "markdownBody": "# System Prompt Optimizer\n\nIteratively improve system prompts via meta-prompting.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `optimize` | ... |\n| `evaluate` | ... |\n| `compare-versions` | ... |\n| `apply` | ... |\n\n## Usage\n\n```bash\npython3 scripts/system_prompt_optimizer.py optimize\npython3 scripts/system_prompt_optimizer.py evaluate\npython3 scripts/system_prompt_optimizer.py compare-versions\n```"
        },
        {
          "slug": "rag-manager",
          "name": "rag-manager",
          "id": "OC-0118",
          "version": "1.0.0",
          "description": "RAG Manager - Handle document chunking, embedding, and vector storage for RAG pipelines",
          "commands": [
            "ingest",
            "query",
            "list-collections",
            "delete-collection"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/rag-manager",
          "markdownBody": "# RAG Manager\n\nIngest documents into a vector store and query them using semantic search. Supports ChromaDB (local) or a JSON-based fallback store.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n- Optional: `pip install chromadb` for persistent vector storage\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `ingest` | Chunk and embed a document into a collection |\n| `query` | Semantic search over a collection |\n| `list-collections` | List all available collections |\n| `delete-collection` | Delete a collection and its embeddings |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/rag_manager.py ingest --file docs/guide.md --collection my-docs\npython3 scripts/rag_manager.py query --text \"How do I reset a password?\" --collection my-docs --top-k 3\npython3 scripts/rag_manager.py list-collections\npython3 scripts/rag_manager.py delete-collection --collection my-docs\n```"
        },
        {
          "slug": "prompt-version-control",
          "name": "prompt-version-control",
          "id": "OC-0115",
          "version": "1.0.0",
          "description": "Prompt Version Control - Save, tag, and rollback prompt templates with git",
          "commands": [
            "save",
            "list",
            "load",
            "diff",
            "tag",
            "rollback"
          ],
          "env": [],
          "path": "ai-utilities/prompt-version-control",
          "markdownBody": "# Prompt Version Control\n\nVersion-control your AI prompt templates using a local git-backed store in `~/.openclaw/prompts/`.\n\n## Prerequisites\n\n- `git` installed\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `save` | Save a prompt with a name |\n| `list` | List all saved prompts and versions |\n| `load` | Load a specific prompt version |\n| `diff` | Diff two versions of a prompt |\n| `tag` | Tag a prompt version |\n| `rollback` | Roll back to a previous version |\n\n## Usage\n\n```bash\npython3 scripts/prompt_version_control.py save --name summarizer --file prompt.txt\npython3 scripts/prompt_version_control.py list\npython3 scripts/prompt_version_control.py load --name summarizer\npython3 scripts/prompt_version_control.py diff --name summarizer --v1 HEAD~1 --v2 HEAD\npython3 scripts/prompt_version_control.py tag --name summarizer --tag v1.0\npython3 scripts/prompt_version_control.py rollback --name summarizer --version HEAD~1\n```"
        },
        {
          "slug": "model-benchmarker",
          "name": "model-benchmarker",
          "id": "OC-0119",
          "version": "1.0.0",
          "description": "Model Benchmarker - Run the same prompt against multiple LLMs and compare output",
          "commands": [
            "run-benchmark",
            "compare",
            "list-models",
            "export-results"
          ],
          "env": [
            "OPENAI_API_KEY",
            "ANTHROPIC_API_KEY"
          ],
          "path": "ai-utilities/model-benchmarker",
          "markdownBody": "# Model Benchmarker\n\nBenchmark prompts across OpenAI, Anthropic, and other models to compare quality, speed, and cost.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n- `ANTHROPIC_API_KEY` (optional)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `run-benchmark` | Run a prompt against multiple models |\n| `compare` | Compare results from a benchmark run |\n| `list-models` | List available models with pricing |\n| `export-results` | Export benchmark results |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n\npython3 scripts/model_benchmarker.py run-benchmark --prompt \"Explain quantum entanglement in 3 sentences\" --runs 2\npython3 scripts/model_benchmarker.py compare --results-file results.json\npython3 scripts/model_benchmarker.py list-models\npython3 scripts/model_benchmarker.py export-results --results-file results.json --format md\n```"
        },
        {
          "slug": "knowledge-graph-builder",
          "name": "knowledge-graph-builder",
          "id": "OC-0122",
          "version": "1.0.0",
          "description": "Knowledge Graph Builder - Extract entities and relationships from text for long-term memory",
          "commands": [
            "extract",
            "add-document",
            "query-graph",
            "export-graph"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/knowledge-graph-builder",
          "markdownBody": "# Knowledge Graph Builder\n\nExtract entities and relationships from text for long-term memory.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `extract` | ... |\n| `add-document` | ... |\n| `query-graph` | ... |\n| `export-graph` | ... |\n\n## Usage\n\n```bash\npython3 scripts/knowledge_graph_builder.py extract\npython3 scripts/knowledge_graph_builder.py add-document\npython3 scripts/knowledge_graph_builder.py query-graph\n```"
        },
        {
          "slug": "eval-suite-runner",
          "name": "eval-suite-runner",
          "id": "OC-0126",
          "version": "1.0.0",
          "description": "Eval Suite Runner - Run automated evals against a golden dataset to catch regressions",
          "commands": [
            "run",
            "add-test",
            "list-tests",
            "compare-runs"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/eval-suite-runner",
          "markdownBody": "# Eval Suite Runner\n\nRun automated evals against a golden dataset to catch regressions.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `run` | ... |\n| `add-test` | ... |\n| `list-tests` | ... |\n| `compare-runs` | ... |\n\n## Usage\n\n```bash\npython3 scripts/eval_suite_runner.py run\npython3 scripts/eval_suite_runner.py add-test\npython3 scripts/eval_suite_runner.py list-tests\n```"
        },
        {
          "slug": "embedding-drift-detector",
          "name": "embedding-drift-detector",
          "id": "OC-0125",
          "version": "1.0.0",
          "description": "Embedding Drift Detector - Alert when retrieved context chunks diverge significantly from the query",
          "commands": [
            "compute-drift",
            "monitor-collection",
            "set-threshold",
            "generate-alert"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/embedding-drift-detector",
          "markdownBody": "# Embedding Drift Detector\n\nAlert when retrieved context chunks diverge significantly from the query.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `compute-drift` | ... |\n| `monitor-collection` | ... |\n| `set-threshold` | ... |\n| `generate-alert` | ... |\n\n## Usage\n\n```bash\npython3 scripts/embedding_drift_detector.py compute-drift\npython3 scripts/embedding_drift_detector.py monitor-collection\npython3 scripts/embedding_drift_detector.py set-threshold\n```"
        },
        {
          "slug": "context-compressor",
          "name": "context-compressor",
          "id": "OC-0117",
          "version": "1.0.0",
          "description": "Context Compressor - Summarize or truncate conversation history to fit context windows",
          "commands": [
            "compress",
            "summarize-history",
            "truncate",
            "estimate-tokens"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/context-compressor",
          "markdownBody": "# Context Compressor\n\nReduce conversation history and long documents to fit within LLM context windows using summarization or smart truncation.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n- Optional: `pip install tiktoken`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `compress` | Compress a file to a target token count |\n| `summarize-history` | Summarize a conversation history JSON file |\n| `truncate` | Truncate text to a max token count |\n| `estimate-tokens` | Estimate token count for a file |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/context_compressor.py compress --file long_doc.txt --target-tokens 2000\npython3 scripts/context_compressor.py summarize-history --file conversation.json\npython3 scripts/context_compressor.py truncate --file doc.txt --max-tokens 4000 --strategy tail\npython3 scripts/context_compressor.py estimate-tokens --file doc.txt\n```"
        },
        {
          "slug": "bias-safety-checker",
          "name": "bias-safety-checker",
          "id": "OC-0120",
          "version": "1.0.0",
          "description": "Bias & Safety Checker - Pre-screen LLM outputs for bias, toxicity, and PII",
          "commands": [
            "check-text",
            "check-file",
            "batch-check",
            "generate-report"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "ai-utilities/bias-safety-checker",
          "markdownBody": "# Bias & Safety Checker\n\nPre-screen LLM outputs for bias, toxicity, and PII.\n\n## Prerequisites\n\n- `OPENAI_API_KEY`\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `check-text` | ... |\n| `check-file` | ... |\n| `batch-check` | ... |\n| `generate-report` | ... |\n\n## Usage\n\n```bash\npython3 scripts/bias_safety_checker.py check-text\npython3 scripts/bias_safety_checker.py check-file\npython3 scripts/bias_safety_checker.py batch-check\n```"
        },
        {
          "slug": "agent-chain-debugger",
          "name": "agent-chain-debugger",
          "id": "OC-0124",
          "version": "1.0.0",
          "description": "Agent Chain Debugger - Visualize and replay multi-step agent tool call chains",
          "commands": [
            "parse-trace",
            "visualize",
            "replay-step",
            "export-report"
          ],
          "env": [],
          "path": "ai-utilities/agent-chain-debugger",
          "markdownBody": "# Agent Chain Debugger\n\nVisualize and replay multi-step agent tool call chains.\n\n## Prerequisites\n\n- No API keys required\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `parse-trace` | ... |\n| `visualize` | ... |\n| `replay-step` | ... |\n| `export-report` | ... |\n\n## Usage\n\n```bash\npython3 scripts/agent_chain_debugger.py parse-trace\npython3 scripts/agent_chain_debugger.py visualize\npython3 scripts/agent_chain_debugger.py replay-step\n```"
        }
      ],
      "skillCount": 12
    },
    {
      "slug": "realtime-audio",
      "name": "Realtime Audio",
      "icon": "ðŸŽ™ï¸",
      "subcategories": [],
      "skills": [
        {
          "slug": "voice-sentiment",
          "name": "voice-sentiment",
          "id": "OC-0108",
          "version": "1.0.0",
          "description": "Voice Sentiment Analyzer - Detect emotion and stress in audio input",
          "commands": [
            "analyze-file",
            "analyze-text",
            "batch-analyze"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "realtime-audio/voice-sentiment",
          "markdownBody": "# Voice Sentiment Analyzer\n\nDetect emotion, tone, and stress levels in audio recordings by transcribing with Whisper and analyzing sentiment with GPT.\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” OpenAI API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `analyze-file` | Transcribe audio and analyze sentiment |\n| `analyze-text` | Analyze sentiment of plain text |\n| `batch-analyze` | Analyze all audio files in a directory |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/voice_sentiment.py analyze-file --file call.mp3\npython3 scripts/voice_sentiment.py analyze-text --text \"I'm really frustrated with this!\"\npython3 scripts/voice_sentiment.py batch-analyze --dir ./recordings --output report.json\n```"
        },
        {
          "slug": "voice-biometrics",
          "name": "voice-biometrics",
          "id": "OC-0111",
          "version": "1.0.0",
          "description": "Voice Biometrics - Identify and verify speakers by voice print",
          "commands": [
            "enroll-speaker",
            "identify-speaker",
            "verify-speaker",
            "list-speakers"
          ],
          "env": [
            "AZURE_SPEECH_KEY",
            "AZURE_SPEECH_REGION"
          ],
          "path": "realtime-audio/voice-biometrics",
          "markdownBody": "# Voice Biometrics\n\nEnroll speakers by voice print and identify or verify them in future recordings using Azure Speaker Recognition.\n\n## Prerequisites\n\n- `AZURE_SPEECH_KEY` â€” Azure Cognitive Services key\n- `AZURE_SPEECH_REGION` â€” Azure region (e.g. `eastus`)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `enroll-speaker` | Enroll a new speaker with a voice sample |\n| `identify-speaker` | Identify the speaker in an audio file |\n| `verify-speaker` | Verify if audio matches a known speaker |\n| `list-speakers` | List all enrolled speaker profiles |\n\n## Usage\n\n```bash\nexport AZURE_SPEECH_KEY=\"...\"\nexport AZURE_SPEECH_REGION=\"eastus\"\n\npython3 scripts/voice_biometrics.py enroll-speaker --name \"Alice\" --file alice_sample.wav\npython3 scripts/voice_biometrics.py identify-speaker --file unknown.wav\npython3 scripts/voice_biometrics.py verify-speaker --name \"Alice\" --file candidate.wav\npython3 scripts/voice_biometrics.py list-speakers\n```"
        },
        {
          "slug": "realtime-voice",
          "name": "realtime-voice",
          "id": "OC-0106",
          "version": "1.0.0",
          "description": "Realtime Voice Interface - STT + LLM + TTS pipeline with low-latency optimization",
          "commands": [
            "transcribe-audio",
            "synthesize-speech",
            "start-session",
            "get-session-info"
          ],
          "env": [
            "OPENAI_API_KEY",
            "ELEVENLABS_API_KEY"
          ],
          "path": "realtime-audio/realtime-voice",
          "markdownBody": "# Realtime Voice Interface\n\nLow-latency voice pipeline combining Whisper (STT), an LLM, and ElevenLabs (TTS) for real-time conversational AI.\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” OpenAI API key (Whisper + GPT)\n- `ELEVENLABS_API_KEY` â€” ElevenLabs TTS API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `transcribe-audio` | Transcribe an audio file to text via Whisper |\n| `synthesize-speech` | Convert text to speech via ElevenLabs |\n| `start-session` | Print session configuration info |\n| `get-session-info` | Show latency targets and model config |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\nexport ELEVENLABS_API_KEY=\"xi-...\"\n\npython3 scripts/realtime_voice.py transcribe-audio --file meeting.wav\npython3 scripts/realtime_voice.py synthesize-speech --text \"Hello world\" --output reply.mp3\npython3 scripts/realtime_voice.py start-session --model gpt-4o --voice-id 21m00Tcm4TlvDq8ikWAM\npython3 scripts/realtime_voice.py get-session-info\n```"
        },
        {
          "slug": "podcast-summarizer",
          "name": "podcast-summarizer",
          "id": "OC-0113",
          "version": "1.0.0",
          "description": "Podcast Summarizer - Fetch, transcribe, and summarize podcast episodes on demand",
          "commands": [
            "summarize-file",
            "summarize-url",
            "fetch-rss",
            "extract-topics"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "realtime-audio/podcast-summarizer",
          "markdownBody": "# Podcast Summarizer\n\nDownload podcast episodes, transcribe them with Whisper, and generate AI summaries.\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” OpenAI API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `summarize-file` | Summarize a local audio file |\n| `summarize-url` | Download and summarize an audio URL |\n| `fetch-rss` | List recent episodes from an RSS feed |\n| `extract-topics` | Extract key topics from an audio file |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/podcast_summarizer.py summarize-file --file episode.mp3 --length medium\npython3 scripts/podcast_summarizer.py summarize-url --url https://... --length brief\npython3 scripts/podcast_summarizer.py fetch-rss --feed-url https://feeds.example.com/podcast.xml --limit 5\npython3 scripts/podcast_summarizer.py extract-topics --file episode.mp3\n```"
        },
        {
          "slug": "meeting-scribe",
          "name": "meeting-scribe",
          "id": "OC-0110",
          "version": "1.0.0",
          "description": "Meeting Scribe - Live transcription and action item extraction from meetings",
          "commands": [
            "transcribe",
            "extract-action-items",
            "generate-summary",
            "export-notes"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "realtime-audio/meeting-scribe",
          "markdownBody": "# Meeting Scribe\n\nTranscribe meeting recordings and automatically extract action items, decisions, and summaries.\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” OpenAI API key\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `transcribe` | Transcribe audio to text |\n| `extract-action-items` | Extract action items from a transcript |\n| `generate-summary` | Generate a meeting summary |\n| `export-notes` | Export formatted meeting notes |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/meeting_scribe.py transcribe --file standup.mp3 --output standup.txt\npython3 scripts/meeting_scribe.py extract-action-items --transcript-file standup.txt\npython3 scripts/meeting_scribe.py generate-summary --transcript-file standup.txt --format detailed\npython3 scripts/meeting_scribe.py export-notes --transcript-file standup.txt --output-format md\n```"
        },
        {
          "slug": "live-translator",
          "name": "live-translator",
          "id": "OC-0107",
          "version": "1.0.0",
          "description": "Live Translator - Translate audio streams and text in real time",
          "commands": [
            "translate-audio",
            "translate-text",
            "list-languages",
            "detect-language"
          ],
          "env": [
            "OPENAI_API_KEY",
            "DEEPL_API_KEY"
          ],
          "path": "realtime-audio/live-translator",
          "markdownBody": "# Live Translator\n\nTranslate audio files and text in real time using Whisper (transcription) and DeepL or OpenAI (translation).\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” for audio transcription via Whisper\n- `DEEPL_API_KEY` â€” for high-quality translation (optional; falls back to OpenAI)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `translate-audio` | Transcribe and translate an audio file |\n| `translate-text` | Translate plain text to a target language |\n| `list-languages` | List supported DeepL language codes |\n| `detect-language` | Detect the language of a text snippet |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\nexport DEEPL_API_KEY=\"...\"\n\npython3 scripts/live_translator.py translate-audio --file speech.mp3 --target-lang ES\npython3 scripts/live_translator.py translate-text --text \"Hello world\" --target-lang FR\npython3 scripts/live_translator.py list-languages\npython3 scripts/live_translator.py detect-language --text \"Bonjour le monde\"\n```"
        },
        {
          "slug": "call-quality-monitor",
          "name": "call-quality-monitor",
          "id": "OC-0114",
          "version": "1.0.0",
          "description": "Call Quality Monitor - Detect jitter, latency, and packet loss in audio streams",
          "commands": [
            "analyze-audio",
            "measure-latency",
            "detect-jitter",
            "generate-report"
          ],
          "env": [],
          "path": "realtime-audio/call-quality-monitor",
          "markdownBody": "# Call Quality Monitor\n\nAnalyze audio files and network captures to measure call quality metrics including MOS score, jitter, and packet loss.\n\n## Prerequisites\n\n- Python: `pip install soundfile numpy`\n- Optional: `ffmpeg` for format conversion\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `analyze-audio` | Estimate MOS score from an audio file |\n| `measure-latency` | Measure perceived latency/gaps in audio |\n| `detect-jitter` | Detect jitter patterns in audio |\n| `generate-report` | Full quality report for an audio file |\n\n## Usage\n\n```bash\npython3 scripts/call_quality_monitor.py analyze-audio --file call.wav\npython3 scripts/call_quality_monitor.py measure-latency --file call.wav\npython3 scripts/call_quality_monitor.py detect-jitter --file call.wav --threshold 30\npython3 scripts/call_quality_monitor.py generate-report --file call.wav --output report.json\n```"
        },
        {
          "slug": "audio-noise-reducer",
          "name": "audio-noise-reducer",
          "id": "OC-0112",
          "version": "1.0.0",
          "description": "Audio Noise Reducer - Clean up microphone input and audio files in software",
          "commands": [
            "reduce-noise",
            "batch-reduce",
            "measure-snr",
            "list-profiles"
          ],
          "env": [],
          "path": "realtime-audio/audio-noise-reducer",
          "markdownBody": "# Audio Noise Reducer\n\nRemove background noise from audio files using the `noisereduce` library (or ffmpeg as fallback).\n\n## Prerequisites\n\n- Python: `pip install noisereduce soundfile numpy`\n- Or: `ffmpeg` installed (fallback mode)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `reduce-noise` | Remove noise from a single audio file |\n| `batch-reduce` | Process all audio files in a directory |\n| `measure-snr` | Estimate the signal-to-noise ratio of a file |\n| `list-profiles` | List available noise reduction profiles |\n\n## Usage\n\n```bash\npython3 scripts/audio_noise_reducer.py reduce-noise --input noisy.wav --output clean.wav\npython3 scripts/audio_noise_reducer.py reduce-noise --input call.mp3 --strength high\npython3 scripts/audio_noise_reducer.py batch-reduce --dir ./recordings --output-dir ./cleaned\npython3 scripts/audio_noise_reducer.py measure-snr --file audio.wav\npython3 scripts/audio_noise_reducer.py list-profiles\n```"
        },
        {
          "slug": "active-listener",
          "name": "active-listener",
          "id": "OC-0109",
          "version": "1.0.0",
          "description": "Active Listener - Detect pauses, extract speaker turns, summarize dialogue",
          "commands": [
            "detect-pauses",
            "extract-turns",
            "summarize-turns",
            "analyze-dialogue"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "realtime-audio/active-listener",
          "markdownBody": "# Active Listener\n\nAnalyze audio conversations to detect pauses, extract speaker turns, and summarize dialogue segments.\n\n## Prerequisites\n\n- `OPENAI_API_KEY` â€” OpenAI API key (Whisper + GPT)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `detect-pauses` | Find silence gaps above a threshold in a transcript |\n| `extract-turns` | Split a transcript into speaker turns |\n| `summarize-turns` | Summarize each speaker turn |\n| `analyze-dialogue` | Full analysis: turns + pauses + summary |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\npython3 scripts/active_listener.py detect-pauses --file call.mp3 --threshold 1.5\npython3 scripts/active_listener.py extract-turns --transcript-file transcript.txt\npython3 scripts/active_listener.py summarize-turns --transcript-file transcript.txt\npython3 scripts/active_listener.py analyze-dialogue --file meeting.mp3\n```"
        }
      ],
      "skillCount": 9
    },
    {
      "slug": "health",
      "name": "Health",
      "icon": "ðŸ’š",
      "subcategories": [],
      "skills": [
        {
          "slug": "workout-logger",
          "name": "workout-logger",
          "id": "OC-0141",
          "version": "1.0.0",
          "description": "Workout Logger - Log exercises to a local store or Strava via API",
          "commands": [
            "log",
            "list",
            "summary",
            "upload-strava"
          ],
          "env": [
            "STRAVA_ACCESS_TOKEN"
          ],
          "path": "health/workout-logger",
          "markdownBody": "# Workout Logger\n\nLog workouts locally and optionally sync them to Strava. Track exercises, duration, distance, and calories.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `STRAVA_ACCESS_TOKEN` â€” Strava API access token (optional, for Strava sync)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log` | Log a new workout |\n| `list` | List recent workouts |\n| `summary` | Show weekly/monthly workout summary |\n| `upload-strava` | Upload a workout to Strava |\n\n## Usage\n\n```bash\nexport STRAVA_ACCESS_TOKEN=\"your_token\"  # optional\n\n# Log a run\npython3 scripts/workout_logger.py log --type run --duration 30 --distance 5.0 --calories 350 --notes \"Morning 5K\"\n\n# Log a strength workout\npython3 scripts/workout_logger.py log --type strength --duration 45 --calories 280 --notes \"Upper body day\"\n\n# List recent workouts\npython3 scripts/workout_logger.py list --limit 10\n\n# Show weekly summary\npython3 scripts/workout_logger.py summary --period week\n\n# Upload last workout to Strava\npython3 scripts/workout_logger.py upload-strava --workout-id WORKOUT_ID\n```"
        },
        {
          "slug": "symptom-checker",
          "name": "symptom-checker",
          "id": "OC-0146",
          "version": "1.0.0",
          "description": "Symptom Checker - Basic triage based on described symptoms (with medical disclaimers)",
          "commands": [
            "check",
            "urgent",
            "log-symptom",
            "history"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "health/symptom-checker",
          "markdownBody": "# Symptom Checker\n\nBasic symptom triage powered by AI. Describes possible causes and urgency level. **Not a substitute for professional medical advice.**\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-based symptom analysis\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `check` | Analyze described symptoms |\n| `urgent` | Quick check if symptoms require emergency care |\n| `log-symptom` | Log a symptom for tracking |\n| `history` | Show symptom history |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Check symptoms\npython3 scripts/symptom_checker.py check --symptoms \"headache, fatigue, mild fever for 2 days\"\n\n# Quick urgency assessment\npython3 scripts/symptom_checker.py urgent --symptoms \"chest pain and shortness of breath\"\n\n# Log a symptom\npython3 scripts/symptom_checker.py log-symptom --symptom \"headache\" --severity 4 --notes \"started after work\"\n\n# View symptom history\npython3 scripts/symptom_checker.py history --days 7\n```"
        },
        {
          "slug": "sleep-analyst",
          "name": "sleep-analyst",
          "id": "OC-0143",
          "version": "1.0.0",
          "description": "Sleep Analyst - Correlate sleep data with productivity metrics",
          "commands": [
            "log-sleep",
            "analyze",
            "weekly-report",
            "correlate"
          ],
          "env": [
            "OURA_TOKEN"
          ],
          "path": "health/sleep-analyst",
          "markdownBody": "# Sleep Analyst\n\nTrack and analyze sleep quality, correlate with productivity, and get AI-powered insights using Oura Ring data or manual logging.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OURA_TOKEN` â€” Oura Ring personal access token (optional, for auto-sync)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log-sleep` | Manually log sleep data |\n| `analyze` | Analyze sleep patterns over time |\n| `weekly-report` | Generate a weekly sleep report |\n| `correlate` | Correlate sleep with productivity scores |\n\n## Usage\n\n```bash\nexport OURA_TOKEN=\"your_oura_token\"  # optional\n\n# Log sleep manually\npython3 scripts/sleep_analyst.py log-sleep --bedtime \"23:30\" --wake \"07:00\" --quality 8 --notes \"Restful\"\n\n# Pull and analyze from Oura (last 7 days)\npython3 scripts/sleep_analyst.py analyze --days 7\n\n# Generate weekly report\npython3 scripts/sleep_analyst.py weekly-report\n\n# Correlate sleep score with productivity\npython3 scripts/sleep_analyst.py correlate --productivity-scores \"8,7,6,9,8,7,5\"\n```"
        },
        {
          "slug": "nutrition-tracker",
          "name": "nutrition-tracker",
          "id": "OC-0142",
          "version": "1.0.0",
          "description": "Nutrition Tracker - Estimate calories from food descriptions and track daily intake",
          "commands": [
            "log-meal",
            "estimate",
            "daily-summary",
            "set-goals"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "health/nutrition-tracker",
          "markdownBody": "# Nutrition Tracker\n\nTrack daily nutrition by logging meals, estimating calories from natural language descriptions, and reviewing intake summaries.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-based food estimation\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log-meal` | Log a meal with food items |\n| `estimate` | Estimate calories from a food description |\n| `daily-summary` | Show today's nutrition summary |\n| `set-goals` | Set daily calorie and macro goals |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Estimate calories from description\npython3 scripts/nutrition_tracker.py estimate --food \"two scrambled eggs with toast and orange juice\"\n\n# Log a meal\npython3 scripts/nutrition_tracker.py log-meal --meal breakfast --food \"oatmeal with banana and coffee\"\n\n# Show today's summary\npython3 scripts/nutrition_tracker.py daily-summary\n\n# Set daily goals\npython3 scripts/nutrition_tracker.py set-goals --calories 2000 --protein 150 --carbs 200 --fat 65\n```"
        },
        {
          "slug": "mental-load-journal",
          "name": "mental-load-journal",
          "id": "OC-0149",
          "version": "1.0.0",
          "description": "Mental Load Journal - Prompt daily reflection and surface patterns over time",
          "commands": [
            "reflect",
            "journal",
            "patterns",
            "mood-trend"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "health/mental-load-journal",
          "markdownBody": "# Mental Load Journal\n\nDaily guided reflection with AI-powered pattern recognition. Track your mental load, surface recurring stressors, and gain insight into your wellbeing over time.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI reflection prompts and pattern analysis\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `reflect` | Start a guided daily reflection session |\n| `journal` | Write a free-form journal entry |\n| `patterns` | Surface recurring themes and patterns |\n| `mood-trend` | View mood trend over time |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Start a guided reflection\npython3 scripts/mental_load_journal.py reflect\n\n# Write a journal entry\npython3 scripts/mental_load_journal.py journal --text \"Feeling overwhelmed with deadlines...\"\n\n# Surface patterns from the last 30 days\npython3 scripts/mental_load_journal.py patterns --days 30\n\n# View mood trend\npython3 scripts/mental_load_journal.py mood-trend --days 14\n```"
        },
        {
          "slug": "meditation-guide",
          "name": "meditation-guide",
          "id": "OC-0144",
          "version": "1.0.0",
          "description": "Meditation Guide - Generate and narrate personalized guided meditation scripts",
          "commands": [
            "generate",
            "list-sessions",
            "log-session",
            "streak"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "health/meditation-guide",
          "markdownBody": "# Meditation Guide\n\nGenerate personalized guided meditation scripts, track sessions, and maintain your practice streak.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-generated meditation scripts\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `generate` | Generate a guided meditation script |\n| `list-sessions` | List past meditation sessions |\n| `log-session` | Log a completed meditation session |\n| `streak` | Show current meditation streak |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Generate a 10-minute stress relief meditation\npython3 scripts/meditation_guide.py generate --duration 10 --focus \"stress relief\"\n\n# Generate a sleep meditation\npython3 scripts/meditation_guide.py generate --duration 15 --focus \"sleep\" --style \"body scan\"\n\n# Log a completed session\npython3 scripts/meditation_guide.py log-session --duration 10 --notes \"Felt calm\"\n\n# Show streak\npython3 scripts/meditation_guide.py streak\n```"
        },
        {
          "slug": "hydration-reminder",
          "name": "hydration-reminder",
          "id": "OC-0145",
          "version": "1.0.0",
          "description": "Hydration Reminder - Smart recurring reminders adjusted for activity level and climate",
          "commands": [
            "log-intake",
            "daily-summary",
            "set-goal",
            "check"
          ],
          "env": [],
          "path": "health/hydration-reminder",
          "markdownBody": "# Hydration Reminder\n\nTrack daily water intake, get smart hydration recommendations based on weight and activity level, and monitor your hydration goals.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log-intake` | Log a water intake entry |\n| `daily-summary` | Show today's hydration progress |\n| `set-goal` | Set personalized daily hydration goal |\n| `check` | Quick check of current hydration status |\n\n## Usage\n\n```bash\n# Log water intake (in ml)\npython3 scripts/hydration_reminder.py log-intake --amount 500\n\n# Log a coffee (counts partially toward hydration)\npython3 scripts/hydration_reminder.py log-intake --amount 250 --type coffee\n\n# Show today's hydration progress\npython3 scripts/hydration_reminder.py daily-summary\n\n# Set a custom goal based on weight and activity\npython3 scripts/hydration_reminder.py set-goal --weight-kg 75 --activity moderate\n\n# Quick status check\npython3 scripts/hydration_reminder.py check\n```"
        },
        {
          "slug": "hrv-recovery-scorer",
          "name": "hrv-recovery-scorer",
          "id": "OC-0148",
          "version": "1.0.0",
          "description": "HRV & Recovery Scorer - Parse Garmin/Polar data and recommend training load",
          "commands": [
            "log-hrv",
            "recovery-score",
            "training-recommendation",
            "trend"
          ],
          "env": [
            "GARMIN_EMAIL",
            "GARMIN_PASSWORD"
          ],
          "path": "health/hrv-recovery-scorer",
          "markdownBody": "# HRV & Recovery Scorer\n\nTrack Heart Rate Variability (HRV) and recovery scores to optimize training load and prevent overtraining.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `GARMIN_EMAIL` / `GARMIN_PASSWORD` for Garmin Connect (optional)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log-hrv` | Manually log HRV measurement |\n| `recovery-score` | Calculate recovery score from recent data |\n| `training-recommendation` | Get training load recommendation |\n| `trend` | Show HRV trend over time |\n\n## Usage\n\n```bash\n# Log manual HRV reading (in ms)\npython3 scripts/hrv_recovery_scorer.py log-hrv --hrv 65 --resting-hr 58 --notes \"Good sleep\"\n\n# Calculate today's recovery score\npython3 scripts/hrv_recovery_scorer.py recovery-score\n\n# Get training recommendation\npython3 scripts/hrv_recovery_scorer.py training-recommendation\n\n# View HRV trend (last 14 days)\npython3 scripts/hrv_recovery_scorer.py trend --days 14\n```"
        },
        {
          "slug": "habit-streaks",
          "name": "habit-streaks",
          "id": "OC-0147",
          "version": "1.0.0",
          "description": "Habit Streaks - Track daily habits such as reading, coding, and running",
          "commands": [
            "add-habit",
            "check-in",
            "status",
            "history",
            "remove-habit"
          ],
          "env": [],
          "path": "health/habit-streaks",
          "markdownBody": "# Habit Streaks\n\nTrack daily habits, maintain streaks, and build consistent routines. Works entirely offline.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `add-habit` | Add a new habit to track |\n| `check-in` | Mark a habit as done for today |\n| `status` | Show all habits and current streaks |\n| `history` | View habit completion history |\n| `remove-habit` | Remove a habit |\n\n## Usage\n\n```bash\n# Add a new habit\npython3 scripts/habit_streaks.py add-habit --name \"Read 30 min\" --emoji \"ðŸ“š\"\n\n# Check in a habit for today\npython3 scripts/habit_streaks.py check-in --name \"Read 30 min\"\n\n# View all habits and streaks\npython3 scripts/habit_streaks.py status\n\n# View history for a habit\npython3 scripts/habit_streaks.py history --name \"Read 30 min\" --days 30\n\n# Remove a habit\npython3 scripts/habit_streaks.py remove-habit --name \"Read 30 min\"\n```"
        }
      ],
      "skillCount": 9
    },
    {
      "slug": "skill-testing",
      "name": "Skill Testing",
      "icon": "ðŸ§ª",
      "subcategories": [],
      "skills": [
        {
          "slug": "skill-runner-cli",
          "name": "skill-runner-cli",
          "id": "OC-0178",
          "version": "1.0.0",
          "description": "Skill Runner CLI - A unified CLI to execute any skill with defined inputs",
          "commands": [
            "run",
            "list",
            "info",
            "validate"
          ],
          "env": [],
          "path": "skill-testing/skill-runner-cli",
          "markdownBody": "# Skill Runner CLI\n\nA unified meta-runner that discovers, lists, and executes any OpenClaw skill from a single entry point.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `run` | Execute a skill by name with arguments |\n| `list` | List all available skills |\n| `info` | Show details for a skill |\n| `validate` | Validate a skill's structure |\n\n## Usage\n\n```bash\n# List all available skills\npython3 scripts/skill_runner_cli.py list\n\n# List skills in a category\npython3 scripts/skill_runner_cli.py list --category productivity\n\n# Show skill info\npython3 scripts/skill_runner_cli.py info --skill google-calendar\n\n# Run a skill\npython3 scripts/skill_runner_cli.py run --skill timezone-converter -- convert --time \"2024-12-15 09:00\" --from-zone \"America/New_York\" --to-zones \"Europe/London\"\n\n# Validate a skill\npython3 scripts/skill_runner_cli.py validate --skill gmail-triage\n```"
        },
        {
          "slug": "skill-linter",
          "name": "skill-linter",
          "id": "OC-0182",
          "version": "1.0.0",
          "description": "Skill Linter - Validate SKILL.md structure and ensure scripts follow OpenClaw conventions",
          "commands": [
            "lint",
            "lint-all",
            "fix-report"
          ],
          "env": [],
          "path": "skill-testing/skill-linter",
          "markdownBody": "# Skill Linter\n\nValidate that skills follow OpenClaw conventions. Checks SKILL.md frontmatter, script structure, and code quality standards.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `lint` | Lint a specific skill |\n| `lint-all` | Lint all skills in the repository |\n| `fix-report` | Generate a report of all issues |\n\n## Usage\n\n```bash\n# Lint a specific skill\npython3 scripts/skill_linter.py lint --skill gmail-triage\n\n# Lint all skills\npython3 scripts/skill_linter.py lint-all\n\n# Lint a specific category\npython3 scripts/skill_linter.py lint-all --category health\n\n# Generate fix report\npython3 scripts/skill_linter.py fix-report --output issues.md\n```"
        },
        {
          "slug": "security-compliance-scanner",
          "name": "security-compliance-scanner",
          "id": "OC-0185",
          "version": "1.0.0",
          "description": "Security Compliance Scanner - Check skill scripts for hardcoded secrets or unsafe shell execution",
          "commands": [
            "scan",
            "scan-all",
            "report"
          ],
          "env": [],
          "path": "skill-testing/security-compliance-scanner",
          "markdownBody": "# Security Compliance Scanner\n\nScan skill scripts for security issues: hardcoded secrets, unsafe shell execution, dangerous builtins, insecure file operations, and other OWASP-relevant patterns.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `scan` | Scan a specific skill for security issues |\n| `scan-all` | Scan all skills in the repository |\n| `report` | Generate a markdown security compliance report |\n\n## Usage\n\n```bash\n# Scan a specific skill\npython3 scripts/security_compliance_scanner.py scan --skill gmail-triage\n\n# Scan all skills and show summary\npython3 scripts/security_compliance_scanner.py scan-all\n\n# Scan a specific category\npython3 scripts/security_compliance_scanner.py scan-all --category productivity\n\n# Generate a full markdown compliance report\npython3 scripts/security_compliance_scanner.py report --output security_report.md\n```"
        },
        {
          "slug": "regression-suite-runner",
          "name": "regression-suite-runner",
          "id": "OC-0181",
          "version": "1.0.0",
          "description": "Regression Suite Runner - Execute skill interactions and diff output against golden master",
          "commands": [
            "record",
            "run",
            "compare",
            "list-suites"
          ],
          "env": [],
          "path": "skill-testing/regression-suite-runner",
          "markdownBody": "# Regression Suite Runner\n\nRecord golden master outputs for skills and run automated regression tests to catch unexpected changes.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `record` | Record a golden master output for a command |\n| `run` | Run all regression tests for a skill |\n| `compare` | Compare current output to golden master |\n| `list-suites` | List all regression suites |\n\n## Usage\n\n```bash\n# Record golden output for a command\npython3 scripts/regression_suite_runner.py record --skill \"timezone-converter\" --command \"convert --time '2024-01-01 09:00' --from-zone UTC --to-zones America/New_York\"\n\n# Run all tests for a skill\npython3 scripts/regression_suite_runner.py run --skill \"timezone-converter\"\n\n# Compare output to golden master\npython3 scripts/regression_suite_runner.py compare --suite-id SUITE_ID\n\n# List all suites\npython3 scripts/regression_suite_runner.py list-suites\n```"
        },
        {
          "slug": "performance-load-tester",
          "name": "performance-load-tester",
          "id": "OC-0184",
          "version": "1.0.0",
          "description": "Performance Load Tester - Run skills in parallel to test concurrency and resource usage bounds",
          "commands": [
            "run",
            "benchmark",
            "report"
          ],
          "env": [],
          "path": "skill-testing/performance-load-tester",
          "markdownBody": "# Performance Load Tester\n\nRun skills in parallel with configurable concurrency and iterations to measure throughput, latency percentiles, and peak resource usage.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `run` | Execute a skill script N times across W parallel workers |\n| `benchmark` | Run multiple concurrency levels and produce a comparison table |\n| `report` | Display a saved performance report |\n\n## Usage\n\n```bash\n# Run a skill with 10 concurrent workers, 50 total iterations\npython3 scripts/performance_load_tester.py run --skill timezone-converter --cmd \"convert --time '2024-01-01 09:00' --from-zone UTC --to-zones America/New_York\" --workers 10 --iterations 50\n\n# Benchmark a skill at concurrency levels 1, 5, 10, 20\npython3 scripts/performance_load_tester.py benchmark --skill timezone-converter --cmd \"convert --time '2024-01-01 09:00' --from-zone UTC --to-zones America/New_York\" --levels 1,5,10,20\n\n# Show a previously saved report\npython3 scripts/performance_load_tester.py report --file perf_report.json\n```"
        },
        {
          "slug": "mock-env-generator",
          "name": "mock-env-generator",
          "id": "OC-0179",
          "version": "1.0.0",
          "description": "Mock Environment Generator - Create sandboxed temp directories and files for safe testing",
          "commands": [
            "create",
            "teardown",
            "list",
            "scaffold"
          ],
          "env": [],
          "path": "skill-testing/mock-env-generator",
          "markdownBody": "# Mock Environment Generator\n\nCreate isolated sandboxed environments with temporary directories, files, and mock configurations for safe skill testing.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `create` | Create a new mock environment |\n| `teardown` | Clean up a mock environment |\n| `list` | List active mock environments |\n| `scaffold` | Generate scaffold files for a skill test |\n\n## Usage\n\n```bash\n# Create a mock environment with test files\npython3 scripts/mock_env_generator.py create --name \"test-gmail\" --files \"inbox.json,sent.json\"\n\n# Scaffold test files for a skill\npython3 scripts/mock_env_generator.py scaffold --skill \"budget-tracker\" --fixtures \"transactions\"\n\n# List active environments\npython3 scripts/mock_env_generator.py list\n\n# Tear down an environment\npython3 scripts/mock_env_generator.py teardown --name \"test-gmail\"\n```"
        },
        {
          "slug": "chaos-monkey",
          "name": "chaos-monkey",
          "id": "OC-0183",
          "version": "1.0.0",
          "description": "Chaos Monkey for Skills - Randomly inject network failures or bad inputs to test skill resilience",
          "commands": [
            "run",
            "list-scenarios",
            "report"
          ],
          "env": [],
          "path": "skill-testing/chaos-monkey",
          "markdownBody": "# Chaos Monkey for Skills\n\nRandomly inject faults â€” network failures, bad inputs, missing env vars, and malformed arguments â€” to test skill resilience under adverse conditions.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `run` | Run chaos tests against a target skill |\n| `list-scenarios` | List all available fault injection scenarios |\n| `report` | Show a summary report of the last chaos run |\n\n## Usage\n\n```bash\n# Run chaos tests against a skill (random scenario selection)\npython3 scripts/chaos_monkey.py run --skill timezone-converter\n\n# Run a specific chaos scenario\npython3 scripts/chaos_monkey.py run --skill gmail-triage --scenario missing-env\n\n# Run all scenarios against a skill\npython3 scripts/chaos_monkey.py run --skill google-calendar --all-scenarios\n\n# List available fault scenarios\npython3 scripts/chaos_monkey.py list-scenarios\n\n# Show report from the last run (saved to chaos_report.json)\npython3 scripts/chaos_monkey.py report --file chaos_report.json\n```"
        },
        {
          "slug": "api-response-mocker",
          "name": "api-response-mocker",
          "id": "OC-0180",
          "version": "1.0.0",
          "description": "API Response Mocker - Intercept outgoing API calls and return fixture data for offline testing",
          "commands": [
            "start",
            "add-fixture",
            "list-fixtures",
            "remove-fixture",
            "verify-calls"
          ],
          "env": [],
          "path": "skill-testing/api-response-mocker",
          "markdownBody": "# API Response Mocker\n\nRun a local mock HTTP server that intercepts API calls and returns fixture responses, enabling offline testing of skills.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `start` | Start the mock server |\n| `add-fixture` | Add a mock response fixture |\n| `list-fixtures` | List all configured fixtures |\n| `remove-fixture` | Remove a fixture |\n| `verify-calls` | Check which API calls were made |\n\n## Usage\n\n```bash\n# Start mock server on port 8765\npython3 scripts/api_response_mocker.py start --port 8765\n\n# Add a fixture for a specific endpoint\npython3 scripts/api_response_mocker.py add-fixture --path \"/api/users\" --method GET --response '{\"users\": []}'\n\n# List fixtures\npython3 scripts/api_response_mocker.py list-fixtures\n\n# Check what API calls were made to the mock\npython3 scripts/api_response_mocker.py verify-calls\n\n# Remove a fixture\npython3 scripts/api_response_mocker.py remove-fixture --path \"/api/users\" --method GET\n```"
        }
      ],
      "skillCount": 8
    },
    {
      "slug": "research",
      "name": "Research",
      "icon": "ðŸ”¬",
      "subcategories": [],
      "skills": [
        {
          "slug": "zotero-manager",
          "name": "zotero-manager",
          "id": "OC-0153",
          "version": "1.0.0",
          "description": "Zotero Manager - Manage Zotero library collections, items, and bibliographies",
          "commands": [
            "list-collections",
            "add-item",
            "search-items",
            "export-bibliography",
            "get-item"
          ],
          "env": [
            "ZOTERO_API_KEY",
            "ZOTERO_USER_ID"
          ],
          "path": "research/zotero-manager",
          "markdownBody": "# Zotero Manager\n\nManage your Zotero reference library: list collections, add new items, search references, export bibliographies in multiple formats, and retrieve item details.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- Environment variables: `ZOTERO_API_KEY`, `ZOTERO_USER_ID`\n\n## Commands\n\n| Command                | Parameters                                                                                              | Description                             |\n| ---------------------- | ------------------------------------------------------------------------------------------------------- | --------------------------------------- |\n| `list-collections`     | â€”                                                                                                       | List all Zotero collections             |\n| `add-item`             | `--title`, `--url`, `--authors`, `--year`, `--item-type` (webpage/journalArticle/book), `--collection-key` | Add a new item to library           |\n| `search-items`         | `--query`, `--collection-key`                                                                           | Search items in library or collection  |\n| `export-bibliography`  | `--collection-key`, `--format` (bibtex/ris/chicago/apa)                                                 | Export bibliography for a collection   |\n| `get-item`             | `--item-key`                                                                                            | Retrieve details of a specific item    |\n\n## Usage\n\n```bash\nexport ZOTERO_API_KEY=\"your-api-key\"\nexport ZOTERO_USER_ID=\"your-user-id\"\n\n# List all collections\npython3 scripts/zotero_manager.py list-collections\n\n# Add a webpage item\npython3 scripts/zotero_manager.py add-item --title \"My Article\" --url \"https://example.com\" \\\n  --authors \"Smith, John\" --year 2024 --item-type webpage --collection-key ABC123\n\n# Search items\npython3 scripts/zotero_manager.py search-items --query \"machine learning\"\n\n# Export bibliography in BibTeX format\npython3 scripts/zotero_manager.py export-bibliography --collection-key ABC123 --format bibtex\n\n# Get item details\npython3 scripts/zotero_manager.py get-item --item-key XYZ789\n```"
        },
        {
          "slug": "wikipedia-deep-dive",
          "name": "wikipedia-deep-dive",
          "id": "OC-0152",
          "version": "1.0.0",
          "description": "Wikipedia Deep Dive - Search, fetch, and summarize Wikipedia articles",
          "commands": [
            "search",
            "fetch-article",
            "summarize",
            "extract-links",
            "get-sections"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "research/wikipedia-deep-dive",
          "markdownBody": "# Wikipedia Deep Dive\n\nSearch Wikipedia, retrieve full article content, generate AI-powered summaries, extract links, and explore article sections across multiple languages.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `openai` library (`pip install openai`) â€” optional, required for summarize command\n- Environment variable: `OPENAI_API_KEY` (optional, for summarize command)\n\n## Commands\n\n| Command          | Parameters                                               | Description                                      |\n| ---------------- | -------------------------------------------------------- | ------------------------------------------------ |\n| `search`         | `--query`, `--lang` (default: en), `--limit` (default: 5) | Search Wikipedia articles                       |\n| `fetch-article`  | `--title`, `--lang` (default: en)                        | Fetch full article content                       |\n| `summarize`      | `--title`, `--length` (brief/detailed)                   | Generate AI summary of an article               |\n| `extract-links`  | `--title`, `--max` (default: 20)                         | Extract wikilinks from an article               |\n| `get-sections`   | `--title`                                                | List all sections of an article                 |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"  # optional\n\n# Search Wikipedia\npython3 scripts/wikipedia_deep_dive.py search --query \"quantum entanglement\" --lang en --limit 5\n\n# Fetch a full article\npython3 scripts/wikipedia_deep_dive.py fetch-article --title \"Quantum entanglement\" --lang en\n\n# Summarize an article with AI\npython3 scripts/wikipedia_deep_dive.py summarize --title \"Quantum entanglement\" --length detailed\n\n# Extract links from an article\npython3 scripts/wikipedia_deep_dive.py extract-links --title \"Quantum entanglement\" --max 20\n\n# Get article sections\npython3 scripts/wikipedia_deep_dive.py get-sections --title \"Quantum entanglement\"\n```"
        },
        {
          "slug": "web-research-agent",
          "name": "web-research-agent",
          "id": "OC-0150",
          "version": "1.0.0",
          "description": "Web Research Agent - Search, scrape, and synthesize web content using Serper and OpenAI",
          "commands": [
            "search",
            "scrape",
            "synthesize",
            "export-report"
          ],
          "env": [
            "OPENAI_API_KEY",
            "SERPER_API_KEY"
          ],
          "path": "research/web-research-agent",
          "markdownBody": "# Web Research Agent\n\nAn automated web research assistant that searches the web via Serper, scrapes page content, synthesizes findings with OpenAI, and exports structured reports.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `openai` library (`pip install openai`)\n- `beautifulsoup4` library (`pip install beautifulsoup4`)\n- Environment variables: `OPENAI_API_KEY`, `SERPER_API_KEY`\n\n## Commands\n\n| Command         | Parameters                                                          | Description                                |\n| --------------- | ------------------------------------------------------------------- | ------------------------------------------ |\n| `search`        | `--query`, `--num-results` (default: 5)                             | Search the web via Serper API              |\n| `scrape`        | `--url`, `--extract` (text/links/headings)                          | Scrape content from a URL                  |\n| `synthesize`    | `--query`, `--num-sources` (default: 3)                             | Search, scrape, and generate AI summary    |\n| `export-report` | `--synthesis-file`, `--output`, `--format` (md/txt)                 | Export a synthesis result to file          |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\nexport SERPER_API_KEY=\"your-serper-key\"\n\n# Search the web\npython3 scripts/web_research_agent.py search --query \"quantum computing breakthroughs 2024\" --num-results 5\n\n# Scrape a URL\npython3 scripts/web_research_agent.py scrape --url \"https://example.com\" --extract text\n\n# Synthesize research on a topic\npython3 scripts/web_research_agent.py synthesize --query \"climate change solutions\" --num-sources 3\n\n# Export a report\npython3 scripts/web_research_agent.py export-report --synthesis-file synthesis.json --output report.md --format md\n```"
        },
        {
          "slug": "perplexity-agent",
          "name": "perplexity-agent",
          "id": "OC-0155",
          "version": "1.0.0",
          "description": "Perplexity Query Agent - Use Perplexity's API for grounded, citation-backed answers",
          "commands": [
            "search",
            "deep-research",
            "summarize-topic"
          ],
          "env": [
            "PERPLEXITY_API_KEY"
          ],
          "path": "research/perplexity-agent",
          "markdownBody": "# Perplexity Query Agent\n\nQuery Perplexity's AI API for grounded, citation-backed answers with real-time web access.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `PERPLEXITY_API_KEY` â€” from Perplexity developer settings\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `search` | Ask a question and get a cited answer |\n| `deep-research` | Detailed research with expanded citations |\n| `summarize-topic` | Generate a structured topic summary |\n\n## Usage\n\n```bash\nexport PERPLEXITY_API_KEY=\"your_key\"\n\n# Quick search with citations\npython3 scripts/perplexity_agent.py search --query \"latest advances in quantum computing 2024\"\n\n# Deep research with full citations\npython3 scripts/perplexity_agent.py deep-research --query \"transformer architecture improvements\"\n\n# Structured topic summary\npython3 scripts/perplexity_agent.py summarize-topic --topic \"Large Language Models\" --depth brief\n```"
        },
        {
          "slug": "patent-search",
          "name": "patent-search",
          "id": "OC-0156",
          "version": "1.0.0",
          "description": "Patent Search Tool - Query patent databases for prior art",
          "commands": [
            "search",
            "get-patent",
            "prior-art",
            "list-by-assignee"
          ],
          "env": [],
          "path": "research/patent-search",
          "markdownBody": "# Patent Search Tool\n\nQuery the USPTO and Google Patents APIs to search for patents, check prior art, and analyze patent landscapes.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `search` | Search patents by keyword |\n| `get-patent` | Get detailed information about a patent |\n| `prior-art` | Search for prior art on an invention concept |\n| `list-by-assignee` | Find patents by company or inventor |\n\n## Usage\n\n```bash\n# Search patents by keyword\npython3 scripts/patent_search.py search --query \"neural network image recognition\" --max-results 10\n\n# Get detailed patent info\npython3 scripts/patent_search.py get-patent --patent-id \"US10000000\"\n\n# Search for prior art\npython3 scripts/patent_search.py prior-art --description \"A method for compressing video using attention mechanisms\"\n\n# Find patents by assignee\npython3 scripts/patent_search.py list-by-assignee --assignee \"OpenAI\" --max-results 20\n```"
        },
        {
          "slug": "obsidian-creator",
          "name": "obsidian-creator",
          "id": "OC-0154",
          "version": "1.0.0",
          "description": "Obsidian Note Creator - Write structured markdown notes directly into an Obsidian vault",
          "commands": [
            "create-note",
            "create-daily",
            "search-notes",
            "append-to-note",
            "list-notes"
          ],
          "env": [
            "OBSIDIAN_VAULT_PATH"
          ],
          "path": "research/obsidian-creator",
          "markdownBody": "# Obsidian Note Creator\n\nCreate and manage structured Markdown notes in your Obsidian vault from the terminal. Supports frontmatter, backlinks, tags, and daily notes.\n\n## Prerequisites\n\n- Python 3.8+\n- `OBSIDIAN_VAULT_PATH` â€” absolute path to your Obsidian vault directory\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `create-note` | Create a new note with optional frontmatter |\n| `create-daily` | Create or open today's daily note |\n| `search-notes` | Search notes by keyword |\n| `append-to-note` | Append content to an existing note |\n| `list-notes` | List notes in a folder |\n\n## Usage\n\n```bash\nexport OBSIDIAN_VAULT_PATH=\"/Users/you/Documents/MyVault\"\n\n# Create a new note\npython3 scripts/obsidian_creator.py create-note --title \"Meeting Notes\" --content \"Key points...\" --tags \"meetings,work\" --folder \"Work\"\n\n# Create today's daily note\npython3 scripts/obsidian_creator.py create-daily --template \"tasks,journal\"\n\n# Search for notes containing a keyword\npython3 scripts/obsidian_creator.py search-notes --query \"project Alpha\"\n\n# Append to an existing note\npython3 scripts/obsidian_creator.py append-to-note --title \"Meeting Notes\" --content \"## Follow-up\\n- Send email\"\n\n# List all notes in a folder\npython3 scripts/obsidian_creator.py list-notes --folder \"Work\"\n```"
        },
        {
          "slug": "news-aggregator",
          "name": "news-aggregator",
          "id": "OC-0157",
          "version": "1.0.0",
          "description": "News Aggregator - Pull and summarize headlines by topic from RSS/APIs",
          "commands": [
            "headlines",
            "search",
            "digest",
            "sources"
          ],
          "env": [
            "NEWS_API_KEY"
          ],
          "path": "research/news-aggregator",
          "markdownBody": "# News Aggregator\n\nPull and summarize news headlines by topic from NewsAPI and RSS feeds. Generate daily digests for your preferred topics.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `NEWS_API_KEY` â€” from newsapi.org (free tier available)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `headlines` | Get top headlines by category or country |\n| `search` | Search news by keyword or topic |\n| `digest` | Generate a summarized digest for multiple topics |\n| `sources` | List available news sources |\n\n## Usage\n\n```bash\nexport NEWS_API_KEY=\"your_key\"\n\n# Get top tech headlines\npython3 scripts/news_aggregator.py headlines --category technology --country us\n\n# Search for specific topics\npython3 scripts/news_aggregator.py search --query \"artificial intelligence\" --max-results 10\n\n# Generate a morning digest\npython3 scripts/news_aggregator.py digest --topics \"technology,science,business\"\n\n# List available sources\npython3 scripts/news_aggregator.py sources --category technology\n```"
        },
        {
          "slug": "arxiv-summarizer",
          "name": "arxiv-summarizer",
          "id": "OC-0151",
          "version": "1.0.0",
          "description": "arXiv Summarizer - Search, fetch, and summarize academic papers from arXiv",
          "commands": [
            "search",
            "fetch-paper",
            "summarize",
            "list-recent",
            "export"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "research/arxiv-summarizer",
          "markdownBody": "# arXiv Summarizer\n\nSearch and retrieve academic papers from arXiv, generate AI-powered summaries, and export paper details in multiple formats.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `openai` library (`pip install openai`)\n- Environment variable: `OPENAI_API_KEY` (required for summarize command)\n\n## Commands\n\n| Command        | Parameters                                                                 | Description                                  |\n| -------------- | -------------------------------------------------------------------------- | -------------------------------------------- |\n| `search`       | `--query`, `--max-results` (default: 5), `--category` (e.g. cs.AI)        | Search arXiv papers                          |\n| `fetch-paper`  | `--arxiv-id`                                                               | Fetch abstract and metadata for a paper      |\n| `summarize`    | `--arxiv-id`, `--length` (brief/detailed/bullet-points)                    | Generate AI summary of a paper               |\n| `list-recent`  | `--category`, `--days` (default: 7), `--max-results` (default: 5)         | List recently submitted papers               |\n| `export`       | `--arxiv-id`, `--output`, `--format` (md/txt)                              | Export paper details to file                 |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Search for papers\npython3 scripts/arxiv_summarizer.py search --query \"transformer attention mechanism\" --max-results 5 --category cs.AI\n\n# Fetch paper details\npython3 scripts/arxiv_summarizer.py fetch-paper --arxiv-id 2303.08774\n\n# Summarize a paper\npython3 scripts/arxiv_summarizer.py summarize --arxiv-id 2303.08774 --length bullet-points\n\n# List recent papers in a category\npython3 scripts/arxiv_summarizer.py list-recent --category cs.LG --days 7 --max-results 5\n\n# Export paper to markdown\npython3 scripts/arxiv_summarizer.py export --arxiv-id 2303.08774 --output paper.md --format md\n```"
        }
      ],
      "skillCount": 8
    },
    {
      "slug": "miscellaneous",
      "name": "Miscellaneous",
      "icon": "ðŸŽ²",
      "subcategories": [],
      "skills": [
        {
          "slug": "travel-planner",
          "name": "travel-planner",
          "id": "OC-0173",
          "version": "1.0.0",
          "description": "Travel Planner - Build multi-day itineraries with flights, hotels, and activities",
          "commands": [
            "itinerary",
            "budget",
            "packing-list",
            "visa-check"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/travel-planner",
          "markdownBody": "# Travel Planner\n\nBuild detailed multi-day travel itineraries with day-by-day plans, budget estimates, packing lists, and visa/entry requirements.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI itinerary generation\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `itinerary` | Generate a detailed day-by-day itinerary |\n| `budget` | Create a travel budget breakdown |\n| `packing-list` | Generate a customized packing list |\n| `visa-check` | Check visa requirements for a destination |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Generate a 7-day Italy itinerary\npython3 scripts/travel_planner.py itinerary --destination \"Italy\" --days 7 --style cultural --budget mid-range\n\n# Create budget estimate\npython3 scripts/travel_planner.py budget --destination \"Thailand\" --days 14 --travelers 2 --style backpacker\n\n# Get packing list\npython3 scripts/travel_planner.py packing-list --destination \"Iceland\" --days 5 --season winter --activities \"hiking,hot springs\"\n\n# Check visa requirements\npython3 scripts/travel_planner.py visa-check --destination \"Japan\" --passport \"US\"\n```"
        },
        {
          "slug": "recipe-generator",
          "name": "recipe-generator",
          "id": "OC-0170",
          "version": "1.0.0",
          "description": "Recipe Generator & Shopper - Create meal plans and export shopping lists",
          "commands": [
            "generate-recipe",
            "meal-plan",
            "shopping-list",
            "substitute"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/recipe-generator",
          "markdownBody": "# Recipe Generator & Shopper\n\nGenerate recipes from available ingredients, create weekly meal plans, and export shopping lists.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI recipe generation\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `generate-recipe` | Generate a recipe from ingredients or cuisine |\n| `meal-plan` | Create a weekly meal plan |\n| `shopping-list` | Generate a shopping list from recipes |\n| `substitute` | Find ingredient substitutes |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Generate a recipe from available ingredients\npython3 scripts/recipe_generator.py generate-recipe --ingredients \"chicken,garlic,lemon,olive oil\" --cuisine italian\n\n# Create a 5-day meal plan\npython3 scripts/recipe_generator.py meal-plan --days 5 --dietary vegetarian\n\n# Generate shopping list for a recipe\npython3 scripts/recipe_generator.py shopping-list --recipe \"Spaghetti Carbonara\" --servings 4\n\n# Find substitute for an ingredient\npython3 scripts/recipe_generator.py substitute --ingredient \"buttermilk\" --recipe \"pancakes\"\n```"
        },
        {
          "slug": "legal-doc-scanner",
          "name": "legal-doc-scanner",
          "id": "OC-0171",
          "version": "1.0.0",
          "description": "Legal Document Scanner - Summarize TOS changes, lease agreements, and contracts",
          "commands": [
            "summarize",
            "flag-risks",
            "compare",
            "extract-clauses"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/legal-doc-scanner",
          "markdownBody": "# Legal Document Scanner\n\nAnalyze legal documents, terms of service, contracts, and lease agreements using AI. Extract key clauses, flag potential risks, and generate plain-English summaries.\n\n**âš  Disclaimer: Not legal advice. Always consult a qualified attorney for important legal matters.**\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI analysis\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `summarize` | Plain-English summary of a document |\n| `flag-risks` | Identify potentially problematic clauses |\n| `compare` | Compare two documents for differences |\n| `extract-clauses` | Extract specific clause types |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Summarize a document\npython3 scripts/legal_doc_scanner.py summarize --file contract.txt\n\n# Flag risky clauses\npython3 scripts/legal_doc_scanner.py flag-risks --file tos.txt\n\n# Compare two versions\npython3 scripts/legal_doc_scanner.py compare --file-a tos_v1.txt --file-b tos_v2.txt\n\n# Extract termination clauses\npython3 scripts/legal_doc_scanner.py extract-clauses --file lease.txt --clause-type termination\n```"
        },
        {
          "slug": "language-tutor",
          "name": "language-tutor",
          "id": "OC-0175",
          "version": "1.0.0",
          "description": "Language Tutor - Run interactive vocabulary drills and grammar corrections",
          "commands": [
            "vocab-drill",
            "grammar-check",
            "translate",
            "lesson",
            "progress"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/language-tutor",
          "markdownBody": "# Language Tutor\n\nInteractive language learning with vocabulary drills, grammar corrections, translations, and personalized lessons.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-powered tutoring\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `vocab-drill` | Run a vocabulary quiz session |\n| `grammar-check` | Check and correct grammar in a sentence |\n| `translate` | Translate text with explanations |\n| `lesson` | Get a mini-lesson on a grammar topic |\n| `progress` | View learning progress |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Vocabulary drill (Spanish, beginner)\npython3 scripts/language_tutor.py vocab-drill --language spanish --level beginner --count 10\n\n# Grammar check\npython3 scripts/language_tutor.py grammar-check --text \"I goes to store yesterday\" --language english\n\n# Translate with explanation\npython3 scripts/language_tutor.py translate --text \"Bon vivant\" --from-lang french --to-lang english --explain\n\n# Get a mini grammar lesson\npython3 scripts/language_tutor.py lesson --language french --topic \"subjunctive mood\"\n```"
        },
        {
          "slug": "gift-recommender",
          "name": "gift-recommender",
          "id": "OC-0174",
          "version": "1.0.0",
          "description": "Gift Recommender - Suggest personalized gifts based on recipient interests and budget",
          "commands": [
            "recommend",
            "budget-gifts",
            "occasion",
            "wishlist"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/gift-recommender",
          "markdownBody": "# Gift Recommender\n\nGet personalized gift suggestions based on recipient interests, age, budget, and occasion using AI.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI gift recommendations\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `recommend` | Get gift recommendations for a person |\n| `budget-gifts` | Find gifts within a specific budget range |\n| `occasion` | Get occasion-specific gift ideas |\n| `wishlist` | Generate a wishlist from interests |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Get recommendations for a friend\npython3 scripts/gift_recommender.py recommend --recipient \"35-year-old male friend\" --interests \"hiking,coffee,photography\" --budget 100\n\n# Budget-specific gifts\npython3 scripts/gift_recommender.py budget-gifts --min 20 --max 50 --interests \"cooking,travel\"\n\n# Occasion-specific gifts\npython3 scripts/gift_recommender.py occasion --occasion \"wedding\" --couple \"adventure-loving couple\" --budget 200\n\n# Generate a wishlist\npython3 scripts/gift_recommender.py wishlist --interests \"gaming,tech,sci-fi\" --budget 500\n```"
        },
        {
          "slug": "dream-journal",
          "name": "dream-journal",
          "id": "OC-0172",
          "version": "1.0.0",
          "description": "Dream Journal - Log and interpret dreams using symbolic analysis",
          "commands": [
            "log",
            "interpret",
            "list",
            "themes"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/dream-journal",
          "markdownBody": "# Dream Journal\n\nLog dreams, get AI-powered symbolic interpretations, and track recurring themes over time.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI dream interpretation\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `log` | Log a new dream |\n| `interpret` | Get symbolic interpretation of a dream |\n| `list` | Browse past dream entries |\n| `themes` | Analyze recurring themes |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Log a dream\npython3 scripts/dream_journal.py log --dream \"I was flying over a city at night...\"\n\n# Interpret a dream\npython3 scripts/dream_journal.py interpret --dream-id DREAM_ID\n\n# List all dreams\npython3 scripts/dream_journal.py list\n\n# Find recurring themes\npython3 scripts/dream_journal.py themes --days 30\n```"
        },
        {
          "slug": "debate-coach",
          "name": "debate-coach",
          "id": "OC-0176",
          "version": "1.0.0",
          "description": "Debate Coach - Argue both sides of a topic and score the strength of arguments",
          "commands": [
            "both-sides",
            "steelman",
            "score",
            "practice"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/debate-coach",
          "markdownBody": "# Debate Coach\n\nExplore both sides of any topic, steelman opposing arguments, score argument quality, and practice structured debate.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-powered debate analysis\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `both-sides` | Present arguments for and against a topic |\n| `steelman` | Build the strongest version of an argument |\n| `score` | Score an argument's logical strength |\n| `practice` | Interactive debate practice session |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Get both sides of a debate topic\npython3 scripts/debate_coach.py both-sides --topic \"Should AI replace human jobs?\"\n\n# Steelman an argument\npython3 scripts/debate_coach.py steelman --argument \"Taxes should be lower\" --side against\n\n# Score an argument\npython3 scripts/debate_coach.py score --argument \"Nuclear energy is the best solution to climate change because it's carbon-free\"\n\n# Practice debate on a topic\npython3 scripts/debate_coach.py practice --topic \"Universal basic income\" --side for\n```"
        },
        {
          "slug": "code-explainer",
          "name": "code-explainer",
          "id": "OC-0177",
          "version": "1.0.0",
          "description": "Code Explainer - Narrate what a code snippet does in plain English for non-developers",
          "commands": [
            "explain",
            "eli5",
            "annotate",
            "complexity"
          ],
          "env": [
            "OPENAI_API_KEY"
          ],
          "path": "miscellaneous/code-explainer",
          "markdownBody": "# Code Explainer\n\nTranslate code into plain English for non-developers, generate line-by-line annotations, and analyze code complexity.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-powered explanations\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `explain` | Explain what a code snippet does |\n| `eli5` | Explain Like I'm 5 â€” ultra-simple explanation |\n| `annotate` | Add inline comments to code |\n| `complexity` | Analyze code complexity and suggest improvements |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Explain a code file\npython3 scripts/code_explainer.py explain --file script.py\n\n# ELI5 explanation\npython3 scripts/code_explainer.py eli5 --file script.py\n\n# Add inline annotations\npython3 scripts/code_explainer.py annotate --file script.py --output annotated.py\n\n# Analyze complexity\npython3 scripts/code_explainer.py complexity --file script.py\n```"
        }
      ],
      "skillCount": 8
    },
    {
      "slug": "finance",
      "name": "Finance",
      "icon": "ðŸ’°",
      "subcategories": [],
      "skills": [
        {
          "slug": "stock-price-fetcher",
          "name": "stock-price-fetcher",
          "id": "OC-0159",
          "version": "1.0.0",
          "description": "Stock Price Fetcher - Get real-time quotes, charts, and earnings data",
          "commands": [
            "quote",
            "chart",
            "earnings",
            "search",
            "watchlist"
          ],
          "env": [
            "ALPHA_VANTAGE_KEY"
          ],
          "path": "finance/stock-price-fetcher",
          "markdownBody": "# Stock Price Fetcher\n\nGet real-time stock quotes, price history, earnings data, and manage a personal watchlist using Alpha Vantage API.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `ALPHA_VANTAGE_KEY` â€” free API key from alphavantage.co\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `quote` | Get real-time quote for a ticker |\n| `chart` | Show price history as ASCII chart |\n| `earnings` | Get earnings history |\n| `search` | Search for ticker symbols |\n| `watchlist` | Manage and display watchlist |\n\n## Usage\n\n```bash\nexport ALPHA_VANTAGE_KEY=\"your_key\"\n\n# Get quote\npython3 scripts/stock_price_fetcher.py quote --ticker AAPL\n\n# Show price chart (last 30 days)\npython3 scripts/stock_price_fetcher.py chart --ticker TSLA --days 30\n\n# Get earnings history\npython3 scripts/stock_price_fetcher.py earnings --ticker MSFT\n\n# Search for ticker\npython3 scripts/stock_price_fetcher.py search --keywords \"Tesla\"\n\n# View/manage watchlist\npython3 scripts/stock_price_fetcher.py watchlist --add NVDA\npython3 scripts/stock_price_fetcher.py watchlist\n```"
        },
        {
          "slug": "invoice-generator",
          "name": "invoice-generator",
          "id": "OC-0161",
          "version": "1.0.0",
          "description": "Invoice Generator - Create and send PDF invoices from structured data",
          "commands": [
            "create",
            "list",
            "send",
            "mark-paid"
          ],
          "env": [
            "RESEND_API_KEY"
          ],
          "path": "finance/invoice-generator",
          "markdownBody": "# Invoice Generator\n\nGenerate professional invoices as text/HTML, track them, and optionally send via email.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `RESEND_API_KEY` â€” optional, for email delivery via Resend\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `create` | Create a new invoice |\n| `list` | List all invoices |\n| `send` | Email an invoice to a client |\n| `mark-paid` | Mark an invoice as paid |\n\n## Usage\n\n```bash\n# Create an invoice\npython3 scripts/invoice_generator.py create \\\n  --client \"Acme Corp\" \\\n  --client-email \"billing@acme.com\" \\\n  --items \"Web Development:40h:150,SEO Audit:1:500\" \\\n  --due-days 30\n\n# List all invoices\npython3 scripts/invoice_generator.py list\n\n# Send invoice by email\npython3 scripts/invoice_generator.py send --invoice-id INV-001\n\n# Mark as paid\npython3 scripts/invoice_generator.py mark-paid --invoice-id INV-001\n```"
        },
        {
          "slug": "google-sheets-analyst",
          "name": "google-sheets-analyst",
          "id": "OC-0163",
          "version": "1.0.0",
          "description": "Google Sheets Analyst - Read, write, and analyze data in spreadsheets",
          "commands": [
            "read",
            "write",
            "append",
            "stats",
            "list-sheets"
          ],
          "env": [
            "GOOGLE_SHEETS_TOKEN"
          ],
          "path": "finance/google-sheets-analyst",
          "markdownBody": "# Google Sheets Analyst\n\nRead, write, and analyze data in Google Spreadsheets directly from the terminal via the Sheets API.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `GOOGLE_SHEETS_TOKEN` â€” OAuth 2.0 bearer token with `spreadsheets` scope\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `read` | Read data from a sheet range |\n| `write` | Write data to a sheet range |\n| `append` | Append rows to a sheet |\n| `stats` | Calculate basic stats on a column |\n| `list-sheets` | List sheets in a spreadsheet |\n\n## Usage\n\n```bash\nexport GOOGLE_SHEETS_TOKEN=\"your_oauth_token\"\n\n# Read a range\npython3 scripts/google_sheets_analyst.py read --spreadsheet-id \"ID\" --range \"Sheet1!A1:E10\"\n\n# Write data\npython3 scripts/google_sheets_analyst.py write --spreadsheet-id \"ID\" --range \"Sheet1!A1\" --values \"Name,Age,City\"\n\n# Append a row\npython3 scripts/google_sheets_analyst.py append --spreadsheet-id \"ID\" --sheet \"Sheet1\" --values \"John,30,NY\"\n\n# Get stats for a column\npython3 scripts/google_sheets_analyst.py stats --spreadsheet-id \"ID\" --range \"Sheet1!B2:B100\"\n\n# List sheets\npython3 scripts/google_sheets_analyst.py list-sheets --spreadsheet-id \"ID\"\n```"
        },
        {
          "slug": "financial-report-summarizer",
          "name": "financial-report-summarizer",
          "id": "OC-0164",
          "version": "1.0.0",
          "description": "Financial Report Summarizer - Parse 10-K/10-Q filings and extract key metrics",
          "commands": [
            "search-filings",
            "summarize",
            "key-metrics",
            "compare"
          ],
          "env": [
            "OPENAI_API_KEY",
            "SEC_API_KEY"
          ],
          "path": "finance/financial-report-summarizer",
          "markdownBody": "# Financial Report Summarizer\n\nSearch SEC EDGAR filings, fetch financial reports, and extract key metrics using AI analysis.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for AI-powered summarization\n- `SEC_API_KEY` â€” optional, from sec-api.io for enhanced search\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `search-filings` | Search SEC EDGAR for company filings |\n| `summarize` | AI-summarize a 10-K or 10-Q filing |\n| `key-metrics` | Extract key financial metrics from a filing |\n| `compare` | Compare two quarters/years |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\n\n# Search for Apple's 10-K filings\npython3 scripts/financial_report_summarizer.py search-filings --company \"Apple\" --form \"10-K\"\n\n# Summarize a filing by CIK and accession number\npython3 scripts/financial_report_summarizer.py summarize --cik \"0000320193\" --form \"10-K\"\n\n# Extract key metrics\npython3 scripts/financial_report_summarizer.py key-metrics --cik \"0000320193\"\n```"
        },
        {
          "slug": "crypto-wallet-watcher",
          "name": "crypto-wallet-watcher",
          "id": "OC-0158",
          "version": "1.0.0",
          "description": "Crypto Wallet Watcher - Monitor addresses for incoming/outgoing transactions",
          "commands": [
            "watch",
            "balance",
            "transactions",
            "alerts"
          ],
          "env": [],
          "path": "finance/crypto-wallet-watcher",
          "markdownBody": "# Crypto Wallet Watcher\n\nMonitor crypto wallet addresses for incoming/outgoing transactions. Supports Bitcoin, Ethereum, and other major chains via public APIs.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `balance` | Get wallet balance |\n| `transactions` | List recent transactions |\n| `watch` | Add/remove addresses to watchlist |\n| `alerts` | Check for new transactions on watched addresses |\n\n## Usage\n\n```bash\n# Check ETH wallet balance\npython3 scripts/crypto_wallet_watcher.py balance --address \"0x...\" --chain eth\n\n# Check BTC wallet balance\npython3 scripts/crypto_wallet_watcher.py balance --address \"bc1q...\" --chain btc\n\n# List recent transactions\npython3 scripts/crypto_wallet_watcher.py transactions --address \"0x...\" --chain eth --limit 10\n\n# Add to watchlist\npython3 scripts/crypto_wallet_watcher.py watch --add --address \"0x...\" --label \"My ETH Wallet\"\n\n# Check for new activity on watched addresses\npython3 scripts/crypto_wallet_watcher.py alerts\n```"
        },
        {
          "slug": "crm-data-puller",
          "name": "crm-data-puller",
          "id": "OC-0162",
          "version": "1.0.0",
          "description": "CRM Data Puller - Fetch deals and contact data from HubSpot or Salesforce",
          "commands": [
            "contacts",
            "deals",
            "pipeline",
            "search-contact",
            "create-contact"
          ],
          "env": [
            "HUBSPOT_TOKEN"
          ],
          "path": "finance/crm-data-puller",
          "markdownBody": "# CRM Data Puller\n\nFetch, search, and manage CRM data from HubSpot directly from the terminal. View contacts, deals, and pipeline status.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `HUBSPOT_TOKEN` â€” HubSpot private app access token\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `contacts` | List recent contacts |\n| `deals` | List deals by stage or owner |\n| `pipeline` | Show deal pipeline summary |\n| `search-contact` | Search contacts by name or email |\n| `create-contact` | Create a new contact |\n\n## Usage\n\n```bash\nexport HUBSPOT_TOKEN=\"your_token\"\n\n# List recent contacts\npython3 scripts/crm_data_puller.py contacts --limit 20\n\n# List open deals\npython3 scripts/crm_data_puller.py deals --stage \"presentationscheduled\"\n\n# View pipeline summary\npython3 scripts/crm_data_puller.py pipeline\n\n# Search for a contact\npython3 scripts/crm_data_puller.py search-contact --query \"john@acme.com\"\n\n# Create a new contact\npython3 scripts/crm_data_puller.py create-contact --email \"new@client.com\" --name \"Jane Doe\" --company \"Acme\"\n```"
        },
        {
          "slug": "budget-tracker",
          "name": "budget-tracker",
          "id": "OC-0160",
          "version": "1.0.0",
          "description": "Budget Tracker - Parse transactions and categorize spending automatically",
          "commands": [
            "add-transaction",
            "list",
            "summary",
            "set-budget",
            "import-csv"
          ],
          "env": [],
          "path": "finance/budget-tracker",
          "markdownBody": "# Budget Tracker\n\nTrack income and expenses, auto-categorize transactions, set budgets, and analyze spending patterns â€” all from the terminal.\n\n## Prerequisites\n\n- Python 3.8+\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `add-transaction` | Add an income or expense |\n| `list` | List recent transactions |\n| `summary` | Show spending summary by category |\n| `set-budget` | Set a monthly budget for a category |\n| `import-csv` | Import transactions from a CSV file |\n\n## Usage\n\n```bash\n# Add an expense\npython3 scripts/budget_tracker.py add-transaction --amount 45.50 --type expense --category food --description \"Grocery run\"\n\n# Add income\npython3 scripts/budget_tracker.py add-transaction --amount 3500 --type income --category salary --description \"Monthly salary\"\n\n# List last 20 transactions\npython3 scripts/budget_tracker.py list --limit 20\n\n# Show monthly summary\npython3 scripts/budget_tracker.py summary --month 2024-12\n\n# Set a monthly budget for food\npython3 scripts/budget_tracker.py set-budget --category food --amount 500\n\n# Import CSV\npython3 scripts/budget_tracker.py import-csv --file transactions.csv\n```"
        }
      ],
      "skillCount": 7
    },
    {
      "slug": "smart-home",
      "name": "Smart Home",
      "icon": "ðŸ ",
      "subcategories": [],
      "skills": [
        {
          "slug": "smart-appliance-scheduler",
          "name": "smart-appliance-scheduler",
          "id": "OC-0169",
          "version": "1.0.0",
          "description": "Smart Appliance Scheduler - Schedule dishwashers, EV charging for off-peak hours",
          "commands": [
            "schedule",
            "list-schedules",
            "cancel",
            "off-peak-windows",
            "run-now"
          ],
          "env": [
            "HOME_ASSISTANT_URL",
            "HOME_ASSISTANT_TOKEN"
          ],
          "path": "smart-home/smart-appliance-scheduler",
          "markdownBody": "# Smart Appliance Scheduler\n\nSchedule smart appliances to run during off-peak electricity hours to reduce costs. Integrates with Home Assistant for smart plug and switch control.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `HOME_ASSISTANT_URL` â€” Home Assistant base URL\n- `HOME_ASSISTANT_TOKEN` â€” Long-lived access token\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `schedule` | Schedule an appliance for off-peak hours |\n| `list-schedules` | Show all scheduled tasks |\n| `cancel` | Cancel a scheduled task |\n| `off-peak-windows` | Show today's off-peak time windows |\n| `run-now` | Trigger an appliance immediately |\n\n## Usage\n\n```bash\nexport HOME_ASSISTANT_URL=\"http://homeassistant.local:8123\"\nexport HOME_ASSISTANT_TOKEN=\"your_token\"\n\n# Schedule EV charger for off-peak overnight\npython3 scripts/smart_appliance_scheduler.py schedule --entity-id \"switch.ev_charger\" --at \"02:00\" --duration 240 --label \"EV Charge\"\n\n# Show off-peak windows\npython3 scripts/smart_appliance_scheduler.py off-peak-windows --peak-start 16 --peak-end 21\n\n# List all schedules\npython3 scripts/smart_appliance_scheduler.py list-schedules\n\n# Run an appliance immediately\npython3 scripts/smart_appliance_scheduler.py run-now --entity-id \"switch.dishwasher\" --duration 90\n```"
        },
        {
          "slug": "mqtt-publisher",
          "name": "mqtt-publisher",
          "id": "OC-0166",
          "version": "1.0.0",
          "description": "MQTT Publisher - Publish and subscribe to MQTT topics for IoT messaging",
          "commands": [
            "publish",
            "subscribe-once",
            "publish-batch",
            "test-connection",
            "list-topics"
          ],
          "env": [
            "MQTT_BROKER_HOST",
            "MQTT_PORT",
            "MQTT_USERNAME",
            "MQTT_PASSWORD"
          ],
          "path": "smart-home/mqtt-publisher",
          "markdownBody": "# MQTT Publisher\n\nPublish and subscribe to MQTT topics for IoT device messaging. Supports single messages, batch publishing from JSON files, and connection testing.\n\n## Prerequisites\n\n- Python 3.8+\n- `paho-mqtt` library (`pip install paho-mqtt`)\n- Environment variables: `MQTT_BROKER_HOST`, `MQTT_PORT` (default: 1883), `MQTT_USERNAME` (optional), `MQTT_PASSWORD` (optional)\n\n## Commands\n\n| Command           | Parameters                                                                          | Description                                      |\n| ----------------- | ----------------------------------------------------------------------------------- | ------------------------------------------------ |\n| `publish`         | `--topic`, `--payload`, `--qos` (0/1/2), `--retain`                                | Publish a message to a topic                     |\n| `subscribe-once`  | `--topic`, `--timeout` (default: 10)                                                | Subscribe and print the first message received   |\n| `publish-batch`   | `--file` (JSON array of {topic, payload})                                           | Publish multiple messages from a JSON file       |\n| `test-connection` | (none)                                                                              | Test connection to the MQTT broker               |\n| `list-topics`     | `--prefix-filter`                                                                   | Note broker-side topic listing limitations       |\n\n## Usage\n\n```bash\nexport MQTT_BROKER_HOST=\"mqtt.example.com\"\nexport MQTT_PORT=\"1883\"\nexport MQTT_USERNAME=\"user\"\nexport MQTT_PASSWORD=\"pass\"\n\n# Publish a message\npython3 scripts/mqtt_publisher.py publish --topic home/living_room/light --payload '{\"state\": \"on\"}' --qos 1\n\n# Subscribe and get one message\npython3 scripts/mqtt_publisher.py subscribe-once --topic home/sensors/temp --timeout 15\n\n# Publish batch from file\npython3 scripts/mqtt_publisher.py publish-batch --file messages.json\n\n# Test broker connection\npython3 scripts/mqtt_publisher.py test-connection\n\n# Info about topic listing\npython3 scripts/mqtt_publisher.py list-topics --prefix-filter home/\n```"
        },
        {
          "slug": "home-assistant",
          "name": "home-assistant",
          "id": "OC-0165",
          "version": "1.0.0",
          "description": "Home Assistant - Control and query your Home Assistant smart home instance",
          "commands": [
            "list-entities",
            "get-state",
            "call-service",
            "turn-on",
            "turn-off",
            "toggle",
            "list-scenes",
            "activate-scene"
          ],
          "env": [
            "HA_BASE_URL",
            "HA_TOKEN"
          ],
          "path": "smart-home/home-assistant",
          "markdownBody": "# Home Assistant\n\nControl and query your Home Assistant smart home instance from the terminal. List entities, read states, call services, and manage scenes.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- Environment variables: `HA_BASE_URL` (e.g. `http://homeassistant.local:8123`), `HA_TOKEN` (long-lived access token)\n\n## Commands\n\n| Command            | Parameters                                                                          | Description                                |\n| ------------------ | ----------------------------------------------------------------------------------- | ------------------------------------------ |\n| `list-entities`    | `--domain-filter` (optional, e.g. light/switch/climate)                             | List all entity states, optionally filtered |\n| `get-state`        | `--entity-id`                                                                       | Get the current state of an entity         |\n| `call-service`     | `--domain`, `--service`, `--entity-id`, `--data-json` (optional)                   | Call any Home Assistant service            |\n| `turn-on`          | `--entity-id`                                                                       | Turn on an entity                          |\n| `turn-off`         | `--entity-id`                                                                       | Turn off an entity                         |\n| `toggle`           | `--entity-id`                                                                       | Toggle an entity on/off                    |\n| `list-scenes`      | (none)                                                                              | List all available scenes                  |\n| `activate-scene`   | `--scene-id`                                                                        | Activate a scene by entity ID              |\n\n## Usage\n\n```bash\nexport HA_BASE_URL=\"http://homeassistant.local:8123\"\nexport HA_TOKEN=\"your-long-lived-access-token\"\n\n# List all light entities\npython3 scripts/home_assistant.py list-entities --domain-filter light\n\n# Get state of a specific entity\npython3 scripts/home_assistant.py get-state --entity-id light.living_room\n\n# Turn on a light\npython3 scripts/home_assistant.py turn-on --entity-id light.living_room\n\n# Turn off a switch\npython3 scripts/home_assistant.py turn-off --entity-id switch.fan\n\n# Toggle a light\npython3 scripts/home_assistant.py toggle --entity-id light.bedroom\n\n# Call a custom service\npython3 scripts/home_assistant.py call-service --domain light --service turn_on --entity-id light.kitchen --data-json '{\"brightness\": 200}'\n\n# List all scenes\npython3 scripts/home_assistant.py list-scenes\n\n# Activate a scene\npython3 scripts/home_assistant.py activate-scene --scene-id scene.movie_night\n```"
        },
        {
          "slug": "energy-monitor",
          "name": "energy-monitor",
          "id": "OC-0167",
          "version": "1.0.0",
          "description": "Energy Monitor - Track and report home energy consumption trends",
          "commands": [
            "current-usage",
            "daily-report",
            "monthly-summary",
            "log-reading",
            "cost-estimate"
          ],
          "env": [
            "HOME_ASSISTANT_URL",
            "HOME_ASSISTANT_TOKEN"
          ],
          "path": "smart-home/energy-monitor",
          "markdownBody": "# Energy Monitor\n\nTrack and analyze home energy consumption. Integrates with Home Assistant sensors or manual readings to build consumption trends.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `HOME_ASSISTANT_URL` â€” Home Assistant base URL (optional, for smart meter integration)\n- `HOME_ASSISTANT_TOKEN` â€” Home Assistant long-lived access token (optional)\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `current-usage` | Get current energy readings from HA |\n| `daily-report` | Show today's consumption report |\n| `monthly-summary` | Show monthly usage and cost summary |\n| `log-reading` | Manually log a meter reading |\n| `cost-estimate` | Estimate energy cost |\n\n## Usage\n\n```bash\nexport HOME_ASSISTANT_URL=\"http://homeassistant.local:8123\"\nexport HOME_ASSISTANT_TOKEN=\"your_token\"\n\n# Get current energy usage from Home Assistant\npython3 scripts/energy_monitor.py current-usage\n\n# View daily report\npython3 scripts/energy_monitor.py daily-report\n\n# Log a manual meter reading (kWh)\npython3 scripts/energy_monitor.py log-reading --kwh 1234.5\n\n# Estimate monthly cost\npython3 scripts/energy_monitor.py cost-estimate --kwh 300 --rate 0.12\n```"
        },
        {
          "slug": "camera-feed-analyzer",
          "name": "camera-feed-analyzer",
          "id": "OC-0168",
          "version": "1.0.0",
          "description": "Camera Feed Analyzer - Describe or detect objects in a home camera snapshot",
          "commands": [
            "analyze-snapshot",
            "detect-motion",
            "describe-scene",
            "analyze-file"
          ],
          "env": [
            "OPENAI_API_KEY",
            "HOME_ASSISTANT_URL",
            "HOME_ASSISTANT_TOKEN"
          ],
          "path": "smart-home/camera-feed-analyzer",
          "markdownBody": "# Camera Feed Analyzer\n\nAnalyze home camera snapshots using AI vision. Detect objects, describe scenes, and identify unusual activity.\n\n## Prerequisites\n\n- Python 3.8+\n- `requests` library (`pip install requests`)\n- `OPENAI_API_KEY` â€” for GPT-4 Vision analysis\n- `HOME_ASSISTANT_URL` + `HOME_ASSISTANT_TOKEN` â€” for camera entity integration\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `analyze-snapshot` | Fetch and analyze a camera snapshot from HA |\n| `detect-motion` | Describe movement or activity in an image |\n| `describe-scene` | Provide a detailed scene description |\n| `analyze-file` | Analyze a local image file |\n\n## Usage\n\n```bash\nexport OPENAI_API_KEY=\"your_key\"\nexport HOME_ASSISTANT_URL=\"http://homeassistant.local:8123\"\nexport HOME_ASSISTANT_TOKEN=\"your_ha_token\"\n\n# Analyze camera feed from Home Assistant\npython3 scripts/camera_feed_analyzer.py analyze-snapshot --entity-id \"camera.front_door\"\n\n# Describe a local image file\npython3 scripts/camera_feed_analyzer.py analyze-file --file /path/to/snapshot.jpg\n\n# Detect motion/activity\npython3 scripts/camera_feed_analyzer.py detect-motion --entity-id \"camera.backyard\"\n```"
        }
      ],
      "skillCount": 5
    },
    {
      "slug": "image-gen",
      "name": "Image Gen",
      "icon": "ðŸ–¼ï¸",
      "subcategories": [],
      "skills": [
        {
          "slug": "image-gen",
          "name": "nvidia-image-gen",
          "id": null,
          "version": "1.0.0",
          "description": "Generate and edit images using NVIDIA FLUX models. Use when user asks to generate images, create pictures, edit photos, or modify existing images with AI. Supports text-to-image generation and image editing with text prompts.",
          "commands": [],
          "env": [],
          "path": "image-gen",
          "markdownBody": "# NVIDIA Image Generation\n\nGenerate and edit images using NVIDIA's FLUX models.\n\n## Models\n\n| Model | Use Case | Speed | Quality |\n|-------|----------|-------|---------|\n| `dev` | High-quality text-to-image | Normal | Best |\n| `schnell` | Fast text-to-image | Fast | Good |\n| `stable` | Stable Diffusion text-to-image | Fast | Good |\n| `kontext` | Image editing | Normal | Best |\n\n## Quick Start\n\n```bash\n# Generate an image\npython3 skills/nvidia-image-gen/scripts/generate.py \"A cute cat in space\"\n\n# Edit an existing image\npython3 skills/nvidia-image-gen/scripts/generate.py \"Add sunglasses\" -i photo.jpg -o edited.png\n```\n\n## Parameters\n\n### Text-to-Image (dev/schnell)\n\n| Parameter | Short | Default | Description |\n|-----------|-------|---------|-------------|\n| `prompt` | | (required) | Text description |\n| `-o, --output` | | output.png | Output file path |\n| `--width` | | 1024 | Output width in pixels |\n| `--height` | | 1024 | Output height in pixels |\n| `--aspect-ratio` | `-ar` | 1:1 | Aspect ratio preset |\n| `--steps` | `-s` | 30 | Diffusion steps |\n| `--seed` | | 0 | Random seed (0=random) |\n| `--model` | `-m` | auto | Model selection |\n\n### Image Editing (kontext)\n\n| Parameter | Short | Default | Description |\n|-----------|-------|---------|-------------|\n| `prompt` | | (required) | Edit instruction |\n| `-i, --input` | | (required) | Input image path |\n| `-o, --output` | | output.png | Output file path |\n| `--steps` | `-s` | 30 | Diffusion steps |\n| `--cfg` | | 3.5 | Guidance scale |\n| `--seed` | | 0 | Random seed |\n\n### Stable Diffusion 3 Medium (stable)\n\n| Parameter | Type | Default | Required | Description |\n|-----------|------|---------|----------|-------------|\n| `prompt` | string | â€” | âœ… | What you wish to see in the output image (max 10,000 chars) |\n| `aspect_ratio` | string | `1:1` | | Aspect ratio. Allowed: `1:1`, `16:9`, `9:16`, `5:4`, `4:5`, `3:2`, `2:3` |\n| `cfg_scale` | number | `5` | | Classifier-free guidance scale (max 9). Higher = more aligned, less diverse |\n| `negative_prompt` | string | `null` | | What you do *not* want in the image (advanced) |\n| `steps` | integer | `50` | | Diffusion steps, 5â€“100. More steps = higher quality but slower |\n| `seed` | integer | `0` | | Random seed (â‰¥ 0). Use `0` for random |\n| `output_format` | string | `jpeg` | | Output content-type. Allowed: `jpeg` |\n| `mode` | string | `text-to-image` | | Generation mode. Allowed: `text-to-image` |\n| `model` | string | `sd3` | | Model to use. Allowed: `sd3` |\n\n## Supported Aspect Ratios\n\n| Ratio | Resolution |\n|-------|------------|\n| 1:1 | 1024Ã—1024 |\n| 16:9 | 1344Ã—768 |\n| 9:16 | 768Ã—1344 |\n| 4:3 | 1216Ã—832 |\n| 3:4 | 832Ã—1216 |\n\n## Examples\n\n### Basic Generation\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"A mountain landscape at sunset\"\n```\n\n### Wide Format (16:9)\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"A panoramic beach view\" -ar 16:9\n```\n\n### Portrait Mode (9:16)\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"A professional headshot\" -ar 9:16\n```\n\n### Custom Size\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"A banner image\" --width 1344 --height 768\n```\n\n### Fast Generation\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"Quick sketch of a robot\" -m schnell\n```\n\n### Edit an Image\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"Make the background a sunset\" -i input.jpg -o output.png\n```\n\n### Reproducible Results\n```bash\npython3 skills/nvidia-image-gen/scripts/generate.py \"A robot\" --seed 12345\n```\n\n## Output\n\nThe script outputs `MEDIA:/path/to/image.png` which can be sent directly to chat.\n\n## API Key\n\nThe API key is embedded in the script. To use a different key, set the `NVIDIA_API_KEY` environment variable."
        }
      ],
      "skillCount": 1
    },
    {
      "slug": "github-copilot",
      "name": "Github Copilot",
      "icon": "ðŸ¤–",
      "subcategories": [],
      "skills": [
        {
          "slug": "github-copilot",
          "name": "copilot",
          "id": null,
          "version": "1.0.0",
          "description": "GitHub Copilot CLI skill. Use when you need an AI agent to perform LOCAL coding work: edit files, run shell commands, and iterate on code in a working directory. This is completely separate from `gh agent-task`.",
          "commands": [],
          "env": [],
          "path": "github-copilot",
          "markdownBody": "# Copilot CLI Skill\n\n## What this is\n\nThe **GitHub Copilot CLI** (`copilot` binary, installed via npm) is a local,\ninteractive, agentic terminal tool. It:\n\n- Runs **on the host machine** in a working directory you specify.\n- Reads and **edits local files** directly.\n- Runs **shell commands** on the host.\n- Streams its progress to stdout.\n- Exits when the task is done.\n\n## What this is NOT\n\n| NOT this | Use instead |\n|----------|-------------|\n| `gh copilot` extension | Deprecated Oct 25, 2025 â€” do not use |\n| `gh agent-task` | Remote task that opens a PR. Use the `gh` skill. |\n| GitHub Copilot Chat | Browser/IDE feature, not scriptable |\n\n## Installation\n```bash\nnpm install -g @github/copilot\n# verify\ncopilot --version\n```\n\n## Authentication\n\nEither:\n- Set `GH_TOKEN` (or `GITHUB_TOKEN`) to a fine-grained PAT with the\n  **\"Copilot Requests\"** permission, or\n- Run `copilot` once interactively and follow the `/login` device-code flow.\n\n## Key concept: tool approval\n\nBy default `copilot` pauses and asks for approval before every file write or\nshell command. For non-interactive / AI agent use you **must** pass an\napproval flag, otherwise it will block indefinitely.\n\n| Flag | Effect |\n|------|--------|\n| `--allow-all-tools` | Approve everything (full access, same as current user) |\n| `--allow-tool shell` | Approve all shell commands without prompt |\n| `--allow-tool write` | Approve all file writes without prompt |\n| `--allow-tool shell(rm)` | Approve only `rm` commands |\n| `--deny-tool shell(rm)` | Block `rm` entirely |\n\nYou can combine `--allow-tool` and `--deny-tool` freely. `--deny-tool` takes\nprecedence over `--allow-tool`.\n\n---\n\n## Commands\n\n### `run` â€” execute a Copilot CLI task\n```bash\npython3 scripts/gh-copilot.py run \"<prompt>\" [options]\n```\n\n**Options:**\n\n| Flag | Description |\n|------|-------------|\n| `--cwd <path>` | Working directory (default: current dir) |\n| `--allow-all-tools` | Approve all tools without prompting |\n| `--allow-tool <spec>` | Approve a specific tool (repeatable) |\n| `--deny-tool <spec>` | Block a specific tool (repeatable) |\n| `--model <name>` | Override AI model (default: Claude Sonnet 4.5) |\n| `--experimental` | Enable preview features |\n| `--trust-all-repos` | Skip directory trust prompt |\n| `--token <pat>` | PAT to use (overrides GH_TOKEN) |\n\n---\n\n## Usage examples\n```bash\n# Explain code in a local repo (read-only, no tools needed)\npython3 scripts/gh-copilot.py run \"Explain the auth middleware in src/auth.py\" \\\n  --cwd /path/to/my-project\n\n# Fix a bug â€” allow file writes only\npython3 scripts/gh-copilot.py run \"Fix the null pointer bug in UserService.java\" \\\n  --cwd /path/to/project \\\n  --allow-tool write\n\n# Full autonomous task: edit files + run tests\npython3 scripts/gh-copilot.py run \\\n  \"Add input validation to all API endpoints. Run pytest after each change.\" \\\n  --cwd /path/to/api-project \\\n  --allow-all-tools\n\n# Same but block destructive shell commands\npython3 scripts/gh-copilot.py run \\\n  \"Refactor the database layer to use SQLAlchemy 2.0.\" \\\n  --cwd /path/to/project \\\n  --allow-tool write \\\n  --allow-tool shell \\\n  --deny-tool \"shell(rm)\" \\\n  --deny-tool \"shell(git push)\"\n\n# Use a specific model\npython3 scripts/gh-copilot.py run \"Review and improve test coverage\" \\\n  --cwd /path/to/project \\\n  --allow-tool write \\\n  --model \"claude-sonnet-4\"\n```\n\n---\n\n## Typical pattern: local work â†’ then push via `gh`\n\nThe Copilot CLI works locally. Once it's done editing, you use normal git and\nthe `gh` skill to push and open a PR:\n```bash\n# 1. Run Copilot CLI to do the local coding work\npython3 scripts/gh-copilot.py run \\\n  \"Implement the feature described in TASK.md\" \\\n  --cwd /repos/my-project \\\n  --allow-tool write \\\n  --allow-tool shell \\\n  --deny-tool \"shell(git push)\"\n\n# 2. Push and open a PR with the gh skill\ncd /repos/my-project\npython3 ../gh/scripts/gh_skill.py pr create \\\n  --title \"feat: implement feature X\" \\\n  --body \"Implemented by Copilot CLI\" \\\n  --base main \\\n  --repo myorg/my-project\n```"
        }
      ],
      "skillCount": 1
    },
    {
      "slug": "github",
      "name": "Github",
      "icon": "ðŸ™",
      "subcategories": [],
      "skills": [
        {
          "slug": "github",
          "name": "gh",
          "id": null,
          "version": "1.0.0",
          "description": "GitHub CLI skill. Use for repository management, pull request lifecycle, Copilot coding agent tasks (gh agent-task), and managing custom agent configs (.github/agents/*.md). All operations are pure `gh` CLI calls.",
          "commands": [],
          "env": [],
          "path": "github",
          "markdownBody": "# gh Skill\n\nThis skill wraps the `gh` CLI. It has **nothing to do with the Copilot CLI**\n(`copilot` binary). See the separate `copilot` skill for that.\n\n## Concepts\n\n### gh agent-task â€” Copilot coding agent\n`gh agent-task create` delegates a coding task to GitHub's **Copilot coding\nagent**. The agent runs **remotely** in a sandboxed GitHub environment, makes\ncode changes to the repository, and opens a **pull request** when finished.\nYou track progress with `gh agent-task view`. This is a GitHub platform\nfeature, not a local tool.\n\nCustom agent personas for it are markdown files stored at\n`.github/agents/<name>.md` in the target repo. Manage them with\n`agent-config install/list/remove`.\n\n### Authentication\n| Command group   | Auth required                              |\n|----------------|--------------------------------------------|\n| `repo`, `pr`   | `GITHUB_TOKEN` / `GH_TOKEN` PAT (repo scope) |\n| `agent-task`   | **OAuth session** â€” run `gh auth login` first. PAT alone is rejected by GitHub (exit code 4). |\n| `agent-config` | PAT with `repo` scope (uses GitHub Contents API) |\n\n---\n\n## Commands\n\n### `repo` â€” Repository management\n```bash\npython3 scripts/gh.py repo list [--limit 30] [--org myorg]\npython3 scripts/gh.py repo create \"my-repo\" [--private] [--description \"...\"] [--auto-init] [--org myorg]\npython3 scripts/gh.py repo view  owner/my-repo\npython3 scripts/gh.py repo edit  owner/my-repo [--description \"New\"] [--visibility private|public|internal]\npython3 scripts/gh.py repo clone owner/my-repo [local-dir]\npython3 scripts/gh.py repo delete owner/my-repo [--yes]\n```\n\n### `pr` â€” Pull request lifecycle\n```bash\n# Create\npython3 scripts/gh.py pr create --title \"feat: login\" --body \"Closes #12\" \\\n  --base main --head feature/login [--draft] [--label bug] [--assignee alice] [--repo owner/repo]\n\n# List / filter\npython3 scripts/gh.py pr list [--state open|closed|merged|all] [--limit 20] \\\n  [--author alice] [--label bug] [--base main] [--repo owner/repo]\n\n# Inspect\npython3 scripts/gh.py pr view    <number> [--repo owner/repo]\npython3 scripts/gh.py pr diff    <number> [--repo owner/repo]\npython3 scripts/gh.py pr checks  <number> [--repo owner/repo]\n\n# Interact\npython3 scripts/gh.py pr comment <number> --body \"Please rebase\" [--repo owner/repo]\npython3 scripts/gh.py pr review  <number> --action approve|request-changes|comment \\\n  [--body \"LGTM\"] [--repo owner/repo]\npython3 scripts/gh.py pr edit    <number> [--title \"...\"] [--body \"...\"] [--base main] \\\n  [--add-label hotfix] [--add-assignee bob] [--repo owner/repo]\npython3 scripts/gh.py pr ready   <number> [--repo owner/repo]   # un-draft a PR\n\n# Finalise\npython3 scripts/gh.py pr merge <number> [--method merge|squash|rebase] \\\n  [--no-delete-branch] [--repo owner/repo]\npython3 scripts/gh.py pr close <number> [--comment \"Won't fix\"] \\\n  [--delete-branch] [--repo owner/repo]\n```\n\n### `agent-task` â€” Copilot coding agent tasks âš ï¸ requires OAuth\n```bash\n# Create a task â€” Copilot works remotely and opens a PR\npython3 scripts/gh.py agent-task create \"Refactor auth to use JWT\"\npython3 scripts/gh.py agent-task create \"Add OpenAPI spec\" \\\n  -R owner/my-api -b main -a code-review --follow\n\n# Pass a long task description from a file\npython3 scripts/gh.py agent-task create -F task-brief.md\n\n# List recent tasks (all repos, current user)\npython3 scripts/gh.py agent-task list [--limit 30] [--web]\n\n# Track a task (by PR number, session UUID, or branch)\npython3 scripts/gh.py agent-task view 42\npython3 scripts/gh.py agent-task view e2fa49d2-f164-4a56-ab99-498090b8fcdf\npython3 scripts/gh.py agent-task view owner/repo#42\npython3 scripts/gh.py agent-task view 42 --follow   # stream live logs\npython3 scripts/gh.py agent-task view 42 --log       # full session log\n```\n\n### `agent-config` â€” Manage .github/agents/*.md files\n\nThese are custom agent persona files. They customise the Copilot coding agent\nwhen referenced by `--custom-agent` in `agent-task create`.\n```bash\npython3 scripts/gh.py agent-config install owner/my-repo code-review\npython3 scripts/gh.py agent-config list    owner/my-repo\npython3 scripts/gh.py agent-config remove  owner/my-repo code-review\n```\n\nLocal templates live in `skills/gh/templates/`. Available: `default`, `code-review`.\n\n---\n\n## Typical AI agent workflow\n```bash\n# 1. Create repo\npython3 scripts/gh.py repo create \"auth-service\" --private --auto-init --org myorg\n\n# 2. Install a custom agent persona\npython3 scripts/gh.py agent-config install myorg/auth-service code-review\n\n# 3. Delegate implementation to Copilot coding agent (opens a PR when done)\npython3 scripts/gh.py agent-task create \\\n  \"Implement JWT authentication with FastAPI. Add pytest tests. Update README.\" \\\n  -R myorg/auth-service -a code-review --follow\n\n# 4. Check CI on the resulting PR\npython3 scripts/gh.py pr checks 1 --repo myorg/auth-service\n\n# 5. Approve and merge\npython3 scripts/gh.py pr review 1 --action approve --body \"LGTM\"\npython3 scripts/gh.py pr merge  1 --method squash --repo myorg/auth-service\n```"
        }
      ],
      "skillCount": 1
    }
  ],
  "totalSkills": 188,
  "generatedAt": "2026-02-22T21:36:19.970Z"
}